NP1 Definitions - 481 - NP Overview
How do we prove that a problem is computationally difficult? Meaning that it is hard to devise an efficient algorithm to solve it for all inputs. To do this, we'll prove that the problem will then be complete. In this section, we'll look at the definition of the class NP and what exactly it means for a problem to be NP-complete. We'll first detail the notion of a reduction. We've actually seen several examples of reductions in this class before. For example, we reduced the two-set problem to the strongly connected components problem. We'll formalize this concept of reduction. Then we'll see what it means that a problem is NP-complete and how to prove that it is NP-complete. We'll look at a bunch of examples of NP-completeness proofs: 3SAT; Graph Problems for example Independent sets, Clique, and Vertex cover; and the classic Knapsack problem. Finally, we'll see Alan Turing's proof that the halting problem is not just computationally difficult but, in fact, it's not solvable in general. Formally, it's undecidable

NP1 Definitions - 482 - NP1 Lecture Outline
In this section we're going to study computational complexity. We're going to address the following question. What precisely does NP completeness mean and how do we prove that a problem is NP complete. Many of you have probably heard of the equation P equals NP or P naught equals NP. We're going to take a look at what precisely this question means. Finally we're going to look at how do we show that a particular problem is intractable. Now what exactly do we mean by intractable, we mean that is unlikely to be solved efficiently. Now we'd love to say that it definitely cannot be solved efficiently, instead of unlikely to be solved efficiently. But that's more than we can achieve at this time. Now what exactly do we mean by efficiently. Well, by that we mean that is polynomial in the input size. Can we solve this particular problem, in time polynomial in the input size. Now in order to show that a particular problem is intractable, what we're going to do is, we're going to prove that it's NP complete. So we're going to learn how to prove that a particular problem is NP complete. So let's dive in now to see what P and NP mean.

NP1 Definitions - 483 - Complexity Classes
We're going to define NP as the class of all search problems. What exactly do we mean by search problems? Well, we'll look at that in more detail in a second. Now, there's one important distinction that we need to bring out at the beginning. We're using the class of search problems to find its class NP. Now traditionally, and what many of you may have seen in your undergraduate course, is that the NP is defined with the class of decision problems instead of search problems. Now, this is a somewhat minor distinction. But for consistency in this class, we're going to use search problems for NP. Why am I using search problems instead of decision problems? Well, it's somewhat more natural to use search problems. In addition, the group of textbook also defines NP with respect to search problems. Now, if you've seen decision problems before, the appeal of search problems is that it gets rid of the need for a witness for particular instances. In any case, let's forget about the notion of decision problems and let's focus on search problems in this course. What do we mean by search problems? Let's look at a rough definition of search problems and then in the next slide, we will look at a formal definition of search problems. Now, roughly, a search problem is a problem where we can efficiently verify solutions so if I give you particular input and I give you a solution to that input, then I can verify that that solution is in fact a solution to that input. I can check solutions in polynomial time so the time it takes to generate the solution doesn't have anything to do with it. All that matters is if I give you an input and I give you a solution, then you can verify that solution in polynomial time. Now, if I want to know about the time it takes to generate a solution then look at the class P. Now, the class P are those search problems which can be solved in polynomial time so I can generate a solution in polynomial time. Whereas, NP just says that it can verify solutions in polynomial time. Now, of course, if I can generate a solution polynomial time then I can also verify solutions in polynomial time. So, P is a subset of NP. Any problem that can be solved in P can also be solved in NP. Formally, we have that P as a subset of NP. Why is that? Well, NP is a class of all search problems so these are problems where we can verify solutions in polynomial time. P is a class of search problems that can be solved in polynomial time. A problem in P means that we can verify solutions in polynomial time and we can generate solutions in polynomial time.

NP1 Definitions - 484 - Comparing P and NP
Now, we'll take a look at the formal definition of search problems momentarily. But let's first take a look at the intuitive difference between P and NP. Now, Now roughly roughly, a search problem is a problem where given an input and as proposed solution, we can verify that that solution is in fact a solution in polynomial time where a polynomial in the input size. Now, P are those search problems where we can also generate solutions in polynomial time. Now what is P equals NP or P not equal to NP, what do they mean? Where P or are the class of problems that we can solve in polynomial time. time, NP are those problems where we can verify solution in polynomial time. So what does the P equal NP question mean? What if P equals NP? That means that it is it's as difficult to solve a problem as to verify solution. Think about this in this context of proofs trying to prove a theorem. NP says that if I give you the proof for theorem, then you can check it in polynomial time. That's sort of like going line by line in the proof and checking each line in the proof. Doesn't sound too difficult. Now, what's the analogue for P? While solving a problem, the analogue for a proof is generating the proof of the theorem. So is generating the proof for of the theorem as hard as verifying a proof for theorem? So if I can check the proof line by line, is that as hard as generating the actual proof? It seems much more difficult to generate the proof or generate a solution to a problem than to just verify that a solution or verify that a proof is correct. So if we show that P equals NP, that implies that if I can verify solution in polynomial time, then I can also solve the problem in polynomial time. So whenever I can check a proof, I can also generate a proof for that theorem. For many of us us, it seems much more plausible that P is not equal to NP. Why? Because it seems much easier to verify a solution, to check a proof than to actually solve the problem or to generate the proof for the theorem. Most go through informally defined search problems.

NP1 Definitions - 485 - Search Problems
A search problem is a problem in the following form. First time given an instance I. What is I? I is the input to the problem. For example, it might be a draft if I'm doing a graph problem, or I might be a formula, if I'm doing a problem such as satisfiability. Now, if I has a solution for this problem, then I want to find such a solution. I can output any solution S which is a solution for I. But if I has no solutions, then I simply output NO. So, if this input has a solution, then I output any such solution. If it has no solutions, I output NO. Now, this is the basic form of a search problem, but I have a further requirement in order to be a search problem. Now, let me rephrase this requirement. So, for a particular problem to be a search problem, it first has to be of this form. So, if it's a yes instance so there is a solution to this input, then we have to output some such solution. And if there are no solutions then we simply output NO. Furthermore, we have the following requirement, for an input that has a solution. If I give you a solution, it doesn't have to be the one that's generated by some particular algorithm. I give you any solution that we need to be able to verify in polynomial time, that S, this proposed solution is in fact a solution to this instance. So, we just have to be able to check the proof. So if I give you a proof, then I can check that proof line by line that it is a proof to this input, to this theorem. Now if this input is a NO instance, so there are no solutions, I don't have to do anything in that case. Simply on yes instances, then I have to be able to verify solutions. But I only have to verify solutions when I'm given the solution. So I don't have to generate the solutions at all. Simply, I have to be if I'm given the solution, then I can verify that, that is a solution to the input. And it's important to stress that, what we mean by efficiently verify, we mean in time polynomial in the input size. Now, how would I show that a particular problem is a search problem? Well, I will show you an algorithm which can verify solutions in polynomial time. So I would show you an algorithm which would take as input an instance I, which is an input to the original search problem and a proposed solution to that input. Now given I and S, now what should my algorithm do? Well my algorithm is going to verify that S is in fact a solution to the I, and it's going to do so in time polynomial in the size of I. Typically, it's very easy to show such an algorithm. So let's take a look at a few example problems that we've seen so far in this course and will verify that they are in fact search problems and therefore they are

NP1 Definitions - 486 - SAT Problem
I start with the satisfiability problem. This was one of the original NP complete problems. Therefore, it has some special significance in the theory of NP completeness. Now this is a SAT problem which we defined before when we looked at graph algorithms. And we saw an algorithm for 2-SAT. Now the input of SAT is a Boolean formula f in conjunctive normal form, CNF. And we'll say that f has n variables, x_1 through x_n, and it has m clauses. Now the output is a satisfying assignment if one exists. What does that mean? That means an assignment to the variables, true or false, for each of the variables, so that when we evaluate the formula, it evaluates to true. Now if there is no satisfying assignment, so there's no way to assign true or false to each of the variables, so that the formula evaluates to true. Then we simply output no. Now here's an example input to SAT with three variables and four clauses. So n equals three and m equals four.

NP1 Definitions - 487 - SAT Example Question
Let's make sure you recall the notation for the SAT problem. So once you go ahead and write a satisfying assignment for this formula, so give an assignment for X1, X2 and X3, so that the formula evaluates to TRUE. If there's no such satisfying assignment then go ahead and enter no.

NP1 Definitions - 488 - SAT Example Solution
This particular input has a satisfying assignment. I can set x1 to true, x2 to false, x3 to false. Let's check it. So for the first clause, I have that x2 is false, so this is our satisfied variable. For the second clause, I have that x2 is true, so this is a satisfied literal. For the third clause, I have that x3 is false, so this is a satisfied literal. For the last clause, I have that x3 is false, so this is a satisfied literal. So every clause has at least one literal satisfied.

NP1 Definitions - 489 - SAT in NP Question
Now, we just saw a particular input formula f and we saw satisfying assignment for it. And then we checked that that satisfying assignment was in fact satisfied this formula f. So, when we plugged in that assignment of true and false to the variables, that the formula f evaluated to true. Now, let's look at the general problem. Suppose I give you a formula f and I give you assignment of true or false to each of the variables. Now, what is the running time to verify that this assignment actually evaluates this formula to true? So, this assignment satisfies the formula. As a function of n and m, what is the running time to do that? Why don't you go ahead and write the running time in big O notation.

NP1 Definitions - 490 - SAT in NP Solution
Why do I care about the running time to verify a solution? Well, this is the key step for proving that SAT is in NP. So let's go ahead and formally prove that SAT is in NP, and then as part of that proof, we'll see the answer to this question. So let's go ahead and prove that SAT is in NP. First, I've to check that it's of the correct form. The correct form is that I'll output a solution if one exists, and I'll output no if there is no solution. So clearly, it's of the correct form. Now, here's a slightly non-trivial aspect. I have to show that I can verify solutions in polynomial time. So if I'm given a formula f and assignment of true and false to these variables, then how long does it take me to check that this assignment satisfies this formula? Well, for a particular clause, it takes me order_n time to check that at least one of the literals in that clause is satisfied. Since there are m clauses, it takes me a total of order_n_m time to verify that this assignment satisfies this formula. So that's the solution to the previous quiz. And also, we've just shown that we can verify solutions in polynomial time. Therefore, SAT is a search problem and therefore SAT is in NP. So if I want to prove that a problem such as SAT is in NP, I have to show you, here's an algorithm which verifies solutions in polynomial time. And normally, it's just going to take one or two sentences to show that a particular problem is in NP, that it is a search problem, that we can verify solutions in polynomial time.

NP1 Definitions - 491 - Colorings in NP
Let's look at the k-colorings problem. This is a natural graft problem that many of you've probably seen before but I don't think we've looked at this particular problem in this course yet. You've probably heard of the four-color theorem. This is the formulation of the general problem. Now, the input to the problem is an undirected graph G and an integer K. K is a number of colors in our palette. Now, our goal is to assign colors to the vertices so their neighboring vertices have different colors. So, if there is a proper coloring, we're going to output an assignment of colors to the vertices. So, each vertex is going to get a color between one through K. These are the names of the colors and this is a proper coloring if adjacent vertices get different colors. Now, if this G has no such coloring, then we output no. So, if there is a proper vertex K coloring for this graph G, then we output such a coloring. And if there is no such proper K coloring, then we output no. Now, the K-colorings problem is in NP. Why? Well first off, it's the correct form when there is a solution. When there is a proper coloring, we output such a coloring. And if there is no such coloring, then we simply output no. Now, the non-trivial step is we have to show that we can verify solutions. So, suppose that were given a graph G and were given a K-coloring for this graph. So, we're given assignment of the vertices to each of the one of the K colors. Now, how do we check that this coloring is a proper coloring. Well, we go through the edges of the graph and we check that each edge is not monochromatic. In particular, in order m time which is the number of edges, we can check for every edge that the color assignment for V is different than the color assignment for W. So, for every edge, the two endpoints have different colors. That's it. That's all we have to do to show that the K-colorings problem is in NP. We simply have to show an algorithm which can verify solutions in polynomial time. And it's a trivial algorithm, so it's a simply one sentence proof that the K-colorings problem is in NP.

NP1 Definitions - 492 - MST Question
So recall the MST problem. The input to the problem is an undirected graph G with positive edge lengths, and the output is a tree T with minimum weight. Now let's test your knowledge of P and NP. So the first question is, is the MST problem in NP? Mark whether this statement is true or false. The second question is whether the MST problem is in the class P. Is that statement true or false?

NP1 Definitions - 493 - MST Solution
Well in fact, both statements are true. The MST problem is in the class NP, and the MST problem is in the class P. Let's go ahead and see why both of these are true.

NP1 Definitions - 494 - MST in NP
Let's see why the MST problem lies in the class NP. First off, is the MST problem of the correct form. If there is a solution are we outputting a solution. And if there is no solution, we're outputting no. Well, the way the problem is formulated, we're always outputting a solution. We're always outputting a tree T, which is guaranteed to be a minimum weight. And the way the problem is formulated there always is a solution. We're simply looking for the tree of minimum weight. So there was always a tree of minimal weight, so we're always outputting a solution. There's never in no instance. There's never no tree of minimum weight. Sum tree has to be of minimum weight. So there's always a solution to this problem and we're always outputting a solution. Now, suppose we're given a graph G, which is our input to the MST problem and we're given a tree T, which we claim is a solution to the MST problem. How do we verify that T is in fact a solution to the MST problem for G? Well, first we have to verify that T is a tree. Or we can simply run the BFS or DFS algorithm to check that T is a tree. To check that T connects up the graph G and that T has no cycles. Now, how do we check that T is of minimum weight? Well, we can run Kruskal's or Prim's algorithm, that's going to give it an MST. Then for that given MST that's outputted by Kruskal's or Prim's algorithm, we check its weight and then we check that T has the same weight as that output from Kruskal's or Prim's algorithm. There's no reason why Kruskal's or Prim's algorithm might generate this particular tree T, but they're going to output a MST and we checked the weight of that MST outputted by these algorithms, and then we compare that to the weight of the tree T. And therefore, we can verify that T has minimum weight and that T is a tree. And therefore, T is an MST. It takes us order N plus M time to run BFS or DFS and it takes us o(mlogn) time to run Kruskal's or Prim's algorithm. So the total time of our verification algorithm is o(mlogn). This shows that the MST problem is in NP.

NP1 Definitions - 495 - MST in P
Now, we just saw that the MST problem is an NP. So, we've seen that MST is a search problem. Now, let's prove that MST is in P. And to show that the MST problem is in P, there's two parts. First, we have to show that the MST problem is a search problem. Well, that's what we just did to show that MST is an NP. So we've done that first part. The second part is to show that we can find a solution in polynomial time. How do we find a solution in polynomial time? We simply use Kruskal or Prim's algorithm. This shows the second part. So this completes the proof that MST is NP.

NP1 Definitions - 496 - Knapsack Problem
We've looked so far at the satisfiability problem, SAT, the colorings problem, and MST; minimum spanning tree problem. And we've seen why each of these are in the class NP. Now let's take a look at the knapsack problem which we studied in the dynamic programming section. Let me remind you the formulation of the knapsack problem. Now the input to the knapsack problem are n objects. For each object, were given an integer weigh, and we are given an integer value. The weights are denoted as W to the first and W to the nth, and the values are denoted by V to the first through V to the nth. And in addition, we're given a total capacity for the backpack or knapsack. Now the output for the knapsack problem is a subset of objects which fit in the backpack, so their total weight is at most capital B. And we want to subset which maximizes the total value. Let's make this a little bit more mathematically precise. By total weight and most capital B, we mean that if you sum over the objects in the subset S, their weights sum up at most capital B. Our objective is to maximize the total value. The total value for a subset S is the sum over the objects in the subset of their values. And we're trying to find the subset S which maximizes this sum of the total value, subject to the constraint that the sum of their weights is at most capital B. Now if you recall there were two variants of the knapsack problem that we studied in dynamic programming section. There was the version with repetition. So there was unlimited supply of each object or there was a version without repetition, so we had at most one copy of each object. Now which of these two variants that you consider, it doesn't matter. For the following discussion, it holds for both of these version.

NP1 Definitions - 497 - Knapsack Complexity Question
For the knapsack problem that we just formulated, let's address the following two questions. Knapsack is in the class NP and knapsack is in the class P. For each of these statements, why don't you mark whether it's true or false?

NP1 Definitions - 499 - Solution Knapsack Complexity
Let's first address whether a knapsack problem lies in the class NP or not. In order to lie in the class NP we have to be able to verify solutions. We have to be able to do the following efficiently. We have to take a particular input to the knapsack problem. An input is given by a set of weights, a set of values, and a total capacity to the for the backpack, and we have to take a solution for that input. Now, in polynomial time, can we check whether this solution is in fact correct for this input? In order for S to be a solution for this input, what do we need to check? Well, we have the constraint that the total weight of the objects in this solution is at most B so we have to check that the sum of objects in this subset of the or individual ways is at most B. Or this is quite straightforward to do. We're just summing up at most n numbers so this takes at most order n time. The second thing that we need to check is that this subset is optimal in the following sense, that it maximizes the sum of the values. It's easy to check what the total value is, we just sum up the values, but how do we check that has maximum total value? How do we check that the value of this subset is better or at least as good as any other subset? For the MST problem, we could check that it has optimal value, it had minimum weight tree by running a polynomial time algorithm such as Kruskal's or Prim's. We checked the output of that algorithm and we look at the total weight of the tree produced and we compare that to the weight of the tree that we're considering in our proposed solution. Now, we had an algorithm for the knapsack problem that we looked at and the dynamic programming section. The running time of our dynamic programming algorithm was order n times B. The problem is that this running time is not polynomial time. It's not polynomial in the input size. Recall the input of size at least n to represent these n objects and how big is the representation of this one number B. Well, that takes log B bits. In order to be polynomial in the input size, we need an algorithm which runs in time polynomial in n and log B. So a dynamic programming algorithm which is actually exponential in the input size. We need a way to efficiently check solutions, so we can't run that dynamic programming algorithm because that's exponential time. We have no way of verifying that our proposed solution is optimal that it's a maximum total value. What is our conclusion? Is the knapsack problem in NP or not? Well the final statement is a bit subtle. If you said that true, knapsack is in NP, that is incorrect. We don't know how to show that knapsack is in NP. Now is knapsack not in np? Well we can't prove that at the moment. If we could prove that knapsack is not in NP, that would imply that P is not equal to NP. It could be the case that there is a polynomial time algorithm for the knapsack problem and then we could check this maximisation in polynomial time. What can we say? We can say that if you said knapsack is in NP, that is incorrect and as for a knapsack not being in NP, well, we don't know whether or not that's true. So the best we can say is that, as far as we know right now knapsack is not known to be in the class NP. Similarly, if you ask for the class P, well, as far as we know, knapsack is not known to be in the class P. Could it be that knapsack is in P? Sure it might be. There might be a polynomial time algorithm for knapsack, P might equal NP in which case knapsack will lie in NP, but as of right now, knapsack is not known to be in the class P. There is a simple variant of the knapsack problem, which is in the class NP. Let's take a look at that variant. What we're going to have to do is drop this optimization part and we're going to add in another input parameter. That additional input parameter is going to be our goal for the total value and then we're going to check whether our total value of our subset is at least the goal. Then, we can do binary search on that additional parameter. The goal for the total value. Let's go ahead and formalize that now.

NP1 Definitions - 500 - Knapsack Search
Now, we're going to look at the version of knapsack which is a search problem. Now, the input starts off the same as before. So, we'll have integer weights W1 through Wn, integer values V1 through Vn and a total capacity, capital B. All of these is the same as before for the original knapsack problem, but there's an additional input parameter which is our goal which will denote as little g. Our output is a subset as just as before where the total weight of this subset S is at most capital B. So, if I sum over the objects in the subset of their individual weights that's at most capital B. That's just as before and we look at the total value of this subset. Previously, we were trying to maximize this total value, but now we're going to just check whether this total value meets our goal. How is the immediate goal? Well, we just want that the total value is at least g. We're trying to maximize the total value. So, we wanted to be at least our goal. If we made it at most our goal that would be easy, that would be trivial. We could just output the empty set. And if we do better than our goal that's even better. That's why we make it at least g. But now, what happens if there's no subset which meets our goal? Well, if there's no solution to this problem, so there's no subset which meets this goal, then we simply output "NO". This is the correct form for our search problem. Notice that if we can solve this knapsack search version in polynomial time, then we can solve the original optimization version in polynomial time. How? Well, in the original version we were maximizing this sum of the total value. Here we're simply finding a subset whose total value is at least little g. Now, suppose that we could solve this version in polynomial time. How do we solve the maximization version? Well, we can simply do binary search over this little g and by doing binary search over the little g and we find the maximum little g which has a solution, then that tells us the maximum total value which we can achieve. How many rounds in our binary search are we going to have to run? How many of these knapsacks search version problems are we going to have to run in order to solve the optimization problem? Well, let's look at the sum of these values. Let's let capital V be the sum of all the values. Certainly the max of this total value that we can achieve is at most capital V. So, we're going to do binary search on little g ranging between one and capital V. So, the total number of rounds in our binary search algorithm is going to be at most order log V. What is the size of the input to represent these numbers? Well, it's log V. So, this algorithm, this binary search algorithm is polynomial in the input size. So, we can solve the knapsack search version in polynomial time, then we can solve the optimization version in polynomial time.

NP1 Definitions - 501 - Knapsack Search in NP
Now this new version of the Knapsack problem does lie in the class NP, we can prove that now. So consider a particular input to the Knapsack-search version, we have the integer weights, integer values, total capacity, and our goal, and consider a particular solution. In order to check that this is in fact a solution, what do we need to do? We need to check that the total weight is in most capital B. So how to do that before. That's easy. We're just summing up at most order numbers. And now instead of checking that it has maximum total value, we just have to check that the total value is at least a little g. This again involves just adding up order n numbers. So we can check these two in O(n) time. We can check a proposed solution in polynomial time. Therefore, this version of Knapsack, the Knapsack-search version does in fact lie in the class NP. Now, let me just be a little bit more precise about one aspect which may be confusing some people. You may ask, "Does this really take O(n) time to some of these numbers?" Well, if you really look at it in terms of the magnitude of these numbers, we had capital V as the sum of all values. That's led capital W to note the sum of all weights. Certainly to add up to these numbers, the time required is at most the number of bits. The number of bits in each of these numbers is at most log of capital W. So the time required to compute this sum is the most order n times log of capital W. To compute this sum is the most O(nlogW). Since the input side is log of capital W and log of capital V, this is still polynomial in the input size. So it is correct that Knapsack-search version does lie in the class NP. We just verify-

NP1 Definitions - 502 - NP acronym for
Now, we have these two complexity classes we'll consider so far, P and NP. What are these abbreviations stand for? P Well, P stands for polynomial time. Why? Because this is the class of search problems that can be solved in polynomial time. Now you might think that NP stands for non not polynomial time. That's incorrect. It Is it may be the case that we can solve NP problems in polynomial time as well? It may be the case that P equals NP. We don't know. So what does NP stand for? NP stands for non-deterministic nondeterministic polynomial time. What does non-nondeterministic mean? This is a class of problems that can be solved in polynomial time on a non-nondeterministic machine. That doesn't do much good, I still haven't defined this term non-nondeterministic. By nondeterministic, I mean a machine where I'm allowed to guess at each step and there is a series of guesses. There is a series of choices which leads to an accepting state. If you think of it in terms of a terminal, typically for a terminal, I specify on a particular input, say 1 one. I move from this day to this day day, and maybe on a particular input 0, I moved move from this date day to this other day. But now now, I don't have to specify which particular input I move from this day to this day. I just specify that sometimes, I might move from this day to this day and sometimes, from this day to this day. And for the case I want to terminal, I just need that there is a path in this terminal that goes to an accepting state. So there is a choice of branchings which leads me to an accepting state. I can't really explain it much more than what I just did, because to be honest, I don't understand it much more than that. But the important thing to remember is that NP does not stand for not polynomial time. What it stands for is nondeterministic polynomial time.

NP1 Definitions - 503 - P vs NP
Let's go back and have a somewhat philosophical discussion on the P verses NP question. Recall that NP stands for the class of all search problems. Meanwhile, P is the class of those search problems that can be solved in polynomial time. So, every search problem lies in NP and P are those search problems which can also be solved in polynomial time. So P has an extra restriction. So P is a subset of NP. So if we look at it graphically, we have this class of problems in P, and then we have this class NP which is a superset of P. Now, we have some examples of problems which lie in P. For example, the MST problem that lies in P and it lies in NP. We just saw that the search version of knapsack problem lies in NP. We saw that the satisfiability problem lies in NP. We saw that the colorings problems lies in NP. Now, is there a separation here? Are there problems which lie in NP but do not lie in P? We don't know whether that's the case. It may be that all these problems in this band actually lie in P. That these two classes are the same. P equals NP or may be the case that there are problems which lie in NP which do not lie in P. That means that P is not equal to NP, and there are some problems that we can not solve in polynomial time.

NP1 Definitions - 504 - NP-Completeness
I suppose that P is not equal to NP. Now looking at our diagram from before, that means that this donor, this separation between P and NP is non-empty. Therefore there are some such problems which can't be solved in polynomial time. They don't lie in the class P. What are the hard problems that lie in this donor? These intractable problems, these problems that we can't solve in polynomial time. The answer is NP complete problems. Now there may be other problems that lie in this class NP which do not lie in P. So they lie in this Donor but NP-complete problems are guaranteed to lie in this donor if it exists. NP complete problems are the hardest problems in the class NP. Let me repeat that because it's very key. NP complete problems are the hardest in the class NP. Now, what exactly do we mean by the hardest in the class? We mean that if P is not equal to NP then the following holds. Then all the NP complete problems are not in the class P. So all NP complete problems cannot be solved in polynomial time if P is not equal to NP. So if P is not equal to NP, this donor is non-empty. There are some problems in NP which don't lie in P, so we can't solve them in polynomial time. And what does NP complete mean? Well, these are the hardest in the class NP, so you can think of them as sort of as the outer layer of this donor. This outer layer are the NP complete problems. If there is some separation between these sets, then these NP complete problems are guaranteed to be in the difference. Now let's look at this statement more carefully. An equivalent statement is the contra-positive of it. Now what's the complement of all NP complete problems are not in P, where the compliment is that there exists in NP complete problem in P. In other words a NP complete problem can be solved in polynomial time. So, the complement of this conclusion that all NP complete problems are not in the class P is that there exists NP complete problem that can be solved in polynomial time. If this holds, then the complement of the hypothesis holds. The complement of the hypothesis is that P equals NP. If P equals NP, that means that all problems in the class NP can be solved in polynomial time. An equivalent statement to this one is that if there exists an NP complete problem that can be solved in polynomial time, then all problems in NP can be solved in polynomial time. Hence to show that a problem such as set lies in this and the complete portion of the donut. We have to show that if there is a polynomial time algorithm for set then there is a polynomial time algorithm for all problems in the class NP. We have to show that if there is an algorithm for set which works in polynomial time, we can use it as the black box to solve all problems NP in polynomial time. To do that, we're going to take every problem in the class NP. Now, there are many problems in this class. I've just marked a few of them but we have to take all such problems. So we take all such problems and we have to show that each of these such problems have a reduction to set. If we can solve set in polynomial time, we can solve every such problem in the class NP in polynomial time. Let's look at this more precisely on the next two slides.

NP1 Definitions - 505 - SAT is NP-Complete
What precisely does it mean for a problem to be NP complete? Let's define it now and let's use SAT as our example. So what does it mean for SAT to be NP complete? SAT is NP complete means the following. First off, we need that SAT lies in the class NP. So if we think as a class of problems that lie in NP, then the first requirement is that SAT lies in this class NP. So we have checked that for the SAT problem, we can efficiently verify solutions. And we've seen how to do that before. We saw how to prove that SAT lies in the class NP. Now the second requirement, is that SAT is the hardest problem in this class. What exactly do we mean by that? Well, we're looking at these problems in terms of whether we can efficiently solve them or not. So for SAT to be the hardest in this class, we mean that it's the least likely to have an efficient solution. What's another way of saying that it's the least likely to have an efficient solution? Is that, if we have an efficient solution for SAT, then we have an efficient solution for every other problem in NP. So let us write this down. So if we can solve SAT in polynomial time then we can solve every problem in NP in polynomial time. What does this mean? This means for every problem in NP, for example MST problem, colorings problem, there are other problems such as the TSP Traveling Salesman Problem, there's the independent set problem which we'll see shortly. For all these problems in NP, there is a reduction or transformation to the SAT problem. So we can take an input for the MST problem and we can transform it to an input to the SAT problem. And then if we have an algorithm which efficiently solves SAT, so it solves a SAT problem in polynomial time, then we can use that algorithm to solve MST. How? We take an input for the MST problem, we reduce it to an input for the SAT problem, and then we run our algorithm on the SAT problem and that gives us an output, a solution to the MST problem. And we can reduce all the problems in NP to SAT. Therefore, if we have an algorithm to solve SAT in polynomial time, we get an algorithm for all of the problems in NP. Now the point is that if P is not equal to NP, then we know that there are some problems in NP which cannot be solved in polynomial time. And therefore, we can't solve SAT in polynomial time because if we could solve SAT in polynomial time, then we can solve all of the problems in NP in polynomial time. Since there are some problems in NP that we can't solve in polynomial time under the assumption that P is not equal to NP, then therefore SAT is not in polynomial time. So SAT is not in the class P. So this means that SAT is the computationally most difficult problem in the class NP. So if you believe that P is not equal to NP, then there is no polynomial time algorithm for SAT. Or alternatively, if you believe that nobody knows how to prove that P equals NP, then nobody knows a polynomial time algorithm for SAT. So it's a reasonably fair assumption that as of right now there is no polynomial time algorithm for SAT. Why? Because if somebody had a polynomial time algorithm for SAT, then they could prove that P equals NP. And if they can prove that P equals NP, they could get a fair bit of money from some mathematical prizes, and they get some fame from proving that P equals NP. They get a Fields Medal and so on. Now let's formalize this a bit more. We know how to do this step. We know how to prove that SAT lies in the class NP. But how do we do this step? How do we prove that if there is a polynomial time algorithm for SAT, then there is a polynomial time algorithm for every problem in NP? So what we're going to do now is formalize this notion of a reduction. We want to show a reduction from problems such as MST and colorings to the SAT problem. What exactly do we mean by reducing this colorings problem to the SAT problem?

NP1 Definitions - 506 - Reductions
Now, let's consider problems A and B, and I want to show a reduction from A to B. And I want us to see what exactly that means. Now, as an example, we can think of A, problem A as the colorings problem, and problem B as the satisfiability problem. Now, this is a notation that we're going to use for a reduction. This is the same notation that's used in the Dasgupta textbook. Now, an alternative notation for reduction is that A is at most B. What does this notation mean? It means that when we show a reduction from A to B, we're showing that B is at least as hard computationally as A, because if we can solve B then we can solve A. Now, if we're trying to devise an algorithm, it'll be easier to devise an algorithm for A. Why? Because if we devise an algorithm for B, then not only do we solve B, but we also solve A. Whereas if we solve A, we may just solve A. We may not necessarily solve B at the same time. Now, let's formalize what exactly we mean by a reduction. So, a reduction from A to B means the following. So, verbally, this notation means reducing A to B. Formerly, this means that if we have an algorithm which solves problem B in polynomial time, so in this case, the SAT problem, then we can use that algorithm for problem B. So, in this case the SAT algorithm, we can use it to solve A in polynomial time. So, a reduction from the colorings problem to the SAT problem means that, if we have an algorithm to solve satisfiability in polynomial time, then we can use that algorithm to solve the colorings problem in polynomial time. Okay, let's dive into this and see how we actually show a reduction. How do we show a reduction from colorings to satisfiability?

NP1 Definitions - 507 - How to do a Reduction
Now, let's suppose I want to show a reduction from colorings to SAT. How do I do it. Well if we reduce coloring to SAT, what we're showing is that, if there is a polynomial time algorithm for SAT, then we can use it to get a polynomial time algorithm for colorings. So what do we do. We suppose that there is a polynomial time algorithm for SAT. And we're going to treat this algorithm like a black box. What does it mean to treat this algorithm as a black box. Well we don't know how the algorithm works, but we can use this as a basic subroutine. We can put in some input for SAT and we can get out some output and it takes polynomial time for that algorithm to run. And we're going to use this black box algorithm, as a subroutine to get a polynomial time algorithm for colorings problem. So let's look at it pictorially. So here's our black box algorithm for SAT. We can give it some input and it produces some output. Either it gives us a solution, or it outputs no, if there's no solution for that particular input. Now, we want to use this black box algorithm or subroutine for satisfiability problem and we want to use it to construct an algorithm for the colorings problem. So this red box denotes our subroutine for the colorings problem. So the input to our colorings problem, is a particular I, which in this case is a graph and a number of colors K. Now, what we need to do, is define a transformation f. We have to show how to transform this input to the colorings problem and produce an input to the satisfiability problem. So we have to change this graph and there's number of colors into a boolean formula. Then we plug that boolean formula into our set solver and our set solver either gives us a solution, in this case it's an assignment, which satisfies this formula or it outputs no, there's no solution for this input. Now, we have to transform this solution into a solution to the original colorings input. So we have defined another transformation which we denote is H.This H takes as input, a solution to our SAT input and it transforms it to get a solution to our original colorings instance. So if S is a solution to f(I), then h(s) is the solution to I. And if our SAT input had no solution, then we'll say that our colorings input had no solution. So if we get out no we output no.

NP1 Definitions - 508 - More on Reductions
To reduce colorings to SAT, what do we need to show? We need to find these two functions, f and h. f takes an input for the colorings problem and produces an input for the SAT problem. If you think of the input for the colorings problem as a graph and a number of colors, so it's a G and a k, then there are input for the SAT problem is f of Gk. Now, h takes a solution to this SAT problem o this f of Gk is a Boolean formula. It's going to take an assignment, a satisfying assignment for this boolean formula and it's going to produce a solution to the original colorings problem on Gk. So it's going to take an assignment which satisfies this boolean formula and it's going to produce h of S which is a colorings for this graph using k colors. We need to define these two functions f, which transforms inputs to colorings to inputs to SAT and h, which transform solutions to SAT into solutions for two colorings. Now, what do we need to prove in order to prove that this reduction is valid. Well, we need to prove that, if S was a solution to f, then h of S is a solution to the original G. But we also need that if there was no solution to f, then there is no solution to the colorings problem. So we need to show that if S was a solution to this SAT input, then h of S is a solution to this colorings input and vice versa. We need to show this equivalence, this if and only if statement because we need to know that the solutions here map to solutions here and no instances here are mapped to no instance here. We need both directions. We need solutions here if and only if solutions here.

NP1 Definitions - 509 - NP-Completeness Proof
Now let's go back and see how we show that a particular problem is NP complete. Later we're going to consider this problem, independent sets problem, and we're going to prove that the independent sets problem is NP complete. Now the details of the independent sets problem is not important at this point. But, what exactly do we need to show in order to show that independent sets problem is NP complete? We need to show the following. I'm a bit lazy, so let me denote independent sets problem by IS. First, we need to show that the Independent sets problem is in the class NP, that we know how to do. We need to show that we can verify solutions in polynomial time. The second thing we need to show, is that if we can solve independent sets problem in polynomial time, then we can solve every problem in NP in polynomial time. Now the second thing we need to show, is that for every problem A in the class NP, there is a reduction from A to the problem independent sets. That means that if we have a polynomial time algorithm for the independent sets problem, then we can use that as a subroutine to solve the problem A in polynomial time. And since we can do this for every problem A in the class NP, then if there is a polynomial time algorithm for the independent sets problem, then there is a polynomial time algorithm for every problem in NP. But how can we do this second step? We need to take every problem in NP, and show reduction from every problem in NP to the independent sets problem.

NP1 Definitions - 510 - Simpler Proof Approach
Now, suppose that we know that the SAT problem is NP-complete. Now, in fact, we do know this. What exactly does this mean? This means that SAT lies in the class NP. And, in addition, it means that, for all problems A, in the class NP we know reduction from A to the SAT problem. Now, suppose we show that the SAT problem reduces to the independent sets problem. Then, what do we know? We know that every problem A and NP reduces to SAT. So a reduces to SAT, and SAT reduces to the independent set problem. So, by just composing these reductions or composing these functions, we have a reduction from A to independent sets problem. And this holds for every A and NP. Therefore, for every A and NP, we have a reduction from A to the independent sets problem. If we have a known NP-complete problem such as SAT, then to show that the independent sets problem is NP-complete, we just have to show that the independent sets problem lies in the class NP, and that there is a reduction from SAT to independent sets. To recap, to show that the independent sets problem is NP complete, we need to show the following. The independent sets problem lies in the class NP, that's easy to do, and we have to take a known NP-complete problem such as satisfiability and we have to show how to reduce satisfiability to the independent sets problem. We have to take the known NP-complete problem and reduce it to our new NP-complete problem. Since every problem A and NP reduces to SAT because SAT is NP-complete, and we just showed this reduction from SAT to independent sets problem. therefore, we know how to take every problem A and NP and reduce it to the independent sets problem and we can start from any known NP-complete problem. At the beginning, we'll start with SAT and we'll build up our repertoire of NP-complete problems and then we can take any of these known NP-complete problems and reduce it to our new problem, which we're trying to show as NP-complete. Now, it sounds much more tangible. To prove that a problem such as independence problem is NP-complete, we have to just show that we can verify solutions in polynomial time. That's the first step and then we have to take a known and complete problem and reduce it to this new problem. Now, the second step is what confuses students many times. Often, they'll show the reduction in the other direction. That's not really proving anything. We already know that every problem in NP can be reduced to this known NP-complete problem. And even if they marked it this way, that they're trying to do a reduction from set independent sets, actually, in the proof, they actually do the reduction the other way. It's meaningless if you do the reduction in the other way. So this is the difficult part for students sometimes. You have to make sure that you're doing a reduction from the known NP-complete problem to this new problem that you're trying to show as NP-complete because you want to show that you can reduce every problem and NP to this new problem in order to prove that this new problem is computationally difficult. It's NP-complete. So next, we're going to dive in and we're going to prove some problems such as independent set problem are, in fact, NP-complete.

NP1 Definitions - 511 - Practice Problems
Now, at this point, you should understand the notions of the class P and the class NP and the notion of reductions. Now, we're going to see a lot of examples of proofs that a problem is NP complete. So I don't expect you to be comfortable with that at this point. But just based on these definitions, there are a few practice problems you can try from the textbook. The first two problems in Chapter 8 of the textbook, Dasgupta, Papadimitriou, and Vazirani, are relevant at this point. The first problem looks at reductions between optimization problems and search problems, and the second problem looks at reduction between search problems and decision problems. Now, in the next lecture, we're going to do our first NP completeness proof. We're going to prove that three set is NP complete using the fact that set is NP.

NP2 3SAT - 512 - NP-Completeness
Our plan now is to prove that the 3SAT problem is NP-complete. What we just saw is that if we have a problem such as SAT, which is known to be NP-complete, then this makes our task much easier. So, we're going to use the fact that SAT is NP-complete. This is known as a Cook-Levin-Theorem. It was proved independently in 1971 by Steven Cook and Leonid Levin. And they proved that SAT is NP-complete. Now, we're going to take this theorem for granted. And later, I'll give you some high-level idea of the proof that the SAT problem is NP-complete. Now, after Steven Cook published his paper, then the importance of NP-completeness was highlighted by a paper by Dick Karp in 1972. He showed 21 other problems which were NP-complete. We're going to look at a few of these 21 in the next few lectures. We'll start with 3SAT, which was one of the 21

NP2 3SAT - 513 - 3SAT
Let me give you a quick reminder of the formulation of the 3SAT problem. So the input to the 3SAT problem is a boolean formula f in conjunctive normal form and we use n for the number of variables and m for the number of clauses in the formula f. Now the extra restriction in 3SAT as opposed to SAT is that we assume this formula f has the following constraint. Each clause has at most three literals. Now the output for the 3SAT problem is a satisfying assignment if one exists. This is an assignment of true and false to the n variables, so that the formula f evaluates to true. Now if there's no satisfying assignment, we simply output-

NP2 3SAT - 514 - Proof Outline
We're going to show now that 3SAT problem is NP complete. Before we dive into the proof, let's outline what we need to show in order to establish that the 3SAT problem is NP complete. The first thing we need to show is that the 3SAT problem lies in the class NP. This will be straightforward to prove. Now our main task is to take a known NP complete problem. In this case, all we know is that SAT is NP complete. So we have to just show a reduction from SAT problem, to the 3SAT problem. Now once we've shown this reduction from SAT to 3SAT, what does that establish? That establishes that for every problem in NP, we have a reduction from this problem A to SAT. And then we have this reduction from SAT to 3SAT, therefore, we have a reduction from A to 3SAT. The implication of this is, that if we have a polynomial time algorithm for 3SAT, then we have a polynomial time algorithm for every problem in NP, because we can reduce every problem in NP to 3SAT. So let's start with the easy task. Let's prove that 3SAT is in the class N-

NP2 3SAT - 515 - 3SAT in NP
Now to prove that 3SAT is in the class ϵNP, we have to show that we can verify solutions efficiently. So, let's take a particular input for the 3SAT problem. So f is our input for the 3SAT problem. And let's take a proposed solution. So this is a true false assignment for the n variables. Now we need to check that this assignment is a satisfying assignment for this formula. Now, how are we going to verify that this assignment is a satisfying assignment? Well, we're going to go through the clauses. So let's take each clause. For a particular clause C, you will take us order one time to check that at least one of the literals in C is satisfied. Why is it order one time? Because each clause has at most three literals. Now if every clause C is satisfied, then the formula f is satisfied. It takes order one time per clause, there's M clauses, so it takes order M total time to verify that this assignment satisfies the formula. So this proves that the 3SAT problem is in the class ϵNP.

NP2 3SAT - 516 - SAT 3SAT
Now let's look at the task of reducing SAT to 3SAT. Let's outline first what we need to prove. Now, we're assuming we have an algorithm a polynomial time algorithm for the 3SAT problem, and we're going to use this as a black box. And we're going to construct an algorithm for the SAT problem, using this 3SAT algorithm as a subroutine. So what do we need to do? We need to take an input for the SAT problem. So we have an f, which is an input formula for the SAT problem, then we have to transform this input f into an input for the 3SAT problem. We'll use f prime to denote the input to 3SAT problem. Now this is a bit tricky to do. Why? Because f might have some big clauses. It might have some clauses which contain maybe n literals. But our input for 3SAT has to have clauses of size and most three. So somehow we have to transform these big clauses, into a series of small clauses. And we need to do it in such a way that if we have a satisfying assignment sigma prime, which is a satisfying assignment for f prime, our 3SAT formula, then we can transform this satisfying assignment for the 3SAT input into a satisfying assignment sigma for the original SAT input. Moreover, we want that if our 3SAT formula, f prime has no satisfying assignments. So there's no Sigma prime. So the algorithm is going to output No, we want that our original SAT formula f also has no satisfying assignment. So you want that f prime has no satisfying assignment, if and only if f has no satisfying assignment. And that way we can simply output No, in both cases. So once again what do we need to do? We need to take an input f, for the SAT problem, and we need to create an input for the 3SAT problem, and then given a satisfying assignment sequence prime for the 3SAT input, we need to transform it and make a satisfying assignment, for the SAT formula. And we need that Sigma prime satisfies f prime. So this is a satisfying assignment for f prime the 3SAT input, if and only if, this transformed output sigma, is a satisfying assignment for our original set formula. So we have a satisfying assignment for the 3SAT input if and only if we have a satisfying assignment for the SAT formula. Why do we need this equivalence? Because we need that No instances for the 3SAT formula, correspond to no instances for the SAT formula. So if we get a No output, we can output a No, for the SAT input. Now this is the main test, so let's dive into it. We want to take an input f for the SAT problem, and transform it into a valid input for the 3SAT problem.

NP2 3SAT - 517 - Example
Let's try to get some idea for the reduction. So let's take a sample input for the SAT problem. So here's a formula with four variables and three clauses. Let's label the clauses as C1, C2, and C3. Now, let's define our input for the three set problem, let's denote this as f prime, where clause 1 and clause 3 we can keep the same. Those are valid inputs. Those are valid clauses for a three set. Now, the challenge is what do we do with the second clause. This is a clause of size four, but valid inputs with three set has size at most three. So what are we going to do for this second clause. Well, we're going to create a new variable y and we're going to replace the second clause by the following pair of clauses. So it's x2 bar or x3 or y. These are the first two literals in C2 and the second clause is y bar or x1 bar or x4 bar. These are the last two literals in the clause C2. Now, the key claim is that this original clause C2 of size four is satisfiable if and only if this new pair of clauses is satisfiable. So C2 is satisfiable if and only if C2 prime is satisfiable. Therefore, replacing C2 by this pair of clauses makes an equivalent formula. And in this new formula, all the clauses have size-

NP2 3SAT - 518 - Claim Forward
Now, let's go ahead and prove this claim, so that we have some idea how to generalize this construction. Here's our original clause of size 4 and here's our new pair of clauses each of size, the most three. And we want to prove that this original clause C_2 is satisfiable, if and only if this new pair of clauses C'_2 is satisfiable. Let's do the forward direction first. Let's take a satisfying assignment for C_2. This is an assignment for x_2, x_3, x_1 and x_4, which satisfies this clause and we want to show that there is a satisfying assignment for C_2 prime. Now in order for this assignment to satisfy C_2, one of the four cases must hold. Either x_2 equals false, x_3 equals true, x_1 equals false or x_4 equals false. Maybe some combination of those hold, but at least one of those has to hold. We'll break up these four cases into the following pair of cases. We'll consider whether x_2 equals false or x_3 equals true. These are the pair of literals which appear in the first clause of C'_2 and the other case is if x_1 equals false or x_4 equals false. This is the pair of literals which appear in the second clause of C'_2. Now if x_2 equals false or x_3 equals true, then we're going to set y to be false. Notice in this case, we have x_2 is false or x_3 is true. Therefore, the first clause is satisfied and we're setting Y to be false. So this satisfies the second clause. C_2 prime is satisfied in this case. Similarly in the second case, if x_1 is false or x_4 is false, then we set y to be true. In this case, since y is true, this satisfies the first clause. And since x_1 is false or x_4 is false this satisfies the second clause. And given a satisfying assignment for C_2, we've constructed a satisfying assignment for C'_2.

NP2 3SAT - 519 - Claim Reverse
Now let's look at the reverse implication. In this case we're going to take a satisfying assignment for C to the second prime and we're going to construct a satisfying assignment for C to the second. What we're going to show is that if we just ignore y, whatever the assignment was for x to the first, x to the second, x to the third, and x to the fourth which satisfied C to the second prime, that's going to satisfy C to the second. Now there will be two cases, either y is true or y is false. Suppose y is true. We know that C to the second prime is satisfied, so each of these two clauses is satisfied. y is true so that satisfies this clause. How about the second clause? Well, either x to the first must be false or x to the fourth must be false. Well, if x to the first is false or x to the fourth is false, both of these satisfy C to the second. So in either of these scenarios, we have an assignment which satisfies C to the second. Now suppose y is false. So this assignment for y satisfies this second clause. How do we satisfy this first clause? What we're assuming that this is a satisfying assignment for C to the second prime so it must satisfy this first clause. y is false, so that's not helping. So it must be the case that either x to the second is false or x to the third is true. So either x to the second is false or x to the third is true. Now if x to the second is false, that means that this is an assignment which satisfies C to the second and if x to the third is true, then also this is an assignment which satisfies C to the second. So in any of these four cases, we have an assignment which satisfies C to the second. So every satisfying assignment for C to the second prime if we ignore y, it's also a satisfying assignment for C to the second. And this establishes the reverse implication. We've done both directions, so we've shown the if and only if.

NP2 3SAT - 520 - Quiz 5-SAT 3-SAT Question
Now, we just saw how to transform a clause of size 4 into a pair of clauses of size 3. Now, let's try to generalize this idea. Let's do it one step at a time. So let's take a clause of size 5 now, and let's try to transform this into a triple of clauses of size 3. Now, previously, to transform the clauses size 4 into a pair of clauses of size 3, we added one new variable y. Now, to transform a clause of size 5 into triple clauses of size 3, we're going to create two new variables, y and z. Now, we're going to make a formula, C prime, which is three clauses, and each of these clauses is going to be of size and most 3. Actually, they're going to be a size equal to 3. And we want to do this in such a way that C is satisfiable. The original clause C is satisfiable, if and only if this triple of clauses, C prime, is satisfiable. And, therefore, in our original input F, if we have a clause such as this, we can replace it by this triple of clauses, and we'll get an equivalent formula. Now, the quiz is to define C prime. Define this triple of clauses, each is of size exactly three literals, and use this pair of new variables, y and z. For simplicity, for entering your solution, let me enter the or symbols for you. And also to simplify your input, let's relabel these literals. So let's relabel these five literals as a, b, c, d, e. So a is equal to X2 bar, b is equal to X3, c is equal to X1 bar, d is equal to X4 bar, e is equal to X5. So use a, b, c, d, e, and y and z, and create a formula, C prime, such that C Prim is satisfiable, if and only if C is satisfiable.

NP2 3SAT - 521 - Quiz 5-SAT 3-SAT Solution
The solution is the following. I take the first two literals, X_2_bar or X_3 or Y, the new variable. That's the first clause. The second clause is the following, I take y_bar or X_1_bar, the third literal or Z. The last clause is Z_bar or X_4_bar, the fourth literal, or X_5, the fifth literal. Instead of formally proving this now, let me give you a quick idea of the proof and then we'll do the general construction and then we'll prove the general construction is correct. Let's suppose that we have a satisfying assignment for C and let's see how we construct a satisfying assignment for C_prime. So, one of these five literals must be satisfied. Let's suppose the middle one, X_1_bar is satisfied, so X_1 is set to false, so that's going to satisfy the second clause. How do we satisfy the first and third clause? Well, here we use these auxiliary variables, setting Y to true satisfies the first clause and setting Z to false satisfies the last clause. And in general, one of these five is going to be satisfied, that's going to satisfy one of these three clauses. And then we can use these other two auxiliary variables to satisfy the other two clauses. How about the reverse implication? Suppose we have a satisfying of assignment for _prime, how do we get a satisfying assignment for C? Well, take the case where Y is false, so this literal is not satisfied so, one of these two literals must be satisfied. If one of these two literals is satisfied, they're satisfied here as well, so C is satisfied. Now, suppose that Z is set to true, then this literal Z_bar is not satisfied. So, one of these two literals must be satisfied, either X_4 is set to false or X_5 is set to true, in which case, one of these last two literals of C is satisfied. The last case is a complement of these two. Y is set to true and Z is set to false. Well, since we're taking a satisfying assignment for C_prime, look at how this second clause can be satisfied. Y is set to true and Z is set to false so these two literals are not satisfied. So the only way to satisfy this clause is to set X_1 to false. So if X_1 is set to false, then we satisfy this third literal in C. Now, let's do the general construction. Let's say we have a clause of size K. Now we're going to create a series of clauses which is equivalent to this original clause. Now when we had a clause of size four, we added one new variable and we had a pair of clauses. When we had a clause of size five, we created two new variables and then we have a triple of clauses. Now, if we have a clause of size K, we're going to create a K minus three new variables and we're going to create K minus two clauses. So, let's go ahead and do the general construction.

NP2 3SAT - 522 - Big Clauses
Let's consider now a general clause of size k, and let's label the literals in this clause by a1, a2 up to ak. Now, for this clause, we're going to create k-3 new variables. Recall that when k was 4, we created one new variable, when k was 5, we created two new variables. In general, we're going to create k-3 new variables. Let's label these new variables as Y1 through Yk-3. Now it's important to note that every clause of size greater than 3 creates new variables, and these new variables are distinct for each clause. So, for each clause, we might create order n new variables. There's m clauses so we might have order, n times m new variables in total. Now we're going to replace this original clause C, by the following k-2 clauses. So we take the first two literals, a1, a2, and the first new variable Y1, and the first clause is a1 or a2 or Y1 and we use the negative of the first new variable, the third literal a3, and then the positive of the next new variable. And this gives us our pattern. So, we then use Y2_bar, the negative of the second variable, and then we use the next literal, a4, and then we use the next new variable, positive form, Y3. Now we continue this pattern, and then the last two clauses look as follows. So the penultimate clause looks as follows. It's going to have Yk-4_bar, or ak-2, this is the third to last literal, or Yk-3 is the last new variable in the positive form. This penultimate clause follows the same pattern. The last clause is going to be slightly different. It has Yk-3_bar, same pattern as before and then we use the last two literals of C. So we have ak-1, or ak. This defines a formula C_prime. Now our claim is that the original clause C is satisfiable, if and only if this new sequence of clauses, C_prime is satisfiable. Now, for our original input to the SAT problem, for every clause, which is size bigger than three, we can replace it under this following construction. We take this clause, which is size bigger than three. We replace it by this sequence of clauses which are all of size exactly equal to three, and then we get a valid input to the three set formula and the key is that this new formula is satisfiable, if and only if the original formula is satisfiable, within the equivalent formula. So let's go ahead and prove this claim, that C satisfiable if and only if C_prime is satisfiable, and then we'll be pretty much done with the reduc-

NP2 3SAT - 523 - General Claim Forward
This was our construction, we took this clause of size k. So we took C which was a₁ or a₂ up to aₖ and we defined this formula C prime, which consisted of K-2 clauses. And our claim is that C is satisfiable if and only if C prime is satisfiable. Now, let's prove this claim. Let's start with the forward implication. So, let's take an assignment to these literals which satisfies this clause C and let's prove that there is a satisfying assignment to C prime. Now, in order for this assignment to satisfy C, one of these literals must be satisfied. Let's let ai be the first satisfied literal. So, let ai be the first literal satisfied. Now, if ai is satisfied that's going to satisfy one of these clauses. i = 1 so, a1 that's in the first clause and if i is at least two, then ai appears in the i minus first clause. So, this literal ai being set to true satisfies the i minus first clause of C prime. Let's suppose i was four. So, we have a four equals to true and this clause is satisfied, so we can remove them. Now, what about the i minus two earlier clauses? Well, we can use these positive forms of these auxiliary variables to satisfy these earlier clauses. So, we set y one in y two to be true in this case and in general we set y one through yi - 2 to true and this satisfies the first i minus two clauses of C prime. So, this setting of the first i - 2 auxiliary variables satisfies the first i - 2 clauses, ai set to true satisfies the i - 2 first clause. What do we do about the later clauses? Well, here we're going to use the negative form of these auxiliary variables. We set the remaining auxiliary variables to false. In this case yk minus four bar and yk minus three bar and in general we set yi - 1 through yk - 2 to false and this satisfies the remaining clauses which appear after the i minus first clause. The punchline is that this literal satisfies the i minus first clause of C prime. We use these auxiliary variables to satisfy the earlier clauses and we use these auxiliary variables to satisfy the later clauses. So, we only need one literal of C to be satisfied, and then we can use the auxiliary variables to satisfy all the other clauses of C prime. Now, let's do the reverse implication.

NP2 3SAT - 524 - General Claim Reverse
Now let's prove the reverse implication. So let's take an assignment to these original K literals and these auxiliary, K minus three variables which satisfy C prime. Let's prove that there is a satisfying assignment for C. What we'll do is we'll just ignore these auxiliary variables and we'll prove that these are settings where these original K literals, satisfies the original clause. Now in order to satisfy this clause C, we just need to show that at least one of these literals is set to true. Let's suppose that's not the case. Suppose all of these K literals are set to false. Under this assumption, is it possible to satisfy C prime? We'll show it's not possible. Now we're supposing we have an assignment which satisfy C prime. So it satisfies all of these clauses. Let's look at the first clause. Now we're supposing that a1 and a2 are set to false. So the first two literals are not satisfied. So the third literal must be satisfied. That means Y1 must be set to true. That's the only way to satisfy this clause, under this assumption. Similarly, let's look at the second clause. What we're seeing Y1 is true. So this literal is not satisfied. Also a3, we're assuming is set to false. So this literal is not satisfied. So, we better satisfied this third literal, Y2. So, Y2 has to be set to true. Continuing in on, look at the penultimate clause. In order to satisfy this penultimate clause, we have to satisfy this literal. So, we have to set Yk-3 to be true. Now look at the last clause, where Yk-3 is set to true. So this literal is not satisfied. Similarly, these last two literals are not satisfied because they're set to false. So this clause is not satisfied. That means that C prime is not satisfied. That's a contradiction. We were assuming that this was assignment which satisfied C prime. So that means, that this assumption that all of these literals are set to false, is not true. So at least one of them must be set to true and therefore that literal satisfies this clause C. So if we just ignore the assignment to these auxiliary variables, then the setting for the original literals satisfies this original clause.

NP2 3SAT - 525 - SAT 3SAT
Now we can formalize our reduction from SAT to 3SAT. So let's consider our input formula for the satisfiability problem. And let's create an input formula for the 3SAT problem, by the following procedure. Let's consider the clauses of f one by one. So, for clause C in f, we'll have two cases depending on whether the clauses of size are most three, or strictly bigger than three. If C contains at most three literals, then we can add this clause as is to this new formula. Now what if C contains more than three literals? Then we have to use our previous construction. In this case, we create k-3 new variables as we said before, and we replace C by this new formula C prime, this sequence of k-2 clauses, as we defined before. So, small clauses stay the same, big clauses are replaced by k-2 new clauses, as we defined before. Now that we've defined the input to the 3SAT problem, now we have to prove that this original input to the SAT problem is satisfiable, f is satisfiable if and only if its input to the 3SAT formula f prime, is satisfiable. So f is satisfiable, if and only if f prime is satisfiable. Now this statement is quite straightforward to prove, given that we've already proven that C is satisfiable, if and only if C prime is satisfiable. Then afterwards, the remaining task is to show that given a satisfying assignment to f prime, we can construct a satisfying assignment to f. That again will be straightforward, because we just ignore these auxiliary variables and the setting for the original variables will give us a satisfying assignment to the original form-

NP2 3SAT - 526 - Correctness
Let's prove this equivalence and hopefully it seems obvious given what we've shown so far. So let's start with the forward implication So let's take an assignment to the original n variables which satisfies the original formula f. Now we want to show that keeping this assignment the same for these original n variables there is an assignment to the new variables so that this new formula f prime is satisfied. Now since we're keeping the assignment for these n variables the same and the new variables are as distinct for each new clause. Therefore, we can look at it a clause by clause. So let's look at clause C in the original formula f. If C has at most three literals then it's obvious. If C is bigger than size three then we replace C by this sequence of K minus two clauses called C prime. Now the key is that C prime uses K minus three new variables. These variables only appear in C prime for C. They don't appear in any other sequence of clauses. So the new variables for C are distinct from the new variables for any other clause. So we can set these variables however you want with respect to C and this won't affect any other clauses. And what we saw before is that there is an assignment to these K minus three new variables so that this new formulas C prime is satisfied. In particular, we took the first literal was satisfied in C, call it Ai and then we set the first Ai minus 2 new variables to true and the remaining new variables to false. And we show that that satisfied C prime. Now let's look at the reversed implication. Let's take a satisfying assignment for f prime. And we want to ignore the assignment for the new variables and show that this assignment for the original n variable satisfies f. Consider a sequence of clauses corresponding to sum C prime in f. What we saw before is that at least one of the literals in the original clause C must be satisfied. If all of these literals in the original clause were set to false then there would be no way to satisfy this sequence of clauses C prime. So therefore we can ignore the setting on the new variables and just looking at the setting on the original n variables. That's going to satisfy each of the clauses in the original formula f.

NP2 3SAT - 527 - Satisfying Assignment
Now going back to our earlier reduction, we showed how to take input formula for SAT and transform it into an input formula for 3SAT. This was the reduction for creating f prime. And then we just proved that the original formula f is satisfiable if and only if this new formula, f prime is satisfiable. Now, what remains? While we run our 3SAT algorithm, our black box algorithm on f prime, if it produces no, that there is no satisfying assignment, then we say no, there is no satisfying assignment for f. What if it produces a satisfying assignment? So suppose it gives us a satisfying assignments Sigma prime which satisfies f prime. Well, we have to produce a satisfying assignment for f. How do we transform this satisfying assignment, Sigma prime, to a satisfying assignment for f? What we just saw from this proof is that if we ignore the assignment for the new variables and keep the assignment for the original variables the same, then we get a satisfying assignment for f. So we take this satisfying assignment for f prime, we ignore the assignment for all of the new variables and the assignment for the original variables gives us a satisfying assignment for f. And that completes our reduction. One last thing to note is what is the size of f prime. F our original input SAT, has n variables and m clauses. How many variables does f prime have in the worst case? Well we might create n new variables for each clause. So it has order nm variables in the worst case. And we're also replacing every clause by order n clauses, in the worst case. So we have order nm clauses. But this is okay because the size of f prime is polynomial in the size of f. So we have an algorithm which is polynomial running time in the size of f prime. It's still polynomial in the size of f as well. So this completes our first NP completeness proof.

NP2 3SAT - 528 - Practice Problems
Now that you've seen your first NP completeness proof, the fact that three SAT is NP complete. There are a few relevant practice problems from the text book that you can try now. In problem 8.3, they consider a variant of SAT, called stingy SAT, and you want to prove that stingy SAT is NP complete. In problem 8.8, you consider exact 4-SAT. This means that every class has exactly four literals, not at most four literals but exactly four literals in every class. And you want to prove that exact 4-SAT is

NP3 Graph Problems - 529 - Lecture Outline
We've seen how to show that the 3SAT problem is NP-complete. Now let's take a look at a few graph theory examples. We'll start with the Independent sets problem, then will show that the clique problem is also NP-complete. And finally, we'll show that the vertex cover problem is NP-complete. I'll define for you each of these combinatorial problems as we go along, in case you're not familiar with them. Let's dive into the independent sets problem.

NP3 Graph Problems - 530 - Independent Set
First off, what is an independent set? Well, let's consider an undirected graph G, here's an undirected graph. A subset of vertices is an independent set if there are no edges contained in that subset of vertices. The green vertices here, the three vertices, are an example of an independent set for this graph. To check that this subset is an independent set, we can check all pairs of vertices in this subset, and we can check that these pairs are not adjacent. Here is another example of an independent set, this one of size six. Now, it's trivial to find very small independent sets. For example, the empty set is an independent set, or any singleton vertex is an independent set. The challenging problem is to find the large independent set.

NP3 Graph Problems - 531 - Quiz Max Independent Set Question
To make sure you understand what's involved in proving that a problem is in the class NP, let's take a short quiz. The max independent set problem is in the class NP. Is that statement true or false? To be more precise, let's change this statement slightly. So let's say the max independent set problem is known to be in the class NP. Is that statement true or false? I added this qualification, known to be, because there are scenarios such as P equals NP that would change things. So this will be the standard form for our true false questions of this type.

NP3 Graph Problems - 532 - Quiz Max Independent Set Solution
The solution to this quiz is false. Now, why is this problem not in the class NP? Because if you give me a solution, and you claim it's of maximum size, I have no way to verify that it is, in fact, of maximum size. The only way I can verify that it is of maximum size is if I can solve this problem in polynomial time. And that only holds if P equals NP. So assuming P is not equal to NP, then the max independence set problem is not in the class NP. Now recall we had a similar scenario for the optimization version of knapsack problem. When we looked at the version which tried to achieve the maximum value possible, that was not known to be in the class NP. But there was a simple fix so that the problem was in the class NP. So let's look at the search version of the independent set.

NP3 Graph Problems - 533 - Search Version
My input is undirected graph as before and also a goal g. My output is an independent set S with size at least g. I want to output such a set S, if one exists, and if there is no independent set of such a size, then I simply output NO. It will be straightforward to show that this version of the problem is a search problem and therefore lies in the class NP. And, in fact, will prove now that the independent set problem is NP-complete.

NP3 Graph Problems - 534 - Proof Outline
Now, let's dive into the proof that the independent set problem is NP-complete. The first step we have to show is that this problem, the Independent-set problem lies in the class NP. To do this, we need to show that we can verify solutions in polynomial time. So given an input to the independent-set problem, this is specified by a graph G and the goal little g and given a proposed solution S. We need to verify that S is in fact the solution to the independent-set problem on this input. In order n squared time, we can consider all pairs of vertices in this subset S. And we can check that this pair of vertices x and y are not adjacent. There's not an edge x, y in the input graph. Once we check this for all pairs of vertices in S, then we know that there are no edges contained in the set S and therefore S is an independent set. And finally in order n time, we can check the size of S and see that the size of S is at least g, our goal. If those two statements are true, then we know that our proposed solution S is in fact a solution to this input. That proves that the independent-set problem is in the class NP. Next, we have to show that the independent-set problem is at least as hard as every problem in the class NP. How do we do that? Well, we take something which is known to be at least as hard as everything in the class NP such as SAT or 3SAT, and we show a reduction from that known NP-complete problem to this new problem. We're going to show a reduction from the 3SAT problem to the independent-set problem. Why consider a 3SAT instead of SAT? Well, 3SAT is just easier. It's a simpler problem. We know that all the clauses are of size one, two, or three. If we consider a SAT, then the clauses are of arbitrary size. Now, let's look at the reduction from 3SAT to the independent-set.

NP3 Graph Problems - 535 - 3SAT IS
So take an input to the three subproblem, it is defined by a formula F, and we'll say the formula F has variables X1 through Xn, and clauses C1 through CM. So it has N variables and M clauses. And now we have to find an input to the independent set problem. And recall since this is three set, each of the clauses has size at most three, so it contains one, two or three literals. The input to the independence set problem is a graph G. We're going to define a graph G based on this formula F, which is the input to the three set problem. We also need to specify our goal little g. It turns out we're going to set our goal g to be M, the number of clauses. Here's the high level ideal for the construction of our graph G. For each of the clauses, we're going to create a vertex in our graph G corresponding to each of the literals in this clause. So this clause has three literals, then we're going to create three vertices. Since there are M clauses, there's going to be at most three M vertices in our graph G. And then we're going to add edges to encode this clause. And then we're going to add additional edges between vertices in different clauses, in order to ensure a consistent assignment. Let's define it more precisely.

NP3 Graph Problems - 536 - Clause Edges
There's going to be two types of edges. The first type were called clause edges because these are defined by the clauses. The second type are variable edges. Let's begin with the clause edges. Let's consider a clause of size three. So here the clause which is x_1 or x_3 bar or x_2. In our graph, we're going to have three vertices corresponding to the three literals. So this first vertex corresponds to x_1. This second vertex corresponds x_3 bar. And the third vertex corresponds to x_2. Now, some of these literals might appear in other clauses. For example if there is another clause containing x_2, we'll have another vertex corresponding to x_2. So there are multiple vertices corresponding to the same literal. Now, how do we encode this clause? Well, we simply add a triangle. We add edges between all pairs of these three vertices. In other words, we add the complete graph on these three vertices. What if we had a clause of size 2? For example, x_4 bar or x_5, then we add two vertices corresponding to these two literals, and we add an edge between them. Finally, if we have a clause of size one, for example x_1 bar, then we adjust at a singleton vertex by itself. This construction to keep property is in an independent set S in this graph is going to have at most one vertex per clause. If you look at these three vertices, we can only include one of them because there's edges between all pairs. Now recolor goal was to find an independent set of size at least m. Since every independent set has at most one vertex per clause. In order to achieve our goal of an independent set of size at least m, this solution has to have exactly one vertex per clause. Now, this one vertex per clause will correspond to this satisfied literal in that clause. Now there may be other satisfied literals in the clause due to other copies of that literal in other clauses, but this property that we have exactly one vertex per clause will ensure that we have at least one satisfied literal in every clause. And therefore, this solution, this independent set will be able to relate it to a satisfying assignment for this original formula. Now, what happens if I take an independent set containing this vertex corresponding to x_1, and this vertex corresponding to x_1 bar? Well, if this is the graph, this is in fact an independent set in this graph. And it can take one of these two vertices, and then I have an independent set of my goal size of three. Now, a natural way of converting this independent set into an assignment for the original formula is to satisfy each of the corresponding literals. So to satisfy this literal, I set x_1 to be true. For this literal, I set x_5 to be true. For this literal, I want to set x_1 bar to be satisfied, which means I set x_1 to be false. Now I have a contradiction, this is not a valid assignment because I'm setting x_1 to be true, and I'm setting x_1 to be false. So I want to ensure that my independent sets correspond to valid assignments. I never try to set a variable to true and to false.

NP3 Graph Problems - 537 - Variable Edges
This motivates the notion of variable edges. If I had an edge from this vertex corresponding to X_1 to this vertex corresponding to X_1-bar, then I ensure that any independent set contains this vertex or this vertex or neither, but it cannot contain both vertices. And therefore, I'll never try to set X_1 to be true and X_1 to be false. In general, for each of the variables X_i, I'm going to add edges between all copies corresponding to X_i and all copies corresponding to X_i-bar. This will ensure that our independent set corresponds to a valid assignment and then the clause edges will ensure that our independent set corresponds to an assignment which satisfies all of the clauses. Let's take a look at a specific example to illustrate this construction.

NP3 Graph Problems - 538 - Example
In this example, we'll have four variables which we'll label X, Y, W, and Z. Now, our three-set input is the following formula. X-bar or Y or Z-bar, that's the first clause. Second clause is X or Y-bar or W. The third clause is X-bar or W-bar. Fourth clause is Y-bar or Z or W. Now, to start a construction of the graph, for each clause, we construct a vertex corresponding to each of the literals. So for this clause, we have three vertices corresponding to the literals X-bar, Y, and Z-bar. We have three vertices corresponding to this clause, two vertices for this clause, three vertices for this clause. Now we add the clause edges. So we add a triangle on these three vertices, a triangle on these three, an edge on this pair, and a triangle on these three. Finally, we want to add the variable edges. So we run an edge from X to all copies of X-bar. Similarly, from Y to all copies of Y-bar. From all copies of W to W-bar. Finally, from Z to Z-bar. Now let's look at an example independent set of size four in this graph. Let's say we take X-bar from this triangle, Y-bar, W-bar, and Y-bar. This independent set corresponds to the assignment X equals false because of this literal, Y equals false because of this and this literal, W equals false because of this literal, and Z has no constraints. And notice that such an assignment satisfies this formula. Let's prove that in general, that an independent set of size m in this graph corresponds to a satisfying assignment of this formula, and a satisfying assignment of this formula corresponds to an independent set of size m.

NP3 Graph Problems - 539 - Correctness
So, we want to prove the following statement: Our three set input F has a satisfying assignment, if and only after our graph we construct has an independent set of size at least g. So there's a solution to this independence set problem, if and only if there's a solution to the original three set input. Let's start with the forward direction. So, consider a satisfying assignment for F, and we'll construct an independent set in this graph of size at least g. Now, this assignment satisfies the formula. So what do we know about it? We know for each clause, at least one of the literals and that clause is satisfied. Since there's at least one satisfied literal in every clause, take one of those satisfied literals, exactly one. Now this literal in this clause, corresponds to a vertex. We're going to add that vertex into the set S. Now, what do we know about the size of S? Well, as contains exactly one vertex per clause. So the size of S is m and recall that our goal little g was set to be m. So this set S is of the goal required size. Now we just have to prove that S is an independent set. Now, S contains exactly one vertex per clause, and it never contains both X_i and X_i bar. Why does it not contain both X_i and X_i bar? Because it corresponds to an assignment, an assignment either sets X_i to be true, in which case we might include copies of X_i, or we set X_i to be false, in which case we might include copies of X_i bar, but we wouldn't include any copies of X_i. Because there is at most one vertex per clause, we know that there is no clause edges contained in this set S. And because we never include a vertex X_i, and a vertex X_i bar, we know that there are no variable edges contained in this set S. So therefore, there are no edges contained in this set S, so, S is an independent set and it's an independent set of size equal to g of our goal size. So we've constructed an independent set of size equal to g in this graph. So we've proved the forward direction, we've proven that if we take a satisfying assignment, we can construct an independent set of the desired size in this graph. Now we can try to do the reverse direction.

NP3 Graph Problems - 540 - Reverse Implication
Now let's look at the reverse implication. Now since this independent set has size at least G and G is set to M, then we know that this independent set has exactly one vertex in each of the clauses, actually in each of the triangles corresponding to the clauses. Now this vertex corresponds to a literal in the original formula. So we set that corresponding literal to true. So we satisfy that literal, since every clause has a satisfied literal then we know every clause is satisfied and therefore the formula is satisfied. But does this correspond to an assignment, a valid assignment? But notice we have no contradictory literals in this set. Why? Because we added edges between Xi and Xi bar so we can never including vertex Xi and a vertex Xi bar in an independent set. Therefore, we never attempt to set Xi to true and Xi to false. So this assignment we constructed corresponds to a valid assignment. This is a valid assignment and it says every clause. Therefore, it satisfies the formula F, so we've taken an independent set of size at least G and we construct a satisfying assignment. This completes the proof of the reverse implication. So we've shown this equivalence. This proves that a reduction from 3SAT to independent set is correct and it shows how to take an independent set and construct a satisfying assignment. And if there is no independent set of size at least G then there is no satisfying assignment. So this completes the proof that the Independent set problem is NP-complete.

NP3 Graph Problems - 541 - NP-hard
We just saw that the independent set problem is NP-complete. I want to go back and look at this optimization version, the Max Independent Set Problem, and I want to see what this implies about this problem. Now we have this class of problems NP, the independent set problem which we just proved is NP-complete lies in this class, and there is a reduction from every problem in this class to the independent set problem. It's at least as hard as every problem in this class of NP. Now the max independent set problem is not known to lie in the class NP, so still outside this class. Notice it's quite straightforward to reduce the independent set problem, to the max independent set problem. Here, I'm looking for an independent set of size at least g. Here, I'm looking for the maximum independent set. If I find the maximum independent set and I check whether that size is at least g, that either gives me a solution, or it tells me there's no solution. So it's quite straightforward to reduce the search version, to the optimization version. That means I have a reduction from the independent set problem, to the max independent set problem, and in fact I have a reduction from every problem in NP, to the max independent set problem, either going indirectly through the independent set problem or directly. What does that mean? That means the max independent set problem is at least as hard as everything in the class NP. Now if we knew it was in the class NP, then we would know it's NP-complete. But we don't know that. But how do we denote that it's at least as hard as everything in the class NP? We say that the max independent set problem is NP-hard. Notice it's NP-hard, not NP-complete. So NP-hard, means that it's at least as hard as everything in the class NP. So there is a reduction from everything in the class NP to this problem max independent set. So if we can solve max independent set in polynomial time, then we can solve everything in NP in polynomial time. To be NP-complete, such as the independent set problem, then it has to be NP-hard, and it also has to lie in the set. So complete problems are the hardest in the set. Hard problems are at least as hard as everything in

NP3 Graph Problems - 542 - Lecture Outline II
We just saw how to show that the independent set problem is NP-complete. Now that reduction was quite interesting since it involved a reduction from SAT, which is a logic problem, to this graph problem, Independent sets. Now, will show that the Clique problem and vertex cover problem are NP-complete. These will be much easier since we now have a graph problem, independent sets to start from. Let's dive into the clique problem.

NP3 Graph Problems - 543 - Clique
A clique is a fully connected subgraph. Let me define it more formally for you. The clique problem is defined for undirected graphs. So, let's consider an undirected graph G. Here's an example of an undirected graph that we'll use to illustrate a clique. A subset S of vertices is a clique if the following holds, for all pairs of vertices in this subset, say the pair is X and Y, then X and Y are connected by an edge. So, all pairs of vertices in this subset S are connected by an edge. Here's an example of a clique of size five in this graph. Notice that all five choose two pairs are connected by an edge. And in fact, this is the largest clique in this graph. This vertex can almost be added to the clique but it's not connected to this vertex over here. The challenging problem is to find large cliques. Why is that the case? Well, very small cliques are trivial to find. For example, the empty set of vertices is always a trivial clique. Moreover, any singleton vertex by itself is also a clique. And if you take any edge, the two endpoints of the edge form a clique. So very small cliques are easy to find. The difficult problem is to find the largest clique or the clique of maximum size.

NP3 Graph Problems - 544 - Clique Search Version
Now let's formally define the Clique problem. The input to the clique problem is an undirected graph G, and it goal little g. The output from the clique problem is a subset of vertices S, which is a clique of size at least g. Now we're trying to find the largest clique possible. Therefore we're trying to output a clique of size at least g. If we outputted a clique of size at most g, that would be quite trivial, because we could always output the empty set. Now we output such a clique if one exists, and if no such clique exists in the graph, then we output NO. And what we're going to prove now, is that the Clique problem is NP-complete.

NP3 Graph Problems - 545 - Clique Proof Outline
Let's dive into the proof that the Clique problem is NP-complete. Now, there's two parts to the proof. The first thing we have to prove is that the Clique problem lies in the class NP. As usual this is quite straightforward. So consider an input to the Clique problem, a graph G, and a goal little g. And consider our proposed solution S. Now, we have to verify in polynomial time that S is a solution, is a clique of size at least g. To verify that S is a clique, we consider all pairs of vertices in S. And we check that that pair of vertices, x and y, are connected by an edge in the input graph G. Now, how long does this take us to do? What takes us the most order n squared time to consider each pair. And then for each particular pair, it takes as the most order n time to check whether they're connected by an edge. So this takes in most order n cube time by a trivial algorithm. Now that's sufficient for this proof since we just have to show polynomial time. But if you give a little bit of thought, you can easily do it in order n square time as well. That verifies that S is a clique. Now we have to verify that the size of S is at least little g. That takes us order n time, and therefore it takes us polynomial time to verify that S is a solution to the clique problem on this input instance. That establishes that the Clique problem lies in the class NP. It's a search problem. We can verify solutions in polynomial time. The second step we have to show is that clique problem is at least as hard as every problem in the class NP. How do we do that? Well, we take a known NP-complete problem, and we show a reduction from the known NP-complete problem to the clique problem. Which problems do we know are NP-complete? We know the SAT problem is NP-complete, 3SAT is NP-complete, and independent set problem is NP-complete. We're going to take one of these. Which one are we going to take? We're going to take the one which is most similar to the clique problem. Clique is a graph problem, so we'll take the independent set problem, which is also graph problem. So, we'll show that the Independent set problem reduces to the Clique problem.

NP3 Graph Problems - 546 - IS Clique Idea
Here's a key idea for relating independent sets and cliques in a graph. Let's compare a clique and independent set. A clique is fully connected which means that I have all edges within the pairs of S. In contrast, an independent set has no edges within the set S. For an independent set, for any pair X,Y in S, they are not connected by an edge. Whereas for clique, for any pair X,Y within S, they are connected by an edge. So they are opposites of each other. Clique is opposite of independent set and vice versa. Now we're going to have to take an undirected graph where we want to solve the independent set problem on this graph. Now we are assuming that we have an algorithm to solve the clique problem. So we want to transform this input for the independent set problem into an equivalent input for the clique problem. What should we do? Well, we should take the opposite of this graph. What exactly do we mean by the opposite? Well, let's formalize it now. We're going to denote the opposite of G as G bar to complement. It's going to have the same vertex set and the edges are going to be the complement of the edges here. So the edges in E bar are those pairs X,Y which are not an edge in E. So in other words, a pair X,Y is an edge in G bar, if and only if, the pair X,Y is not an edge in E. So it's not an edge in E, then it's an edge in E bar. If it is an edge in E, then it's not an edge in E bar. Now we can formalize this key idea, that clique and independent sets are opposites of each other. Now our observation is that S is an independent set in the original graph G, if and only if that same set S is a clique in the complement graph G bar. So if I look at a graph G and its complement graph, its opposite graph, then a set S is an independent set in the original graph, if and only if the set S is a clique in the opposite graph G bar. Now I call it an observation because it doesn't really require a proof after observing this statement. If S is an independent set, that means for all pairs of vertices X,Y and S, they are not connected by an edge. And therefore, in G bar, they are connected by an edge. And therefore, S is fully connected in G bar. And similarly, if S is a clique in G bar that means all pairs X,Y are connected by an edge than in the original graph G, all pairs are not connected by an edge. And therefore, it's an independent set. S does not contain any edges in the original graph G.

NP3 Graph Problems - 547 - IS Clique
Given this observation, it's now straightforward to show a reduction from the independent set problem to the clique problem. Now we're doing a reduction from independent set to clique, so we have to take an input for the independent set problem and transform it to an input for the clique problem. So consider an input for the independent set problem. This is defined by a graph G and a goal little g. We take the opposite of the G, that's G bar and we use G bar and the same little g as our input to the clique problem. Now we use our observation. If we get a set S which is a clique in the opposite graph G bar, then we know that S is an independent set in the original graph G. Now if we get a solution s for the clique problem, that means that S is a clique of size at least little g in G bar. Then we return S as a solution to the independent set problem, because we know S is an independent set of size at least little g in the original graph capital G. Now if our clique problem returns no. So there's no clique of size at least little g in G bar, then we return no for the independent set problem, because we know that there's no independent set of size at least a little g in the original graph G, because if there was an independent set of sufficient size in capital G, then we know there would be a clique of sufficient size in the opposite graph G bar. This completes the definition of the reduction and the proof of correctness follows from this observation. Therefore, we've shown that the clique problem is NP complete.

NP3 Graph Problems - 548 - Lecture Outline III
We've shown clique is NP-complete, now let's show that vertex cover is NP-complete.

NP3 Graph Problems - 549 - Vertex Cover
What exactly is a vertex cover? Let's formally define it. Once again, we're going to consider undirected graph G. Here's an example graph. A subset of vertices is a vertex cover, if, it covers every edge. The red vertices in this graph, our vertex cover for the graph G. What exactly does it mean that the set S covers every edge? Well, if you look at this example, for every edge, such as this edge, at least one of the two endpoints is in the red set, is in the vertex cover. For this edge, one endpoint is in. For this edge, both endpoints are in the red set. Formally, to cover every edge, we mean that for every edge of the graph. Say x, y, either endpoint x is in the set S and/or y is in the set S. So, both end points can be in there, or at least one of the endpoints is in there. Now it's easy to find a large vertex cover. For instance, I can include all the vertices in the vertex cover. And, this is a large vertex cover for this graph.

NP3 Graph Problems - 550 - VC Search Version
The input to the vertex cover problem is undirected graph G, and the goal which we'll call a budget, little b. Why do we change a terminology from goal to budget? Because instead of trying to find the maximum size clique or independent set, we're trying to find the minimum size vertex cover. The output to the problem is a vertex cover, S, of size at most, little b. We're trying to find the smallest possible, if one exists. And if no such vertex cover exists in the graph G, then we simply output NO. We're going to prove now that the vertex cover problem is NP-complete.

NP3 Graph Problems - 551 - VC Proof Outline
to prove that the vertex cover problem is np-complete there are two parts the first part once again is to prove that it's in the class and P so consider an input to the vertex cover problem a graph capital G and a budget little B and consider a proposed solution capital S this is a proposed vertex cover in the graph G can we verify in polynomial time that ass is a vertex cover of requisite size in the input graph G first in order to verify that s is a vertex cover we have to check every edge of the graph and we have to check that at least one of the two endpoints is in set s this can be done in linear time in order n plus M time next we have checked that the set s is sufficiently small this can easily be done in linear time in order n time this shows that in polynomial time we can verify that s is a solution to this input instance now we can do the second more non-trivial aspect of the proof now we have to show that the vertex cover problem is at least as hard as every problem in the class NP so we have to take a known np-complete problem we now have four problems that we know are np-complete sad 3sat independent set and clique and we have to reduce one of them to the vertex cover problem it's most natural to take one of the graph problems either independent set or Klee these are quite similar to each other so it doesn't matter too much we're gonna take independent set problem and reduce it to the vertex cover problem now let's do the reduction from the independent set problem to the vertex cover problem

NP3 Graph Problems - 552 - VC Reduction Idea
To get an idea for the reduction, let's look at our earlier example of a vertex cover. The red vertices are our vertex cover in this graph. What do you notice about the vertices that are not red? The white vertices. They form an independent set in this graph. Let's take a look at another example of a vertex cover. There's a minimum sized vertex cover. What do you notice about the white vertices in this graph? They also are an independent set in this graph. We claim this holds in general as is a vertex cover in the graph if and only if S bar the complement of s is an independent set. So the red vertices are vertex cover and the non-red vertices are an independent set and vice versa. Let's prove this claim and then the reduction from independent set to vertex cover will be straightforward.

NP3 Graph Problems - 553 - Forward Implication
Let's start with the forward implication of this claim. So let's take a vertex cover S and let's prove that S bar is an independent set. So let's consider this example, the red vertices are in vertex cover S. Now consider an edge of the graph. For instance, this is a particular edge, notice that at least one of the endpoints is red. Similarly for this edge, at least one of the endpoints is red. In this case both endpoints are red and in general we know for every edge X, Y, at least one of the endpoints is in the set S, because the vertex cover, covers every edge. And therefore, at most one of X or Y is in S bar, the complement of S. If at least one is in S then at most one is in S bar, this means that no edge of the graph is contained in S bar. S bar contains at most one of the endpoints for every edge. So it doesn't contain both endpoints for any edge. Therefore, S bar is an independent set. So we've shown that if S is a vertex cover, then S bar is an independent set.

NP3 Graph Problems - 554 - Reverse Implication
Now, let's prove the reverse implication. Let's take an independent set, S-bar, and let's prove that S is a vertex cover. S-bar, we're assuming, is an independent set. So what do we know? We know that no edge is fully contained in this set, S-bar. Therefore, we know that, at most, one of the endpoints, x or y, is in the set, S-bar. If both endpoints, x and y, are in S-bar, then that means the edge is fully contained in the set, S-bar, and therefore, S-bar is not an independent set. But since it's an independent set, at most, one of the endpoints or neither the endpoints is in the set, S-bar. If at most, one is in S-bar, then at least one is in S. Thus, S covers every edge of the graph, because for every edge of the graph, at least one of the endpoints is in S. And therefore, S is a vertex cover. This proves this direction, that if S-bar is an independent set, then S is a vertex cover. And that completes the proof of the claim. Now, we can do the reduction.

NP3 Graph Problems - 555 - IS VC
Let's detail the reduction from Independent set problem to the Vertex cover problem. So we're trying to find an independent set of size at least little g in the input graph capital G. Now we have to define our input for the vertex cover problem. We let little b=n-g. And then we run the vertex cover problem on the input graph G, the same graph as before with budget little b. Now, that defines the reduction. Now let's look at the correctness of this reduction. What do we know from the claim? What we know that G has a vertex cover of size at most N minus a little g which is b. So, we have a vertex cover S of this size and we know that in G, S bar is an independent set and this independent set is going to be of size at least little g. So, if we find a vertex cover of the requisite size in G, then its complement set is an independent set of the desired size in G. And if there is no vertex cover of the requisite size, then there is no independent set of the desired size.

NP3 Graph Problems - 556 - IS VC Correctness
Our reduction took this input instance for the independence set problem. So we took a graph, a capital G, with a goal, little g, for the independence set problem, and we reduced it to the vertex cover problem with input instance, capital G, the same graph, and budget, little b. And little b was defined as n minus little g. Now given a solution s for this vertex cover instance. So this is a vertex cover of size at most little b. Then we return S-bar as the solution to the independence set problem because we know that if S is a vertex cover of size at most little b, then we know that S-bar is an independent set of size at least little g. And if our vertex cover problem comes back with no, there's no solution, then when we return no, there's no solution for the independence set problem, because we have this if and only if statement, if there's no solution here and there's no solution here and vice versa. That completes the reduction and that proves the correctness of the reduction. That completes the proof that the vertex cover problem is NP complete.

NP3 Graph Problems - 557 - Practice Problems
At this point, all of the practice problems at the end of Chapter Eight are relevant. Here are a few of my favorite problems. In problem 8.4, they give you a proof, a supposed proof of NP-completeness for a problem, and you have to spot the error in that proof. Now in problem 8.10, there are seven subparts, and you have to prove that each of these problems that they present is NP-complete by doing a proof by generalization. You have to show it's a generalization of a known NP-complete problem. Some other nice problems are 8.14 where you do the Clique plus Independent set problem. So you're checking whether graph has a large clique and a large independent set. And 8.19, you consider the Kite problem. Now in all these NP-completeness problems, there's two parts, yet the first show that the problem is in the class NP, that's usually trivial. And then you have to take a known NP-complete problem and reduce it to this new problem. Now, what's the known NP-complete problem you should use? Well, it's probably something similar. So, for instance, this talks about clique and independent set, probably you should use clique or independent set here as the known problem. If you're talking about a SAT variant, then you should probably use SAT or 3SAT over here. Now, there are roughly two flavors of NP-completeness productions. The first is proof by generalization. You can show that this new problem is more general than a known problem. Now, in some sense, we're always showing that this new problem is a generalization of the known problem. But what we mean by this proof by generalization is that you can just set the parameters here so that you get this known problem here. Now, the other type of reduction is you have to do a gadget. We did something like this for the 3-SAT proof. What we do is we take the formula as input over here and we modify it in some way or we take a graph problem over here and input the graph problem here and we modify that graph by adding some small structure to that graph. We call that a gadget that we're adding in. So, those are the two main approaches. You're going to do proof by gadget. You're going to take the input here and you're going to modify it by adding some gadget to make an input for the new NP-complete problem, or you are going to do a proof by generalization. This topic is a little like dynamic programming. You have to do a lot of practice problems to get the hang of it. So, good luck and try a lot of practice problems from the text.

NP4 Knapsack - 558 - Lecture Outline
Let's give a quick recap of what we've seen so far. We took for granted that SAT is NP-complete. This means that all the problems in the class NP can be reduced to SAT. So, if we can solve SAT in polynomial time, then we can solve any problem in NP in polynomial time. And we saw that 3SAT is NP-complete. This involved a reduction from SAT to 3SAT, then we prove that the Independent Set problem is NP-complete. This involved a reduction from 3SAT to the Independent Set problem. This was a quite interesting reduction because it involved a transformation from a logic problem, 3SAT to a Graph problem, Independent Set problem. Then we proved that the Clique problem and Vertex cover problems were NP-complete. These involve more trivial reductions from the Independent Set problem. What we are going to do now is we're going to prove that the Knapsack problem is NP-complete. As an intermediate step, we're going to look at the Subset-sum problem. We're going to prove that a Subset-sum problem is NP-complete. This is going to involved a reduction from the 3SAT problem to Subset-sum problem. This again is a quite non-trivial reduction because it involves transforming a logic problem 3SAT into this optimization problem Subset-sum. Once we prove that Subset-sum is NP-complete, it will be quite easy to prove that the Knapsack problem is NP-complete. We'll leave this last step as a homework problem proving that Knapsack is NP-complete once we know that Subset-sum is NP-complete. If you recall from the beginning, in the course, we study Dynamic Programming Algorithm for the Knapsack problem. And there, we saw an order N times B time Algorithm for the Knapsack problem, and we pointed out why this is not polynomial time. Why this running time is not polynomial in the input size? In order to be polynomial in the input size, it has to be polynomial in N and log of B. Why this is not polynomial is somewhat of a subtle point. I think it becomes much clearer when you see this reduction from 3SAT to Subset-sum, or 3SAT and Knapsack. What you see in this reduction, is that capital B will be exponential in the size of the input formula for the 3SAT problem. So, if we use this Algorithm to solve 3SAT, this would give us an exponential time Algorithm of 3SAT. It's a quite clever reduction so let's dive into it. Let's prove that the Subset-sum problem is NP-complete. Let's start with the definition of a Subset-sum.

NP4 Knapsack - 559 - Subset Sum
The input to the subset sum problem are n positive integers which we'll denote as A_1 through A_n, and one additional integer, t. Our goal is to find a subset of numbers which sum up to exactly t. So we want the sum over the indices in this subset of the corresponding numbers to be equal to exactly t. We output such a subset if it exists and otherwise, we output NO. This is a great practice problem for dynamic programming. Using dynamic programming, we can solve this problem in order n times t time. If you want practice with dynamic programming, I suggest you

NP4 Knapsack - 560 - Subset-Sum in P Question
Let's take for granted that there's an order n times t, time algorithm for the subset-sum problem. Now given that fact, the subset-sum problem is known to be in the class P. Is that true or false?

NP4 Knapsack - 561 - Subset-Sum in P Solution
This is false. Just like with the knapsack problem, this is not polynomial in the input size. To be polynomial in the input size, the running time would have the N times polynomial in log t.

NP4 Knapsack - 562 - Subset-Sum NP-Complete
We're going to prove now, that's a subset-sum problem is NP-complete. Again, there are two parts of the proof. First, we have to prove that the subset-sum problem is in the class NP. So we take an input instance to the subset-sum problem, this is specified by and numbers a to the first through to a to the nth and t, and we take a proposed solution S. And we check that the sum over the integers in that subset equals exactly t. How long does it take to compute the sum? Well, there is the most and numbers there, so there's order n time. And then how long as each number? Well, each numbers at most log t bits. So to sum these up, takes in most O(n logt). Notice this as polynomial in the input size, so we can verify solutions in polynomial time. Next we have to show that the subset-sum problem is at least as hard as every problem in the class NP. So we have to take a known NP-complete problem, and reduce it to the subset-sum problem. Which problem do we choose? Well, we're going to choose the 3SAT problem, and we're going to reduce it to the subset-sum problem. The reduction is very clever, and somewhat involved, but it doesn't involve any heavy math or anything like that. And it really illustrates why the order n times t time algorithm, is not efficient for this subset-sum problem.

NP4 Knapsack - 563 - 3SAT Subset-Sum Input
The input to the subset sum problem will consist of 2n plus 2m plus one numbers. There are n variables and 2n literals, so we'll have a number for each literal. There are m clauses, so we'll have two numbers for each clause. And then we'll have one additional number which is our desired sum. We'll have V_1 and V_1 prime corresponding to X_1 and X_1 bar, V_1 and V_2 prime for X_2 and X_2 bar. And V_n and V_n prime for X_n and X_n bar. We'll have these two additional numbers for the first clause, and so on for the m clauses. And finally, we'll have the desired sum. Now these numbers are all huge. They're going to be at most n plus m digits long. And we're going to work in base 10. This is so that if we add up any subset of numbers, there'll be no carries between the digits. Note these numbers are huge, for instance, t is on the order of ten to the n plus m. This illustrates why our order n times t algorithm is a somewhat terrible algorithm.

NP4 Knapsack - 564 - 3SAT Subset-Sum Variables
Now let's take a look at the actual specification of the input to the subset sum problem. Let's start with these numbers corresponding to the two n literals, in particular Vi corresponds to Xi. So we're going to include this number Vi in the subset S, if and only if the literal Xi is set to true. Similarly Vi prime corresponds to Xi bar and will include Vi prime in this subset S if and only if the variable Xi is set to false. And assignment for the three set formula either sets Xi to true or Xi to false. Therefore, we need for the subset sum problem that either we include Vi in S or Vi prime in S. Well, we can't include both and we can include neither, because then we don't know how to set Xi. So we need to ensure that exactly one of Vi or Vi prime is in S. How do we achieve this? Well, in the Ith digit of these three numbers Vi, Vi prime and T we put a one. In all other numbers, we put a zero in the Ith digit. Now by using base 10, we will ensure that there is no carrys between the digits. So each digit is going to behave independently of each other. Recall that T is our desire sum, so the only way to achieve a desired sum that has a one in the Ith digit, is to include either Vi or Vi prime in S, but not both and not neither. So this specification ensures that our solution to the subset sum problem is going to correspond to an assignment. Whether it's satisfying or not is another issue, but for now at least we know that we have an assignment. So either we're going to correspond to Xi being set to true or Xi being set.

NP4 Knapsack - 565 - 3SAT Subset-Sum Example
To illustrate the reduction it'll be useful to have a running example and we can fill in the numbers as we go along. So let's consider this input formula to the 3SAT problem. It consists of three variables and four clauses. For variable X1, there'll be two numbers, the V1 and V1 prime, similarly for X2, there'll be V2 and V2 prime and for X3, there'll be V3 and V3 prime. In addition there'll be two numbers for each clause, so we have S1 and S1 prime for clause one, S2 and S2 prime for clause two, S3, S3 prime, S4, S4 prime for the last two clauses and finally we have t which is our desired sum. These 15 numbers specify the input to the subset-sum problem. These numbers are going to be seven digits long. The digits correspond to the variables, three variables and clauses, four clauses. The first three digits correspond to the three variables, X1, X2, X3, the next four digits correspond to the four clauses. Now in assignment to f, either sets X1 to true or false, so we wanted that a subset-sum solution either includes V1 or V1 prime in the subset. How do we ensure that? We put a one in the first digit for V1, V1 prime and t. For all other numbers, we put a zero in the first digit. Now assuming there's no carry from the other digits, how can our subset of numbers achieve a sum of one in the first digit? Well, the only way is to include either V1 or V1 prime but not both and not neither. So we have to include exactly one of these two in order to achieve a sum of one in the first digit. Similarly we put a one in the second digit for V2 and V2 prime and for t, and in the third digit we put a one for V3, V3 prime and t. Then we put a zero for all other numbers in the second and third digits. This ensures that exactly one of V2 and V2 prime is in the subset and exactly one of V3 and V3 prime is in the solution to the subset-sum problem. So now we know that any solution to the subset-sum problem corresponds to an assignment. Now we have to ensure that it corresponds to a satisfying assignment. So for that we use these remaining four digits.

NP4 Knapsack - 566 - 3SAT Subset-Sum Clauses
The first n digits correspond to the variables so the next m digits correspond to the clauses. So digit n plus j is going to correspond to clause Cj. If the literal Xi appears in the clause Cj, well, Xi, this literal corresponds to this number of Vi. So we're going to put a one in digit n plus j for this number Vi. Similarly, if the literal Xi bar appears in this clause, well, in this case, this literal Xi bar corresponds to this number Vi prime. So we put a one in digit n plus j for this number, Vi prime. What this does is it encodes the clauses in these numbers, Vi and Vi prime. Let's go back to our running example. Our first clause contains X1 bar, X2 bar, and X3 bar. This clause corresponds to the fourth digit so we're going to put a one in V1 prime and put a one in V2 prime, and a one in V3 prime. Similarly, for the second clause, we put a one in V1 prime for X1 bar, V2 prime and V3. For clause three, we put a one in V1, V2 prime, and V3. Clause four, V1 and V2. Now for the first clause, we want to ensure that either V1 prime, V2 prime, or V3 prime are included in the subset in the solution to the a subset-sum problem. We just need that at least one of these is included. We don't need that exactly one so we can't just put a one here in t. We want that either one, two, or three of these numbers are included in the solution so we put a three in the fourth digit of t, fifth digit, sixth digit, and seventh digit. Now, if we include all three of these numbers in our solution, then we're okay, but what if we only include one of these digits? What if only one of these literals is satisfied? Well, that's where we use these buffer numbers, S1 and S1 prime. We're going to put a one in the fourth digit for these two numbers. The point is that if only one of these three literals is satisfied, then we get up to some of the three by including both of these buffer numbers. So we get a one from one of these three plus one plus one and that gives us three. What if all three of these literals are satisfied? Then, we don't have to use either of these buffer numbers. What if exactly two of these literals are satisfied? Then we use one or the other of these buffer numbers. But if none of these literals are satisfied, then using both of the buffer numbers only gets us up to a sum of two so we can't satisfy t. We can't get a solution to the subset-sum problem. The only way to get a solution to the subset-sum problem is to have at least one of these literals satisfied and then we can use the buffer numbers to get the desired sum in this digit. So, similarly, for clause two, we put a one in this digit for S2 and S2 prime, S3 and S3 prime, S4 and S4 prime. All the other numbers have zeros in these digits. This specifies the reduction from the 3SAT formula to the subset-sum problem. Note that V1 is the number 1000011. V1 prime is the number 1001100. S4 and S4 prime are the numbers one, t is the number 1113333.

NP4 Knapsack - 567 - 3SAT Subset-Sum Buffers
Let's go back and specify the remainder of the reduction in general. For each clause, we encoded the literals which appear in that clause using V_i and V_i prime. To ensure that at least one of these literals is satisfied, we put a three in digit n plus j of t. Then, if all of the literals in this clause are satisfied, we get the desired sum in this digit. What if only one or two of the literals in this clause are satisfied, how do we get the desired sum? Well, that's where we use S_j and S_j prime to act as buffers. We put a one in digit n plus j of both of these numbers, and finally put a zero in digit n plus j of all the other numbers which we haven't specified so far. The main point is that, if all three of the literals in this clause are satisfied, then we get the desired sum of three in this digit. If exactly one or two of these literals are satisfied, then using these buffer numbers, we get the desired sum of three in this digit. But if none of the literals in this clause are satisfied, then there's no way to achieve a sum of three in this digit because the sum of these buffer numbers only adds up

NP4 Knapsack - 568 - 3SAT Subset-Sum Correctness
What we've sketched so far and what we'll formally prove now is that the subset sum instance that we constructed has a solution if and only if the original 3SAT input is satisfiable. It's going to prove that we did a value reduction. Let's start with the forward direction. Let's take a solution S to this subset sum instance. So we know that if we sum up the numbers in S, it sums up to exactly T. Let's first look at the first N digits. These correspond to the N variables X1 through Xn. We know that T has a one in digit I. In order to get a one in digit I, we have to include Vi or Vi prime in our subset S, but not both. If we include both we get a two n digit i. And if we include neither, we get a sum of zero in digit i. So the only way to get a sum of exactly 1 in digit i is to include exactly one of Vi and Vi prime. If we include Vi in our subset S, then we set the variable Xi to true. If we include Vi prime in our subset S then we set the variable Xi to false. So from this solution to the subset sum problem, we get an assignment. We get a true false assignment for the variables. Why is this a satisfying assignment? Well, to see that we'll look at the remaining digits.

NP4 Knapsack - 569 - Proof Satisfying Assignment
We just saw, if we take a solution to the subset sum instances that we specified, then using the first n digits that specifies a true-false assignment for the n variables X_1 through X_n. Now, using the remaining n digits, we're going to show that that assignment that we just specify corresponds to a satisfying assignment. It satisfies the input formula f. First n digits correspond to the variables, the next m digits correspond to clauses. So let's look at digit n plus j, where j varies between one and n, so digit n plus j corresponds to clause C_j. In our definition of the subsets sum instance, we put a three in digit n plus j of t. So we need to achieve a sum of three in digit n plus j. In order to get a sum of three digit and plus j, we have to include at least one of the numbers corresponding to the literal appearing in clause C_j. If we satisfy exactly one literal in C_j, then we use both S_j and S_j prime as buffer numbers and then we get a sum of three. If we satisfy exactly two literals in this clause, then we either include S_j or S_j prime in our subset S, and that gives us a sum of three. If we satisfy exactly three literals in this clause, then we don't need to use either of these buffer numbers, S_j or S_j prime. Just using these three satisfied literals gives us a sum of three in this digit n plus j. If we satisfy zero of the literals in this clause, then there is no way to achieve a sum of three in this digit, and therefore, we don't have a solution to the subset sum problem. We're assuming we have a solution, therefore, we must have at least one satisfied literal in this clause. Thus, C_j is satisfied and thus, every clause is satisfied. And therefore, we have a satisfying assignment for f. So we've shown that a solution to this subset sum instance corresponds to a satisfying assignment for our 3SAT formula. And we've actually shown how to transform this solution to the subset sum problem to find the satisfying assignment to the 3SAT's formula. Now let's prove the reverse implication. Let's prove that if we have a satisfying assignment for this 3SAT formula, it corresponds to the solution to the subset sum problem.

NP4 Knapsack - 570 - Reverse Implication
Let's prove the reverse implication that a satisfying assignment for the 3SAT formula corresponds to a solution to the subset-sum instance. So let's take a satisfying assignment for f, and we'll construct a solution to the subset-sum instance in the following manner. In our satisfying assignment, if we set the variable X to the ith to true, then we add the number V to the ith to the solution S. And if we set the variable X to the ith to false in our satisfying assignment, then we add the number of V to the ith prime to our solution S. We're adding exactly one of V to the ith and V to the ith prime to S. This means, in the ith digit, we get exactly one. So the ith digit of T is correct. Now let's look at the jth clause. We started from a satisfying assignment, therefore, at least one of the literals in this clause is satisfied. The numbers corresponding to these literals give us a sum of one, two, or three in the digit n plus j. T has three in digit n plus j. So how do we achieve a sum of three digit n plus j? Well, using the numbers corresponding to these literals, we get a sum of one, two, or three, and then we can use S to the jth and/or S to the jth prime to get up to a sum of three. This ensures that digit n plus j is correct and therefore, the last m digits are correct and the first digits are correct. And therefore, we have a solution to the subset-sum instance. So we've proved this equivalence and we've proved that our reduction is correct.

NP4 Knapsack - 571 - Knapsack is NP-complete
You just proved that the subset sum problem is NP-complete. Now a nice homework problem is to use that fact that subset sum problem is NP-complete and then prove that the knapsack problem is NP-complete. And make sure that you use the correct version of the knapsack problem. The version that which lies in the class NP. Now to prove that the knapsack problem or any problem is NP-complete, there's two parts: You first have to prove that the desired problem lies in the class NP, and second you have to take a known NP-complete problem and you have to reduce the known NP-complete problem to this new problem, in this case knapsack problem. We know that all problems in NP reduce to this known NP-complete problem, therefore if we show a reduction from this known NP-complete problem to the knapsack problem, then we know that all problems in NP reduced to the knapsack problem. Which problem are you going to use for this part? Well I'm not trying to trick you, so what are you going to use is the problem that looks most similar to the knapsack problem, in this case is subset sum problem. On the homework or exam, if you have a graph problem which you're trying to prove is NP-complete, what are you going to use here? Probably a graph problem which sounds similar or looks similar to the desired problem. If you have a logic problem you're trying to prove is NP-complete and probably you're going to use set or three set over here. The other thing to make sure of is that you're doing the reduction in the correct direction. So you're assuming you have a polynomial time algorithm for this problem and you are using that to solve this problem in polynomial time. So you have taken input to this known NP-complete problem and reduce it, transform it into an input for this problem. Then if we take a solution to this problem then you can transform it back to a solution to this original problem. So you have to transform inputs from this known NP-complete problem to inputs to this new problem. That's a common mistake that students make, even though they write the direction this way, they actually do the reduction in the other direction. They take inputs for this problem and transform it to input to this problem. You have to make sure you're doing it the correct direction. So you take inputs to the known NP-complete problem and transform it to inputs to this new problem.

NP5 Halting Problem - 572 - Undecidability
We've now seen many NP-complete problems. When a problem is NP-complete it signifies to us that it's computationally difficult. Formally what does that mean? That means it is the most difficult problem in the class NP. So, if we can solve this NP-complete problem in polynomial time, we can solve all problems in the class NP in polynomial time. And now since there are literally thousands of problems in the class NP from all scientific fields it's unlikely that we're going to derive a polynomial time algorithm for our NP-complete problem. To be precise if P is not equal to NP, then that implies that there's no algorithm which can run in polynomial time on every input for this NP-complete problem. Notice the important distinction is on every input. We may have an algorithm which takes polynomial time on some inputs or even on most inputs or almost every input, but there's no algorithm which is guaranteed to take polynomial time on every input. Now we're going to look at the class of undecidable problems. These are problems which are computationally impossible. For an NP-complete problem it's unlikely to have an algorithm which solves the problem in polynomial time. In contrast, for an undecidable problem there is no algorithm which solves the problem on every input regardless of the running time of the algorithm. You run polynomial time, exponential time; there's no algorithm which is going to solve it on every input. Now in 1936 the great Alan Turing proved that the halting problem is undecidable. And we're going to see the idea of that result now. Now this paper by Turing in 1936 introduced the notion which we now refer to as Turing Machine what Turing showed is that the halting problem is undecidable on a Turing Machine and a Turing Machine captures the power of a conventional computer. Now by conventional we're excluding things like quantum computer. Now later, many other problems were showed to be undecidable, but the halting problem is quite nice, so we're going to dive into that proof.

NP5 Halting Problem - 573 - Halting Problem
Now let's formally define the Halting Problem. The input to the halting problem is a program P, with an input I for that program P. Now how is this program P given to you? Well, we can restrict it to any language we want. We can say it's in pseudocode, we can say it's in C, Python, but we can say it's in an arbitrary language. Now what is the output of the halting problem? Well, think of the basic task of a compiler. Given a program and an input, we want to figure out if this program terminates on this input, or does it have an infinite loop. That's the task of the halting problem, to figure out whether this program on this particular input runs forever, or ever terminates. So if the program P on input I ever terminate, so it stops eventually, then we output true. We're not trying to figure out whether it runs correctly, whether it gives a correct solution on this input. We're just asking whether the program P ever stops when we run it on input I. On the other side we output false if the program P on input I never terminates. In other words, it has an infinite loop. To summarize, I'm giving you a particular program P, and a specific input I, and on this specific input I, does the program P have an infinite loop? Or does it eventually stop?

NP5 Halting Problem - 574 - HP Example
Let's look an example instance for the halting problem. Let's look at the following simple program P. And I'll attempt to write it in C. My program P consists of one input variable, X, and it consists of one while loop. The while loop checks whether X mod two is equal to one. So it checks whether X is odd. If X is odd, then it adds six to X and it repeats. And it keeps going until X is even. Now let's look at this program P on input X equals five. Now for this simple program, it's easy to see what will happen. X starts at five, and then it'll be 11, and then 17, 23, and so on. X will always be odd. So the program never halts. This is going to be an infinite loop. Now of course, this is assuming infinite memory. So there's no overflows or anything like that. Therefore if we look at halting with this pair of inputs, program P and this input X equals five. Therefore, if I look at halting on this particular pair of inputs, program P and input X equals five, then this program has an infinite loop on this particular input. Therefore, halting of P, five is false. Because the program P never terminates on this particular input, five.

NP5 Halting Problem - 575 - HP Undecidable
Now, let's prove the theorem that the halting problem is undecidable. How can we hope to prove this theorem? We can't expect to come up with an incredibly difficult program for which no algorithm can solve the halting problem on that program. It's more like for every algorithm, there is a program for which the algorithm fails. So the way we go about proving this theorem is by contradiction. Suppose that we had an algorithm that solves the halting problem on every input. Now we're going to derive a contradiction and therefore, our assumption that there exists an algorithm which solves the halting problem is not true. And therefore, there is no algorithm which solves the halting problem. What we're going to do is for this particular algorithm which solves the halting problem, we're going to construct an input for which this algorithm is incorrect. And therefore, our assumption that this algorithm solves the halting problem on every input is incorrect. And we have a contradiction and therefore, that will prove the theorem. Now let's give a name for this algorithm. Now this algorithm is determining whether a particular program on a specific input terminates or not. So let's call this algorithm Terminator. Terminator takes a pair of inputs, P and I. P is a program, I is an input for this program, and Terminator outputs true or false depending on whether this program P, on this particular input I, terminates eventually or not. If it eventually terminates, then an output is true. If it has an infinite loop, then an output is false. And we're assuming that Terminator is correct. It solves the halting problem for every program P, and every input I. Now we're going to construct a program Q and an input J, and we're going to show that when we run Terminator on this input pair Q,J, then its output is incorrect. Since Terminator is incorrect on this pair of inputs, therefore, Terminator does not solve the halting problem on every input. So this will give us our contradiction, and therefore, that would complete the proof by contradiction. Now how can we hope to construct this program Q? Well, one important piece is that we're assuming the existence of this program, Terminator. So we can use this algorithm, Terminator as a subroutine in our new algorithm Q. Now I don't know anything about the inner workings of Terminator so I have to use it as a black box, but I can use this as a subroutine. So we're going to use it as a subroutine to get our paradox or contradiction.

NP5 Halting Problem - 576 - HP Paradox
So consider the following evil program, it's evil in the sense that Terminator algorithm that we assumed existed is going to fail on this program. This new program that I'm going define now. I'm going to call Harmful. Harmful has one input J. First line of harmful is an if statement. We run this Terminator Algorithm which we assumed existed on input J and J. So we use this input for the harmful program. As the program P and the input I for the Terminator algorithm. Now Terminator returns true or false. Now if it returns true then I'm going to go to one. So I have this loop. If Terminator returns false then I simply exit the procedure. Now why did I call this procedure harmful. While this was just a reference to Dijkstra's article from 1968, which was titled GoTo statement is considered Harmful. Anyways I'm allowed to use whatever Programming language I want and any programming style I want. So I choose to use this GoTo statement. It's going to make the loop more apparent in the algorithm. Let's summarize what we just did. We assume the existence of this Algorithm Terminator which solves the halting problem on every input. Now we're going to construct a new program which we call harmful for which the Terminator will show fails. This new program harmful simply has one line. It's just an if, then, else statement. Now we're using this supposed algorithm Terminator as a black box in our harmful algorithm so harmful takes an input J. What we do is we run Terminator on this input pair J J. So J is a program and J is the input to the program J. And we run Terminator on this pair. If Terminator returns true on this input pair then our program goes to one. So we get this loop. If Terminator returns false then we simply exit this procedure and we exit the program harmful.

NP5 Halting Problem - 577 - HP Whats Harmful
Let's detail once again what's happening in this simple program. We're running Terminator on input J, J. What does that do? That runs program J on input J, and Terminator returns true if program J on input J terminates. It eventually halts. And it returns false if J on input J never terminates. It has an infinite loop. So there are two cases, either Terminator of J, J returns true or false. In which case, we either go to the THEN statement or the ELSE statement. Now, if program J on input J terminates so we get a true, then in this case, what happens in the program? So we go to the THEN statement and we have a GOTO(1) and then we have an infinite loop. So in this case, Harmful of J never terminates. It has an infinite loop. Because if terminator of J, J returns true, then we go to one and we have this loop. In the other case, if we get false, then we go to the ELSE statement and we exit the program right away. So Harmful of J terminates.

NP5 Halting Problem - 578 - HP Paradox derived
Here's our summary from the previous slide. If program J on input J terminates, then our new evil program harmful never terminates. It gets into this go to loop, and then it has an infinite loop. On the other hand, if program J on input J never terminates, so it has an infinite loop. Then our new evil program goes into the else statement. And it exits right away, and therefore it terminates. Now, we need to derive a paradox or a contradiction. What we do is we set the input J to be this program harmful which we just defined. So harmful is this short one line program, and we use that as the input to harmful itself. Now the question is, does the program harmful when it takes itself as input, does it terminate or not? Well there are two possibilities, either it does terminate or it has an infinite loop. Let's consider both possibilities. Suppose program harmful when it takes itself as input does terminate. Going up to the above summary, if J on J terminates, then harmful on J never terminates because it gets into this go to statement. So plugging in J equals harmful, we have that harmful on harmful never terminates. So if the program harmful on itself as input terminates, then harmful on itself is input never terminates. That's a contradiction. Therefore this can't be the case. So it must be the case that when we run program harmful on itself as input, then it never terminates. What happens in this scenario? Well, let's look above. In this scenario when J on J never terminates, then harmful on J terminates because it goes into this else statement, and it exits the program harmful immediately. Once again, if the program harmful when it takes itself as input never terminates, then what we conclude is that harmful on itself terminates. Again, we have a contradiction, so this can't be the case. So it can't be the case that it terminates, and can't be the case that it never terminates. Since either case leads to a contradiction, our initial assumption that the program terminator which solves the halting problem on every input exists must be impossible. And therefore there does not exist a program which solves the halting problem on every input. And that completes the proof of the theorem.

