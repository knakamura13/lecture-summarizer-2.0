What we've seen so far is how to use divide and conquer in a clever way to multiply large integers. So for N bit integers, we were able to multiply, compute their product in time better than order n square. A similar idea applies to matrices as well. What we're going to do now is multiply polynomials. And to do this, we're going to use the beautiful divide and conquer algorithm known as FFT. FFT stands for fast fourier transform. So here's the set up. We have a pair of polynomials A of X and B of X. For the polynomial A of X, will denote its coefficients as A knot, A1, A2 up to An minus one. So it's of degree at most n minus one. And for B of X, will denote its coefficients as B knot, B1 up to Bn minus one. And it also is of degree of most n minus one. Our goal is to compute the product polynomial, C of X which is A of X times B of X. And the coefficient of C of X will denote as C knot, C1 up to C2 n minus two. Since the degree of C of X is at most two n minus two. Now recall that the Kth coefficient of the polynomial C of X, so this is denoted by c sub k. This is obtained by taking the constant term for A of X, this is A knot times the coefficient for the Kth term of B of X, this is BK. So I look at A knot times BK and I add that to the other possibilities A1 X Bk minus 1 and so on, up to a Nk times B knot. We want to solve the following computational problem. We're given the vector of coefficients defining A of X and we're given the vector of coefficients defining B of X and we want to compute the vector of coefficients for the product polynomial C of X. Now this vector C is known as the convolution of A and B. So this star symbol denotes the convolution.