RA1 Modular Arithmetic - 101 - Modular Exp. Fast Question
So in the repeated squaring algorithm, we start off the same. We compute X_mod_N and let's store the answer as a_one. Then we compute X_squared_mod_N. How do we get X_squared? Well, a_one is X_mod_N, so we take a_one_squared_mod_N. So far it's the same as the other algorithm. Now we're going to skip X_cubed and we're going to go to X_to_the_fourth. How do we get X_to_the_fourth? We take the previous solution, let's call it a_two and we square that. A_two is congruent to X_squared_mod_N, so if we take X_squared and we square that, then we get X_to_the_fourth. Then we take that solution and let's call it a_four. Now to compute X_to_eighth_mod_N, you take the previous solution and we square that. That gives us X_to_the_fourth_squared which is X_to_the_eighth_mod_N. And we repeat. What do we end up with? We end up with X raised to the powers of two. Then what do we do? We look at the binary representation of Y and then we can use the appropriate powers of two and we can get X_to_the_Y_mod_N. Let's look at a specific example so you illustrate the idea better.

RA1 Modular Arithmetic - 103 - Mod Exp Algorithm
Here's the key fact that we're going to use. For even y, when we divide y by two we get an integer. So x to the y is the same as x to the y over two squared. What happens for odd y? Well, we got to be careful because when we do y divide by two, we get a fractional amount. So, for odd y, when we want to look at x to the y, let's take out an x, so that we look at x to the y minus one. Let's take out that x. Now, we're going to take y minus one, divided by two, which is the same as y over two floor. So, we take y over two and we round it down. So, we drop the fractional part. We raise x to that power and then we square it. And we multiply by the extra factor of x, and we get x to the y. Now, let's take this simple observation and detail a divide and conquer algorithm for modular exponentiation. And these three input parameters, x, y, and capital N are all little n-bit integers. And let's assume there are non negative integers. And our algorithm is computing x raised to the power y, mod, capital N. This can be a recursive algorithm. So, let's start with the base case. The exponent is going to keep going down. The base case is going to correspond to y equals zero, in which case we're taking x to the zero, which is one. So, when we take that mod N, that's also one, assuming N is at least one. So, let's, uh, let's actually assume here that N is positive number. Now, let's look at the general case, what are we going to do? We're going to compute this x to the y over two. If y is odd, then we got to round it down. If y is even, we don't have to worry about rounding it down. But, if we round it down, it doesn't make any difference. So, we're going to recursively call this algorithm with x, raise to the power y over two, round it down, mod capital N. We store that answer in z. Now, we check whether y is even and we follow this case, or y is odd and we follow this case. In the case when y is even, then we want to take the z, which is x to the y over two, and we want to square it, take it mod N, then return the answer. So, we're going to return z squared, mod, capital N. In the other case, when y is odd, we have to take z squared, which is the inner term, and then multiply by x. So, in this case, we want to take x times z squared, mod N. And that's our answer when we return.

RA1 Modular Arithmetic - 104 - Multiplicative Inverse
A key concept that we're going to need for the RSA algorithm are multiplicative inverses. Now the concept is a bit subtle for a modular arithmetic. Let's go back and look at the normal, real numbers and see what multiplicative inverses mean there. If we take a number three, what's its multiplicative inverse, it's one third. And so if we look at three times one third what do we get? We got one. And in general for a number a, it's multiplicative inverse is one_over_a. And, when we multiply those two together what do we get? One. Now we're going to have a number z and we want to look at its inverse mod N. So we want to know what one_over_z_mod_N is. So we're going to define it as the number, so that when we do z_times_one_over_z we get back one. So our definition of the inverse of z_mod_N, this is number x, so that if we do x_times_z, we get one_mod_N. In this case x is the inverse, it's one_over_z_mod_N. And the notation is that x is z_to_the_negative_one, same as one over Z. So x is z_to_the_negative_one_mod_N. So x is the multiplicative inverse of z_mod_N. Notice also, that if x is the inverse of z_mod_N, then z is the inverse of x_mod_N, because x_times_Z is one_mod_N. So, x is the inverse of z and z is the inverse of x_mod_N. Now let's go ahead and look at a specific example to make sure this notion of multiplicative inverse modulo N makes sense.

RA1 Modular Arithmetic - 105 - Inverse Example
So, let's take the example where capital N is 14 and let's look at the inverses of the numbers one through 13, mod N. Starting with X equals one. So, what is the inverse of one mod N 14? What is the number so that one times that number is one mod 14? Well, One times itself is one. So, the inverse of one is one itself. It a self inverse. And that's always the case. One is always itself inverse. Let's do a non-trivial case where x equals two. What's the inverse of two mod 14? What number times two is congruent to one mod 14? Well, actually there is no number where that's the case. So, the inverse of two mod 14, does not exist. Let's try X equals three. What's the inverse of three mod 14? Well, notice three times five is 15 which is one, mod 14. So, the inverse of three is five. And the inverse of five is three mod 14. What about X equals four? What's the inverse of for a mod 14? Once again, just like the case of X equals two, that doesn't exist. What about X equals five? We already solve that. Its inverse three. How about six, seven and eight? Actually, none of those have an inverse mod 14. What about nine? What's the inverse of nine mod 14? This is 11 because nine times 11 is 99 and 14 times seven is 98. So, nine times 11 is one mod 14. The last one is, what about 13? What's the inverse of 13 mod 14? It turns out it is a self inverse. It's 13 itself. 13 times 13 is one mod 14. All the other cases the inverse doesn't exist. When exactly does the inverse exist or not? What is the key fact about when the inverse exists or not? When two, four and six. Those are all even numbers. And 14 is an even number. So, they all have a common divisor too. Okay. What about seven? Well, seven is not even but it shares a common divisor with 14, seven. So, that's the key property. They share a common divisor. Then there is no inverse. But if they have no common divisor and in which sense, which case they're feel like primes relative to each other, then there is an inverse. So, one, three, five, nine and 13 have no common divisor with 14.

RA1 Modular Arithmetic - 106 - Inverse Existence
so when exactly are their multiplicative inverses or not the general theorem is that X inverse mod an exists if and only if X and n have no common divisor so the greatest common divisor is one GC D stands for a greatest common divisor so if they're both even then 2 is a divisor of both so the GCD is at least 2 might be bigger what's at least 2 now just some terminology when the greatest GCD of X and n is 1 so they have no common divisor then we say that X and n are relatively prime with respect to each other they feel like primes to each other for instance 9 and 14 neither one is prime but with respect to each other they have no common divisors so they feel like Prime's to each other so the theorem says that if these numbers are prime relatively prime to each other then there is an inverse but if they have a common divisor then there is no inverse let's look at why this theorem holds but before we get into it let's look at some basic properties about inverses

RA1 Modular Arithmetic - 107 - Inverse Terminology
Suppose that X has an inverse mod N. So, X inverse mod N exists. Let's prove that this inverse, if it exists, is unique. What exactly do we mean by unique? Well, let's consider a specific example. Here's a simple example. X equals three and N equals 11. What's the inverse of three mod 11? Well, these numbers are quite small, so it's easy to figure out that the inverse of three mod 11 is four, because three times four is 12, which is one mod 11. Now, if we look at four mod 11, there are an infinite number of equivalent numbers. For example, 15, 26, and so on, these are all congruent to four mod 11. We can also look at negative numbers, negative seven is congruent to four mod 11. And there are an infinite number of such numbers which are equivalent to four mod 11. All of these numbers are inverses of X mod N, but for concreteness, we'll always report the inverse of X mod N as the smallest non-negative integer. So, we report it as the integer between zero and N minus one, if that inverse of X mod N exists. And if the inverse of X mod N does not exist, we simply report does not exist. Now, later in this lecture, you'll see how to find the multiplicative inverse if it exists. And to do that, we'll use the extended Euclid algorithm. In that case, often, the algorithm will return the negative number and then we'll have to do a simple calculation in order to convert it to a number, an integer between zero and N minus one.

RA1 Modular Arithmetic - 108 - Inverse Unique
Now, let's go back to our original question. Suppose X inverse mod N exists, how many such inverses can there be? So, in this example, three has an inverse mod 11, four is one such inverse. Are there any other inverses? When we're looking at integers between zero and 10, what's easy to check that four is the only integer between 0 and 10 which is an inverse of three mod 11. And what we want to prove now is that if X has an inverse mod N, then there is a unique such inverse. So, there is only one such inverse. Let's prove now that if the inverse exists, it's a unique choice. So, there's a unique number between zero and N minus one, which is an inverse of X mod N. How are we going to prove this? Let's prove it by contradiction. So, let's suppose that X mod N has two inverses. And then, let's show a contradiction. So, suppose that Z is an inverse of X mod N, and suppose that Y is also an inverse of X mod N. And let's suppose that these numbers Y and Z are different. What do we mean different? We mean, they are different mod N. So, we're assuming that Y and Z are different mod N. This means that if we think of the Y and Z as numbers between zero and N minus one, Y and Z are different. For this small example for these small numbers, it's easy to verify that this number three can have multiple inverses mod 11. We want to prove, in general, that if a number X has an inverse mod N, and that inverse is unique. So, we're assuming that there's multiple inverses of X mod N. And we're denoting those as Y and Z. And now we're going to derive a contradiction. Now Z is an inverse of X mod N, so what does that mean? That means that if we look at the product of X and Z that congruent to one mod N. That's the definition of an inverse. Similarly, if we look at Y, we know that X times Y is also congruent to one mod N. Therefore, X times Y is congruent to X times Z mod N. Now, we know that the inverse of X mod N exists. Actually, we're supposing that there's multiple such inverses. Anyways, take one of those inverses and multiply both sides of this equation by that inverse. So, multiply the left side and the right side by X inverse. What do you get? Well, X inverse times X is one, X inverse times X is one, so we can cancel these terms, and we can cancel out these terms. And what are we left with? We are left with the Y and Z. So, the left-hand side simplifies to Y, the right-hand side simplifies to Z. Let's forget this one. And we know that Y is congruent to Z mod N. But our assumption earlier was that Y is not congruent to Z mod N, that these are different numbers between zero and N minus one. Therefore, we derived our contradiction, and thus, our assumption that there is multiple inverses of X mod N is not true. So, if the inverse of X mod N exists, it's a unique such inverse. It's unique when we look at these numbers between zero and N minus one. Later, we're going to prove that if X and N are relatively primes, so the GCD of X and N is one, then the inverse of X mod N exists. How are we going to prove that? We're going to prove that this inverse exists by finding it. We're going to show an algorithm extended Euclid algorithm to find the inverse, when the GCD of X and N is one. But, on the next slide, we'll prove that if X and N have a common factor, so the GCD of X and N is greater than one, then the inverse of X mod N does not exist.

RA1 Modular Arithmetic - 109 - Inverse Non-existence
Let's look at the case when multiplicative inverses do not exist. Why don't they exist? So in the case where X and N have a common divisor. So their GCD is strictly greater than one, in which case this theorem says that the inverse of X mod N does not exist. Let's take a look at why that happens. Let me give you the intuition for the proof. Let me do the simple case where X and N both even. So then they have a common divisor of two. If you understand this case then you can understand the general case. Suppose X did have an inverse mod N, let's call it Z. So what does that mean? That means that X times Z is congruent to one mod N. So how can XZ be congruent to one mod N? That means XZ is either N+1 or it might be 2N+1 or 3N+1. In general, it's some multiple of N+1. So it's QN+1 for an integer Q. Now X we assumed was even. So what is X times Z? Even number times some other number is going to be an even number. Okay? Because it still has two as a divisor. Okay. So XZ is even because X is even. Now N is even. So what about Q times N? That's going to be even as well just the same as before. So XZ is even and QN is even. What about QN+1? We take an even plus one we got an odd number. So this is an odd number. This is an even number. How can they be equal? They can't be equal. So that's our contradiction. Therefore, there is no inverse of X mod N. And similarly, if X and N just share a common divisor then you have a similar proof to explain why the inverse does not exist. Now the interesting case is when they are relatively prime to each other, so their greatest common divisor is one. So they have no common divisors except for one. Then the inverse exists. Why is that the case? Can we prove why the inverse exists? We'll prove it exists by actually giving an algorithm for finding it. We'll actually find it and by finding it we prove its existence. Okay? What is the algorithm we're going to use for finding it? Well some of you might have seen Euclid's algorithm before for computing the greatest common divisor. So even if we want to check whether the inverse exists or not we have to compute the GCD of X and N. Check whether they're relatively prime to each other. I mean these are big numbers so it's not easy to just eyeball and check. So we got to run an algorithm to check the greatest common divisor and see whether it's one or not. That algorithm for that is Euclid's algorithm which is very simple recursive algorithm and we're going to see it in a moment. And then a slight modification of Euclid's algorithm is extended Euclidean algorithm and that extended Euclidean algorithm will give us the greatest common divisor of X and N and if the greatest common divisor is one it will give us the inverse of X mod N. And therefore, that will prove the existence of the inverse of X mod N. Okay? So let's go ahead and dive into Euclid's algorithm and the extended version of the algorithm to find the inverse.

RA1 Modular Arithmetic - 110 - GCD Euclids Rule
Before diving into Euclid's algorithm, let's look at the basic fact which is called Euclid's rule which is the basis for Euclid's recursive algorithm. Let's take integers X and Y. And we want to compute the GCD of X and Y. And let's assume for simplicity that X is at least Y. So the order. And let's assume that Y is greater than zero. Then the basic fact is that the greatest common divisor of X and Y is the same as the greatest common divisor of X mod Y and Y. And notice these are now in reverse order because Y is going to be at least X mod Y. So if we want to compute the GCD of X and Y then given this fact we can compute the GCD of X mod Y with Y. And that's going to be the basis of our recursive algorithm. But let's first see why this is true. Here's a basic proof idea. The proof relies on the following simple fact. The GCD of X and Y is equal to the GCD of X minus and Y. Let's call this star. Notice, if we play star repeatedly, we get the theorem statement. GCD of X and Y is equal to the GCD of X mod Y and Y. How do we get X mod Y? We get X mod Y by taking X and subtracting off Y repeatedly. Let's say Q times. So we take off as many Y's as we can from X and then we take the remainder and that's X mod Y. So it keeps subtracting Y, and Y, and Y, and Y repeatedly until we're left with a number smaller than Y. So we keep applying this X minus Y. So we take X, X minus Y, and then that thing minus Y, minus Y, minus Y again, again. Q times and then we end up with X mod Y. So if we prove this fact star then that implies this theorem statement. So it suffices to prove star and then that implies the theorem. Okay, and then the star is a bit simpler statement than the theorem statement. So why's star true? Let's look at why that's true. You can think of this as if and only if. If a number D divides X and Y then it divides X minus Y and Y. That's the number D divides X minus Y and Y then it divides X and Y. So any divisor of these two, it's a divisor of these two. Any divisor of these two, it's a divisor of these two. If we prove that, we're done. So we can think as a if and only if. Given a divisor here of these two, it divides these two. Let's do that statement first. If D divides X and Y then clearly it divides Y. Ready. And D divides X minus Y as well. If it divides X and Y then it obviously divides X minus Y as well. You can factor out D from X and from Y so you can factor it out from X minus Y. That gives this one direction, the forward direction. What about the reverse direction? So if D divides X minus Y and Y then D divides X as well because X is just the sum of X minus Y plus Y. So it divides both of these then it divides their sum. So that gives us the reverse direction therefore they have all the divisors in common, so the greatest divisor is also in common. That proves this statement star which implies this Euclid's rule. Here is Euclid's rule that we saw in the last line. GCD of X and Y is the same as the GCD of X mod Y and Y. Now, let's use that basic fact and design of recursive algorithm for computing the GCD. It's called the Euclid's algorithm.

RA1 Modular Arithmetic - 111 - GCD Euclids Algorithm
What we just saw is the following fact known as Euclid's Rule. The gcd of x and y is the same as the gcd of x_mod_y and y. This leads to a natural, recursive algorithm which we'll now detail. Here's Euclid's GCD algorithm. The input to the algorithm are two integers, x and y. And we'll assume these input parameters are ordered so that x is at least y and that both of these integers are non-negative. And the output of the algorithm is the gcd of x and y. This is the recursive algorithm, so let's start with the base case. The base case will be when y, the smaller parameter, is equal to zero. When y equals zero, so we're looking at the gcd of x and zero, we're going to return x as the gcd. Now, to be honest, this case actually is confusing to me. So, we'll go back and we'll discuss this more in a little bit more detail after. Now, in the general case, we're just going to apply Euclid's rule. Euclid's rule tells us that the gcd of x and y is the same as the gcd of x_mod_y and y. So, we're going to return the recursive call of Euclid's algorithm on y and x_mod_y. We flip the order of these two parameters in order to maintain the fact that the first parameter is at least the second parameter. That completes the pseudocode of the algorithm. Let's go back and look at the space case a little.

RA1 Modular Arithmetic - 112 - GCD Base Case
In the base case of our algorithm Y equals zero. So, we're looking at the GCD of X and zero. What are the divisors of zero? This is a case where we should define it in an appropriate way. What is an appropriate way? What is a reasonable manner of defining the divisors of zero? Well, how do we get to this case? We got to this case by taking the GCD of sum multiple of X with X. Because look at what happens when we do the recursive call on this. We're going to take kX, mod X, and that's going to be zero. So, the second parameter is going to be zero and the first parameter will be the second parameter. Now, what is the GCD of kX and X? Well, this is clearly X, since the first parameter is a multiple of X. So, this is why we define the GCD of X and zero to be equal to X.

RA1 Modular Arithmetic - 113 - GCD Running Time
Let's take a look at the running time of Euclid's algorithm. The only non-trivial step in each round is computing X mod Y. How long does that take to compute? Well that involves dividing X by Y which takes the order N squared time, where N is the number of bits. So the time is order N square time per round. How many rounds or recursive calls do we have in this algorithm though? Here's the key lemma for figuring out the number of rounds. If X is at least Y which is the case for our algorithm the first parameter is always at least the second parameter. Then X mod Y, which is the second parameter in our recursive call, that's the only parameter which is changing, is strictly less than X over two. So the one parameter which is changing goes down by a factor of at least two. So let's take a look at the algorithm. Let's say we have a call with X and Y, then a recursive call is going to be Y, X mod Y. What happens in our next recursive call? Well this second parameter is going to become the first parameter. So we get X mod Y, is the first parameter. What's the second parameter? The second parameter is Y mod X mod Y. Okay, it's a little bit hard to write. Let's skip it. It's not important. What does this lemma tell us? It tells us this X mod Y, which is right here, this is strictly less than X over two. So notice after two rounds of the algorithm, what happens to the first parameter? It went down by least a factor two. So how many rounds does the algorithm have? It's going to have at most two N rounds. Why? Because every other round we've shown the first parameter goes down by a factor of at least two. Since we have order N rounds and we have order N squared time per round, the total running time is order N cubed. So we've established the running time of the algorithm modulo this lemma. Let's go ahead and prove this lemma which is would be quite straightforward to prove. Once we break it up into the appropriate cases the proof will be almost immediate. We're going to break it up based on the size of Y, either Y is small and then X mod Y is immediately small, or Y is big and then we'll figure out another reason why X mod Y is small. So let's first take the case where Y is small. Let's say Y is at most X over two. What do we know about X mod Y? How big can it be? The largest it can be is Y minus one which is smaller than Y. What we know about Y? Y is at most X over two. So what have we shown? We've show that X mod Y is strictly smaller than X over 2 which is what we're trying to prove. Now let's take the case where Y is big. Y is strictly greater than X over 2. What do we know about X divided by Y? Well Y goes into X at most one time. So this is one. So what does that imply about X mod Y? In order to get the remainder when we do X divided by Y, we just have to subtract off Y one time from X. So X mod Y is equal to X minus Y. Well we know that Y is strictly greater than X over 2, so X minus Y is strictly smaller than X minus X over 2 because Y is strictly bigger than X over 2. And this is clearly at most X over 2. And that's what we're trying to prove. We prove that X mod Y is strictly smaller than X over 2, which is what we're trying to prove in the lemma. That completes the proof of the lemma, and therefore we've shown that the running time of Euclid's algorithm is order N cubed time.

RA1 Modular Arithmetic - 114 - Computing Inverses
Now, let's look at how we compute inverses. To do this, we're going to use the extension of Euclid's algorithm called the Extended Euclidean Algorithm. Euclid's algorithm takes as input two parameters X and Y. And the same will be true for Extended Euclidean Algorithm. These parameters x and y are integers, and we assume that these parameters are ordered, so that x is at least y and both of these are non-negative. Now, here's the difference: the output of the algorithm here is three parameters--the alpha and beta. These are integers. Now D is the gcd of x and y. So, if we just pay attention to the first parameter d, this will behave just as in Euclid's algorithm. Now, what are these additional parameters alpha and beta? Well these parameters alpha and beta satisfy the following relation. D is guaranteed to equal x times alpha plus Y Times beta. Well, this is a bit mysterious, why do I want an alpha and beta which satisfy this relation? Let's look at, why it's useful to have an alpha and beta satisfying this relation. Recolor goal is to compute inverses. We're going to be in a setting where we're going to run extended Euclide on x and capital N. We're trying to compute the inverse of x mod N. First off, do we know that this inverse exists? Well, we have to look at the gcd of x and N, to see whether the inverse exists. We need them to be relatively prime. We need that the gcd of x and N is 1 and then the inverse exists. Well, when we run extended Euclid algorithm, d the first parameter gives us the gcd of x and y. In this case it's x and N, so if d equals 1 then we know the inverse exists. So where in this scenario where d equals 1, when we run extended Euclid on x and N and we get back this alpha and beta which satisfy this relation. So we know that one equals x times alpha plus N times beta. Now from this alpha or this beta, can we figure out the inverse of x mod N? Well this relation is true, so now if we take mod N of both sides, then the relation will still be true. So, now we have that 1 is congruent to X alpha plus N times beta mod N. Now can we simplify this? Yeah, look at the second term here on the right hand side. This is N times beta. This is a multiple of N, therefore it's zero mod N. So, we are going to place N times beta by zero. So, that goes away and what are we left with, we're left with one is congruent to x times alpha mod N. That means that alpha is the inverse of x mod N, because alpha is the integer where X times that integer alpha is congruent to 1 mod N, that's the definition of its inverse. So, we shown that alpha is the inverse of x mod N, in the case where d, the gcd of the two parameters, is equal to 1. And similarly beta is the inverse of an N mod x. So, in the case where these two parameters are relatively prime to each other, so their gcd is 1, so d equals 1, then alpha gives the inverse of x mod y and beta gives inverse of y mod x.

RA1 Modular Arithmetic - 115 - Inverses Ext. Euclid Alg. Question
Let's go ahead and detail the extended Euclid algorithm. Recall, it takes two parameters as input X and Y where X is at least Y and we're going to output three parameters. D alpha and beta. D is the GCD. So, if we just look at the first parameter, it's going to behave like Euclid's algorithm and we're also going to output this alpha and this beta, which satisfy this relation. Let's start again with the base case. So, when Y equals zero, where do we return.? Well, the first parameter D is the GCD. So, that should be equal to X. Now, we want to find alpha and beta which satisfy the relation, where D in this case is equal to X. So, we want X equals X times alpha plus Y times beta. Well, that's easier to satisfy. We can just say alpha equal to one, and beta equal to zero. That takes care of the base case. Now, for the general case, we're going to use Euclid's rule, which says that the GCD of X and Y is equal to the GCD of Y and X mod Y. So, we recursively call this algorithm on Y and X mod Y. That's going to return three numbers, D, alpha, beta. Let's call it D alpha prime, beta prime. Now, we're going to have to do a little bit of manipulation of these three parameters, in order to get our output for X and Y. Now, we know the first parameter stays the same. The GCD of these two parameters is the same as the GCD of X and Y. Now, what do we know about alpha prime and beta prime? Well, we know that D equals Y times alpha prime plus X mod Y times beta prime. Now, in order to find an alpha and beta which satisfy this relation for X and Y, we have to do some algebra to manipulate this alpha prime and beta prime. It turns out that it's sufficient to set alpha equal to beta prime, and we set beta equal to alpha prime minus X divided by Y, rounded down times beta prime. In order to see where this quantity comes from, you got to look at the proof of correctness which is not too bad, but it's just a bit of algebra. I'll refer you to the textbook for the details on that proof of correctness. That completes its pseudo code for the extended Euclid algorithm. Finally, what's the running time with this algorithm? Well notice, each step, the non-trivial operations are X mod Y and there's little bit of algebra, right here. So, it takes order N squared time per round, and the number of rounds is order N just like Euclid's algorithm. So the total run time is order N cube time.

RA1 Modular Arithmetic - 117 - Mod. Exp. + Inverses Recap
Let's recap what we've seen so far. We've seen the Modular Arithmetic definition, X mod Y. The first non-trivial algorithm that we saw was computing modular exponentiation using the repeated squaring idea. This gave us an algorithm which was polynomial in the number of bits, little n. This modular exponentiation algorithm is gonna be a key component in the RSA algorithm. We're gonna have numbers X, Y and capital N and we're gonna have to compute X raised to the Y mod N. And these numbers X, Y and capital N are all gonna be huge number of bits. So we're gonna have to compute this modular exponentiation, in time polynomial, in the number of bits, not in the size of the numbers. So it will be key that we use this Fast algorithm that we devised. The other key concept that we looked at were multiplicative inverses. For example, X inverse mod N. What we saw is that this inverse exists, if and only if, these two numbers are relatively prime. In other words, that their GCD is one. How do we check that they're relatively prime? How do we check their GCD? Well, we can compute their GCD using Euclid's algorithm. Now if they are relatively prime, how do we compute their inverse? Well we saw how to compute their inverse using the extended Euclid algorithm. So those are the key algorithms that we're gonna use in our RSA cryptosystem. Euclid's algorithm, extended Euclid algorithm and this Fast modular exponentiation. Now, we can dive into their RSA cryptosystem.

RA1 Modular Arithmetic - 92 - Randomized Algorithms
Now we'll dive into randomized algorithms. Hopefully at the end, you'll appreciate how randomness is a beautiful and powerful algorithmic tool. We'll start with cryptography. We'll look at the amazing RSA Cryptosystem. This is one of the most widely used Cryptosystems. It's extremely elegant. Once we learn some of the basic mathematics about modular arithmetic, you'll appreciate the ingenuity of the RSA protocol. Then you'll have a basic understanding of how these Cryptosystem that we use everyday, many times a day in fact, actually work. Another beautiful and incredibly useful application of randomized algorithms that we'll study is for hashing. We're going to look at a hashing scheme known as Bloom Filters. This is a simple scheme that's quite popular in many different fields. We'll look at the mathematics behind it. This will involve some basic probability analysis and then you'll do a programming project to implement and study Bloom Filters.

RA1 Modular Arithmetic - 93 - RSA Lecture Overview
Let me give you an overview of the topics that we're gonna study in this lecture. Now the mathematics of the RSA cryptosystem are very beautiful and they're fairly simple once you have the right mathematical background. So we're going to start with a short primer on the mathematical topics that we need. The relevant topic that we need is Modular Arithmetic. Some of you may have seen this before, so it might be a reveal, for others it's fairly simple to learn. Then one key concept that we need are multiplicative inverses, and what they mean in modular arithmetic. And then we're gonna look at Euclid's GCD algorithm, greatest common divisor, which is gonna be used in the RSA cryptosystem. Next we're going to learn about Fermat's Little Theorem and it's the key tool in the design of the RSA algorithm. So at this point we'll be able to detail the RSA algorithm. Finally, we'll look at Primality testing, given a number, can we test whether the number is prime or not, or composite? Once we see how to do that using Fermat's Little Theorem, then we're going to be able to generate random primes. Generating random primes is a key component in the RSA algorithm. So once we complete that, we'll have completed our discussion of the RSA algorithm. Now let's go ahead and dive into the algorithms related to the RSA.

RA1 Modular Arithmetic - 94 - Huge Integers
Lets look at the context of the RSA algorithm. In cryptography, we're going to work with N-bit numbers X, Y and N. For example, the number of bits in these numbers is going to be huge. Think of the number of bits as 1024 or 2048. It's a huge number of bits. So normally, we thought of our arithmetic operations as built into hardware, but that usually restricts the attention to 64 bits or so. But here we're talking about 1000 or 2000 bits. So we have to go back and review how long does it take for basic arithmetic operations.

RA1 Modular Arithmetic - 95 - Modular Arithmetic
Now let's take a look at modular arithmetic. This is the basic mathematics that underlies the RSA algorithm and we're going to see a lot of beautiful mathematics along the way. Let's look at a simple example, X modular two where X is an integer. What is X mod two? This is the least significant bit of X. What does the least significant bit of X tell you? It tells you whether X is odd or even. In particular, it's one if X is odd and zero if X is even. Now, what's another way of looking at this least significant bit of X? Well, we can take X divided by two. If it's even then the remainder is going to be zero because it's a multiple of two, and if it's odd, then the remainder when X divided by two is going to be one. So we looked at X mod two. Now let's look at X mod N where N is an arbitrary integer at least one. Recall X mod two is the remainder when we do X divided by two. So X mod N is going to be the remainder when we divide X by N. Finally let's look at some important notation for modular arithmetic. Suppose we have two numbers X and Y, and we look at these two numbers modular N, and suppose that they're same mod N, how do we denote that? Well, they're not equal. The two numbers are not equal, but they're congruent in this, or they're equivalent in this world modular N. So how do we denote that equivalence or congruence? So the standard indication is three lines instead of two lines. So this notation means that X and Y are congruent modular N, which means that when we look at X divided by N, and Y divided by N, they have the same remainder, and we denote that by three lines, X is congruent to Y modular.

RA1 Modular Arithmetic - 96 - Example Mod 3
Look at a simple example to make sure everybody understands the concept of modular arithmetic. Let's look at numbers modulo three. When you look at the number mod three, there are three possible values, zero, one, or two. Hence, there are three equivalence classes for the numbers modulo three. Now we set three mod three is also zero. Same with six, nine, and so on. All the multiples of three. Similarly four mod three is one. Same with seven, and 10, and so on. Finally, five mod three is two. Same for eight, and 11, and so on. But look, we can also go negative. What is negative three mod three? Well, negative three divided by three is negative one, and the remainder is zero. So negative three mod three is zero. Same for negative six, negative nine, and so on. Now if I look at negative two mod three, then it is one. Why is that? X mod N equals R means that when I divide X by N, I get a remainder of R. What does that mean? That means that there are some multiple of N, so I can take Q copies of N, and I have to add an R, and I end up with X. Now look at negative two mod three. That is one. Why is that? So if I look at negative two divided by N, what do I get? I get negative one. So negative two, I have Q equals negative one times three. So there's negative three plus one, so, R equals one. And I end up with two. So the remainder is one. So negative two mod three is one. Similarly, negative five mod three is one. Negative eight mod three is one as well. Finally, negative one mod three is two. Same with negative four mod three is two, and negative seven, and so on. So these three equivalence classes all of these numbers, negative nine, zero, nine, are all the same with respect to modulo three. They're all congruent mod three. These numbers are congruent mod three. These numbers are congruent mod three.

RA1 Modular Arithmetic - 97 - Basic Fact Question
Here's a basic fact that we're going to use repeatedly throughout our work. Let's say I have two numbers, x and y, which are congruent mod N. And I have two additional numbers, a and b, which are also congruent mod N. Now, the point is, that with respect to mod N, x and y are equivalent and a and b are equivalent. So, I can replace one by the other. More precisely, suppose I'm looking at x plus a mod N. Well, x is equivalent to y, so I can replace x by y, and a is equivalent by b, so, I can replace a by b. So, x plus a mod N, is congruent to y plus b mod N. I can replace x by y and a by b. Similarly, if I look at x times a mod N, instead of adding or multiplying, then I can do the same replacement operation. So x times a mod N, is congruent to y times b mod N. Now let's look at an example to illustrate the usefulness of this basic

RA1 Modular Arithmetic - 99 - Modular Exp. Naive Question
We've seen the definition of the modulo operation, the basic modular arithmetic operation that we're going to do repeatedly is modular exponentiation. So, the setting is that we have n-bit numbers X, Y, and capital N, and our goal is to compute X raised to the power Y modular N. Now recall, little n, the number of bits, is going to be huge. For example, we might have little n, the number of bits, be about a thousand or 2000 in which case these numbers, X, Y, and capital N, are on the order of about two to the thousand or two to the 2000. S, o we want an efficient algorithm to compute X raised to the power Y mod N. By efficient we want polynomial in little n, because little n is the size of the input, to represent these numbers it takes little n bits. So, we want polynomial in the input size, which is polynomial in little n. We don't want polynomial in the numbers themselves because the magnitude of these numbers is exponential in little n. These are huge, if we had running time which was polynomial in two to the thousand that would be enormous. There was no way we could run such an algorithm. So, let's look at the time it takes to compute X raised of the power Y mod N. So, let's start off with a simple algorithm for computing X to the Y mod N. We start off by computing X mod N, let's call that a1. Then what do we do? We compute X squared mod N. Now x squared, that's going to be a1, which is x mod N, and then multiply that by x. So, we take the previous solution, a1, multiply it by x and then take that mod N. Then for x cubed mod N, we take the previous solution, let's call that a2, and we take the a2 and we multiply by x and we take it mod N. And we keep repeating finally for X to the Y in the last round we take the previous solution, which is aY minus 1, and we multiply by x and we take in mod N. Now, how long does this algorithm, this simple algorithm take? Let's look at one round. What are we doing? Let's look at x cubed here. So, we're taking this number a2, which is an n bit number because it's at most capital N minus one. Okay? So, this is n bit number, x is an n bit number. How long does it take to multiply two n bit numbers? That's just normal real arithmetic. That has nothing to do with modular arithmetic, okay? So, we're multiplying two n-bit numbers that takes order n squared time, and then we're taking it mod capital N. How do we do that? We take this order n-bit number and we divide it by this order n-bit number and we take the remainder. How long does it take to divide two n-bit numbers? That's order n squared time. So, this takes order n squared time for this one operation. How many rounds, how many operations do we have? How many ai's do we have? We got y ai's. How large is y? y is n-bits, little n-bits. So, y is at most two to the n. So then, the total runtime of our algorithm is order n squared time per round, and then the number of rounds is on the order of y, which is at most two to the n. So, that means the total runtime of our algorithm that we just described is n squared times 2 to the n. It's an exponential time algorithm, exponential in the input size, little n. So, this is a terrible algorithm. If we have little n even, let's say, about 30 there's no way we could run such an algorithm. And we're going to be looking at a little n which is on the order of about 1000 or 2000. So, this is enormous. So, what do we do better? We used the basic idea of repeated squaring, which you've probably seen many times. So, instead of taking the previous answer and then multiplying by X, we're going to take the previous answer squared and that's going to give us the powers of two. Let's go ahead and in detail

RA2 RSA - 118 - Fermats Little Theorem
Before we dive into the RSA cryptosystem, we're going to dive into the mathematical concept which is the basis for the whole cryptosystem. The key concept is Fermat's little theorem. Take a prime number P, then for every number Z, which is at most, P minus one and least one. If we look at Z raised to the power P minus one mod p, what is that going to equal? That's going to be congruent to one. So for any Z, which is relatively prime to P, so this statement here, can be replaced by any Z, which is relatively prime to P. So the gcd of Z and P is one. For any such Z, if P is prime, if we take Z, raiseed to the power P minus one is going to be congruent to one mod p. This easy to state fact is going to be the basis of the RSA cryptosystem. It's also going to be the basis of a primality testing algorithm. So, if we're given a number x, and we want to test whether x is prime or not, we're going to devise an algorithm based on Fermat's little theorem. Now, we're going to look at the proof of Fermat's little theorem. It's not too hard, it's not too easy, it's reasonable proof, but it's a very beautiful proof, very elegant. And there are several important ideas in the proof. For example, how does it come up that P is prime? How does that come into the proof? Just a little bit of foreshadowing, if P is prime, what does that tell you about Z? Well, these- Z's are all relatively prime to P. So, what does that imply? What that implies that these Zs all have an inverse mod P. That's the key thing about a prime number P and that's going to come out in the proof. One last historical note. This is Fermat's little theorem, it's not Fermat's last theorem. Fermat's last theorem is the one which he claimed to have a proof and he couldn't fit it into the margin and which was proofed roughly 400 years later by Andrew Wiles, after 10 years of hard work. So, this Fermat's little theorem is quite easy to prove and we're going to prove it now. We'll go through the proof of Fermat's last theorem in the homework. Don't worry, we'll give you a few hints.

RA2 RSA - 119 - Fermats Thm. Proof
So, here's Fermet's little theorem again. For prime number p, for every z between one and p minus one, if we look at z raised to the power of p minus one and take in mod p we end up with one. So well let's look at the proof of this theorem. Let me look at the set of possible z's. What are these? These are all the numbers between one and p minus one. One, two, three up to p minus one. Let's define the set s as the possible z's. So, these are the numbers one, two, three up to p minus one. Which is defined in this set s. Now let's look at another set s prime. S Prime is going to be defined by taking the elements of s, each of these p minus one elements, multiplying each one by z. So we got z times s and then for each of those elements we take it mod p. So the first element is going to be one time z mod p. The second element is going to be two times z mod p. The last element is going to be p minus one times z mod p. Let's look at a simple example. Let's take p as seven and let's take z as four. First off, what's the set S? S there are the numbers one, two, three, four, five, six. What's S prime? Well, the first element is one times four which is four mod seven, which is going to be four. The second element is going to be two times four which is eight mod seven which is one. The third element is going to be three times four which is 12 mod seven which is five and four times four is 16 mod seven is two. Five times four is 20 mod seven is six. Finally six times four is 24 mod seven is three. Look at this set. It's the same as s except in different order. So the set of elements are the same just it's a permutation of s. So the key thing is that s and s prime are the same sets, just in different order. Let me prove to you this fact, that in general s and s prime are the same sets and then we're going to use this fact that s and s prime are the same sets to prove the Fermet's little Theorem.

RA2 RSA - 120 - Proof Key Lemma
Let me prove to you now that this fact that S and S prime are the same sets, just in different order. Recall S as a set one, two, three, up to P minus one, where P is a prime number from the hypothesis of the theorem statement. And the set S prime is the following, first element is Z mod P, the second element is 2Z mod P, and so on. The last element is P minus one times Z mod P. Now let's go ahead and prove that S and S prime are the same. We're going to show that the elements of S prime are distinct and non-zero. What are the possible values for the elements of S prime? We take them all mods P, right? So they're all between zero and P minus one. Okay. So those are possible values, zero up to P minus one. Now if we show they're all non-zero then the possible values are one, two, up to P minus one. So, this P minus one possible values. How many elements are there in S prime? Well there's P minus one elements in there. So, since the size of S prime is P minus one, and the possible values are P minus one possible values. So if they're all distinct then they must contain exactly each of these elements one time and, therefore, it's the same. S prime is the same as S, just in possibly different order. So, once we show that the elements of S prime are distinct and non-zero, we're done. Let's start off by showing that they're distinct. We'll do it by contradiction. So let's suppose they're not distinct. So let's suppose for some I not equal to J. The Ith element and the Jth element of S prime are the same. The Ith element of S prime is I times Z mod P and the Jth element of S prime is J times Z mod P. So we're supposing that the Ith element and the Jth element are the same, so that IZ is congruent to JZ mod P. Now let's use the fact that P is a prime. If P is a prime, what do we know? We know then that every element in S has an inverse mod P. So, Z is an element in S, right? Z is a number between one and P minus one. So to recap, P is a prime so that implies that Z has an inverse mod P. So, let's use that inverse. What can we do? Look at this equation IZ is congruent to JZ mod P. Let's multiply both sides by Z inverse. It exists. I don't know what it is, but no matter what it is multiply both sides by Z inverse, okay? So what do we get? So, I multiplied the left hand side by Z inverse and the right hand side by Z inverse. What do I get? Now I have Z times the inverse. What is that? That's one. Z times the inverse, that's one. What am I left with? I is congruent to J mod P. What does that mean? That means they're the same when I look between one and P minus one. So, therefore, they're the same index. I suppose that they were different indexes, which gave me the same value but in order to come up with the same value, they have to be the same index. So I get my contradiction. Therefore, there is no repeat elements in S prime and they're all distinct. Now, we've shown that the elements of S prime are distinct. Now let's show that the elements of S prime are non-zero. Again, let's do a proof by contradiction. Suppose one of the elements is zero. So take the Ith element of S prime and suppose it's zero. So that means I time Z is congruent to zero mod p. What do we know? We know the inverse of Z exists mod P, right? So let's multiply both sides by Z inverse again, and what are we left with? We're left with I is congruent zero mode p, which means that I is not one of the indices here, the indices here are between one and P minus one. So this is not an element of S prime. So we get a contradiction, therefore the elements of S prime are non-zero and they're distinct and therefore, they contain the elements one through P minus one just in possibly different order and therefore, S and S prime are the same.

RA2 RSA - 121 - Proof Finishing Up
So let's recap where we are. Our goal is to show that Z raised to the power P minus one is congruent to 1 mod P. What have we done so far? We've looked at these two sets S, which are the possible values for Z. One, two, up to P minus one, and we have this set S Prime, which we obtained by taking the elements of S, multiplying each one by Z, and then taking at mod P. So, we have this set of elements, and we've shown, that S and S Prime are the same. Just in possibly different order. Now, we're going to use that fact that S and as Prime are the same, in order to prove this theorem statement. So, what are we going to do.? We're going to multiply the elements of S together, and we're going to multiply the elements of S Prime together. The elements are the same, just in possibly different order. So, when we multiply the elements of S together, we should get the same product, as when we multiply the elements of S Prime together. So, when we multiply the elements of S together, what do we get? We get 1 times 2 times 3 up to P minus 1. When we multiply the elements of S Prime together, what do we get? We get one time Z, then we get two times Z, then we get three times Z, and so on, the last term is P minus one times Z. And these are the same, modulo P. So, on the left hand side, we've got the elements of S multiply together. On the right hand side, we've got the elements of S Prime multiplied together. So, we've got the same numbers, just in different order, and we're taking it mod P, because these sets are the same with respect to mod P. What do we got on the left hand side? Let's just simplify it a little bit. This is P minus 1 factorial right? What do we got in the right hand side? Well, we got Z, Z, Z. How many Z's do we got? We got P minus one Z's. Now that looks good. Now we're starting to look like the theorem statement. And what else do we got? We got one times two times three, up to P minus one. So, we got another P minus one factorial. And these are the same mod P. Okay? Can we get rid of this P minus one factorial? In normal real arithmetic, we can just cancel it out. We cancel out here. Well, does the inverse exist? Notice P is prime. So, that means that there is an inverse for one, two, up to P minus one. Each of these numbers has an inverse mod P. Each of these P minus one numbers has an inverse mod P, because P is a prime. So, they're all relatively prime to P. So, we can multiply both sides by these inverses. And what happens? We get rid of this one times two times three, up to P minus one from both sides. So that cancels out the P minus 1 factorial. And then, what are we left with? We're left with, one is congruent to Z to the P minus one mod P. Which is the theorem statement we're trying to prove. So we're done.

RA2 RSA - 122 - Eulers Theorem
Now I misled you a little bit. We're going to use a generalization of Fermat's little theorem called Euler's theorem. So from this little theory as Gann says, if P is a prime then for every Z between one and P minus one, we take that Z raised to the power P minus one is congruent to 1 mod P. Euler's theorem is going to generalize it to any number N here instead of just a prime number P. So Euler's theorem replaces P by any N, not necessarily a prime number, and any Z but we need that Z and N are relatively prime to each other. By relatively prime, we mean that the GCD of Z and N is one. Now if Z and N are relatively prime to each other then we're going to perform an operation similar to Fermat's a little theorem. So we're going to raise Z to the power phi of N, I'll tell you what phi of N is in a second, and that's going to be congruent to one. Now what is this crazy phi of N? When N is a prime then phi of N is P minus one or N minus one. In general, what does it phi of N? It's a number of integers between one and N which are relatively prime to N. So in other words, it's the size of the set of those Xs where X is between one and N and X is relatively prime to N, which means that the GCD of X and N is one, and we want to look at the cardinality of this set. How many Xs between one and N, or N minus one, have GCD of one with N? This function phi of N is called Euler's totient function. Try to say that ten times quickly. So let's take a look at what Euler's totient function is for the case when N equals P is a prime number. For prime number P, what is phi of P? How many numbers between one and P are relatively prime to that prime number P? Well every number between one and P minus one, one, two, three, up to P minus one are all prime, relatively prime to P. So the number of relatively prime to P is P minus one. So if you look at Euler's theorem for the case when N is a prime number P then we're raising Z to the power of P minus one, and that's congruent to one mod P. So it's exactly the same as Fermat's little theorem. So Euler's theorem is a generalization of Fermat's little theorem to arbitrary N.

RA2 RSA - 123 - Eulers Totient Quiz Question
Now here's Euler's theorem again. Let's look at this Euler's totient function for the case that we're going to use. We're going to have a pair of prime numbers P and Q. So we saw when N equals one prime number P, then Euler's theorem is the same as Fermat's little theorem. We're going to apply Euler's theorem for the case when capital N is the product of P and Q, where P and Q are both prime numbers. What is phi of N in this case? Why not go ahead and try to figure out what is phi of N for the case when N is P times Q for prime numbers P and Q. So we want to figure out how many numbers between 1 and P times Q are relatively prime to PQ.

RA2 RSA - 124 - Eulers Totient Quiz Solution
Now, let's go ahead and look at what phi_of_n is for this case when n_equals_p_times_q. Let's write out all the numbers that we're looking at. We're looking at the numbers between one and p_times_q. So, this pq numbers here. How many of these numbers are multiples of p? Well, p, two_times_p, up to q_times_p, are all multiples of p. How many of those are there? There's q of them. So, q are multiples of p. How many are multiples of q? There's q, two_times_q, up to p_times_q. So, p of these numbers are multiples of q. So, each of these numbers has a common divisor with p_times_q, namely p. And each of these numbers has a common divisor with p_times_q, namely q. So, we have to exclude all these numbers. So we had p_times_q numbers originally. Q of them are multiples of p, and p of them are multiples of q. And look, we double counted. P times q is counted twice, so let's add one while I can. This can be rewritten as p_minus_one_times_q_minus_one. So, what is phi_of_n for the case when n is p_times_q for prime numbers p and q? Is p_minus_one_times_q.

RA2 RSA - 125 - Eulers Thm. for N=pq
What is Euler's Theorem tell us for the case when N equal P times Q, where P and Q are prime numbers? For any Z which is relatively prime to N, which means that the GCD of Z and N is one, and if we take Z raised to the power phi of N, which is P minus one, Q minus one, we get back one_mod_N, which is P_times_Q. This fact here, is going to be the basis for the RSA algorithm. We're going to generate a pair of prime numbers, P and Q. And we're going to look at P_times_Q, and we're going to have a message, and we're going to use this P_minus_one, Q_minus_one, to generate a encryption key and the decryption key, and this is going to give us a basic fact, which is going to allow the encryption and decryption. Let's investigate this a little bit more and then will see the basic idea of the RSA algorithm.

RA2 RSA - 126 - RSA Alg. Idea
Now we can get to the basic idea behind the RSA algorithm. Let's first look at from Fermat's Theorem. It talks about a prime number P. Let's look at a pair of numbers, B and C, which are relatively prime to each other mod p minus one. Why is P minus one? Because remember Euler's totient function or Fermat's Little Theorem, the exponent there is P minus one. Okay? That's where that P minus one comes from. So we're taking a pair of numbers B and C which are inverses to each other modulo P minus one. So what does that mean? That means B times C is one mod P minus one, or in other words B times C is one plus some multiple of P minus one. So K is a sum integer. So that means when we take B times C and we divide it by P minus one then we get a remainder of 1. Let's take a number Z between one and P minus one, and let's raise it to the power B times C, and let's take the whole thing mod P. Now we can replace B times C by this formula. So we get to Z then we get Z to the K times P minus one. We can do the P minus one. We can raise the whole thing to the Kth power. Now what do we get? Well the Z sticks around. What about the Z to the P minus one? What do we know? Fermat's Little theorem tells us that Z to the P minus one is congruent to one mod P. So we can replace this by 1 and then one to the K is what? It's one. So this whole thing is one. So it drops out and we're left with Z. So Z raised to the power B times C is Z mod P. So we get back Z itself. Okay? We're starting to get the idea for the encryption and decryption algorithm. I'm going to take a message Z, and now, if I raise it to the power B to encrypt it and then later I raise it to the power C to decrypt it, that's the same as taking Z to the power B times C and that's going to end up with Z itself. So if I encrypt by raising to power B and then decrypt by raising it to the power C, I end up with the original message itself. Now, the problem is that I have to tell everybody P, so that they can do these operations. If I tell them P then they know P minus one, and therefore, given B then they can figure out C, which is the inverse of B with respect to mod P minus 1. So I want to conceal this fact. I want to conceal this P minus one term. How am I going to do that? Well I'm going to use Euler's theorem instead of Fermat's little theorem. For Euler's theorem, I want to have a pair of primes, P and Q. I'm going to look at their product N. Now, what am I going to do? I'm going to take a pair of numbers, D and E, which are inverses of each other with respect to P minus one times Q minus one. So, D times E is congruent to one mod P minus one, Q minus one. Why did they use P minus one and Q minus one instead of P minus one? Well, in Fermat's little theorem when I raise Z to the P minus one I get one mod P. What happens in Euler's theorem? Well, the totient function of N we saw was P minus one, Q minus one for this case when it's P times Q. So if I take a number Z and I raise it to this P minus one Q minus one, I'm going to get one, when I look at it, mod N. So, that's what I'm going to do. I'm going to take a number Z. I'm going to raise it to the power D times E. What do I get? D times E is congruent to one mod P minus one Q minus one. That means D times E is equal to one plus some multiple of P minus one times Q minus one so I get the one and then I get some multiple of P minus one times Q minus one. Now what is this, Z raised to the power P minus one, Q minus one? I'm looking at this whole thing mod N. Euler's theorem tells me that if Z is relatively prime to N then this thing is one. So then one raised to the power of K, just like before, is one. So this term goes away, I'm left with Z, and there it is. Notice the terms D and E decryption, encryption. So, you give me a message Z. I'm going to tell you E and I'm going to tell you N, what are you going to do? If you want to send me the message Z, you're going to take Z and you're going to raise it to power E and then get mod N, and then you're going to send it to me. That's the encrypted message. What do I do? I compute this D, which is the inverse of E mod P minus one, Q minus one. That's my decryption key. So I take that encrypted message with the Z to the E mod N. I raise it to the power D. And what am I left with? I'm left with Z itself, the original message. Now, the point is you know N, which is P times Q. I know P and Q, but you don't know them. You just know the product of them, you know N. So from N, can you figure out P minus one times Q minus one? I don't know how to do that unless you tell me P and Q. If you just tell me their product P times Q, I don't know how to get P minus one times Q minus out of P times Q. But I know P and Q, so I can take P and Q and compute P minus one times Q minus one, and then I can run extended Euclid algorithm to compute the inverse of E mod P minus one, Q minus one. So I can compute D but nobody else knows how to compute D because they don't know P minus one, Q minus one. They simply know N, P times Q. So, everybody's going to know N, and everybody is going to know E, but I alone know D and that's the decryption key. So I tell everybody E and N, we take the message, raise it to the encrypted power, take it mod N, that's the encrypted message. Send that. The whole world can see that, but only I can decrypt it. So now let's go ahead and detail the RSA algorithm.

RA2 RSA - 127 - Crypto Setting
Here's the general Crypto setting. I got Alice over here and we got Bob over here. Alice has a message M, that she wants to send to Bob. Now, they have a communication line that they can talk over. The problem is, that there's someone eavesdropping on this conversation. So, whatever transmitted over this communication line can be seen in the clear by Eve, who's the eavesdropper on the communication. So, Eve sees everything in the clear that's communicated on this line. So, Alice doesn't want to send the message by itself. She wants to encrypt a message. So, Alice is going to take the message M, she is going to feed that into the encryption scheme and out is going to pop E(M), the encrypted form of M, the message. She's going to send that along the transmission line. Bob, meanwhile is going to have his decryption box. So, he's going to take this encrypted message, feed that as input into his decryption box, an arrow is going to pop the decrypted message. Meanwhile, Eve what did she see? She sees this encrypted message, because that's what sent over this communication line. And, from the encrypted message, she doesn't know how to decrypt. Only, Bob knows how to decrypt. Now, this is a public key cryptosystem. By public key, we mean that no communication needs to be happen between Alice and Bob in private. So, they don't need to have any coordination beforehand. What's going to happen is, Bob is going to do a computation on his own and he's going to compute a public key and a private key. His public key is going to be two numbers, N capital N and and E. Capital N it's going to correspond to P times Q, the product of two primes and E is going to be some number which is relatively prime to P minus one times Q minus 1. He's going to announce to the world, N and E. Now, anybody that wants to send a message to Bob is going to take his public key. They're going to take their message and using M, they're going to encrypt their message using N and E, the public key. But, the thing is only Bob knows how to decrypt messages that are encrypted using his public key. So, he's going to have a private key D, what is D? D is going to be the inverse of E mod P minus one times, Q minus one. Only he knows P and Q, so only he can compute D. He can compute D and then he can take this encrypted message and he can raises the power D and then take it mod N and that will give him the original message. But, only Bob knows how to compute this private key, so only he can do this decryption. But, there's no coordination that needs to happen between Alice and Bob. Bob does this computation on his own. He computes N and E and announces it to the world and he computes this private D and keeps it to himself. Meanwhile, anybody that wants to send a message to Bob looks up his public key, sees his N and E, he uses that to encrypt, the sender encrypted message in the clear. So, anybody can see the encrypted message and then, only Bob can decrypt it. So, let's detail this scheme, this is a RSA cryptosystem.

RA2 RSA - 128 - RSA Protocol Keys
Let's detail the RSA protocol. Let's start with the receiver, Bob. So what is Bob going to do? Bob has to compute his public key and his private key and he has to announce to the world his public key. How does he do it? The first step that Bob is going to do, is he's going to choose two N-bit numbers P and Q which are primes. And he's going to do that at random. So he's going to choose two random prime numbers P and Q. How does he do that? We haven't discussed that at all. And we're going to skip it until after we see the whole protocol. The idea is that, first he's going to generate two random N-bit numbers P and Q. And then he's going to check whether those random N-bit numbers are prime or not. So we're gonna have a primarily testing algorithm, so we can efficiently test whether a number is prime or not. So he's going to generate random numbers, test whether they are prime, if the are prime, then they are random prime, if they're not prime, he's going to repeat and generate a new random number and check whether its prime again and keep going until he gets a prime number. How do you generate a random number? You just try and generate a random string of zeros and ones of length and that gives you an N-bit random number. How do you check whether it's prime or not? Well, that's a little bit more complicated. And it turns out that a random number has a reasonable chance of being prime. Primes or dense in some sense. We'll see details of all that next, after we go through the whole RSA protocol in detail. The second step, Bob chooses an E which is relatively prime to P minus 1 times Q minus 1. How does he do that? He's going to try E equals 3 and he's going to check whether the GCD of three and P minus 1, Q minus 1 is 1. If it is, then they are relatively prime to each other. How does he check it? He runs Euclid's GCD algorithm. And if three is not relatively prime, then what does he do? He tries five and then seven and then 11 and so on. You know, if you get up to 13 or 17 or 19 and none of those are relatively prime to P minus 1, Q minus 1, what do you do? Usually, you go back to the first step, choose two new primes P and Q and try again. It's nice to keep this encryption key small. It makes it easy for somebody to encrypt their message, to send to you. Now what do you do? Let's let N equal P times Q. Now Bob can publish his public key, N and E. N is the product of P times Q. So he's publishing that product. He's not publishing P or Q, he's just telling what the product is and he's telling them what E is, where E is relatively prime to P minus 1, Q minus 1. So the whole world can know N and E. Meanwhile, Bob computes his private key. What's his private key? It's the inverse of E relative to P minus 1, Q minus 1. So D is the inverse of E mod P minus 1, Q minus 1. How do we know that D exists? Because E is relatively prime to P minus 1, Q minus 1. We chose it so that it was relatively prime therefore it has an inverse mod P minus 1, Q minus 1. And we can find that inverse, how? By using the extended Euclid algorithm, we can find the inverse. This is going to be Bob's decryption key. He keeps it private, he doesn't tell anybody. He tells the whole world N and E, but he keeps private his decryption key, D.

RA2 RSA - 129 - RSA Protocol Encrypting
Now, let's look at things from Alice's perspective. Alice has a message M that she wants to send to Bob. What's the first step that Alice does? She looks up Bob's public key which is this pair N, E. Now, she needs to encrypt her message using Bob's public key. What does she do? She encrypts using their public key. She takes the message M raises its power E and takes that mod N. And that's her encrypted message, Y that she sends to the world. Now, one key thing is, E might be a little bit large. So, how does she raise M to the power E Mod N? She uses our fast modular exponentiation algorithm that we just saw earlier in this lecture. Finally, Alice can send the message Y. Now, let's look at the final step of the procedure. What happens for Bob? Bob receives this encrypted message Y that Alice sent. Now, Bob decrypts this message. How does he decrypt it? He computes Y, this encrypted message, raises it to the power D which is his private key and he takes that mod. N. What is that going to equal? That's going to give him back M. So, he's going to end up with the original message M. Let me recall why that's the case. Remember, how did we choose D? D is the inverse of e mod P minus one Q minus one. That means D times E is congruent to one mod P minus 1 Q minus one. That means D times Z is one plus some multiple of P minus one times Q minus one. Now, what are we doing? We're starting with the message M. Alice is encrypting it by taking that message M raising it to the power E then taking it mod N. Call N is P times Q where P and Q are prime numbers. This M to the E is Y. Now, what does Bob do? Bob takes this as message Y and he decrypts it by raising it to the power D. What do we get then? We get M to the power E times D. What do we know about E times D? That's equal to one plus some multiple of P minus one Q minus one. We get M for this one and then we get this multiple of P minus one Q minus one. What is M raised to the power P minus one Q minus one? Well, when M is relatively prime to N, then Euler's theorem tells us that this is one. So, this whole term drops out and what are we left with? We're left with M, the original message. So, we take this message M raise it to power E and then raise it to the power D, what do we end up with? M the original message. This is the case when M is relatively prime to N. And also it holds when M and N have a common factor namely, P or Q. In which case you can prove this statement still holds. But it takes a little bit more work. You got to use Chinese Remainder Theorem. But that's the basic idea. We use Euler's theorem. So, that gives us this P minus one Q minus one term. That's the whole RSA algorithm. It's fairly simple. The only thing that's missing now for us, is how do we generate a random prime number? How do we get this P and this Q? We said, generate a random number and then check whether it's prime. So, we've got to look at how to check whether a number P is prime or not. We'll do that next. But let's first look at some simple issues that might arise in the RSA algorithm that you have to be careful about. One important note before we move on. How do we compute this Y to the D mod N? Notice we, typically tried to make E small. Why did we make E small? So, that it's easy, it's fast to compute the message raised to the power E mod N. So, it's easy and it is fast to encrypt the message. So, we want to make it easy for somebody to send us an encrypted message. But then we're going to put in extra work in order to decrypt it. Why? Because this D, if E is smaller then D is probably going to be a huge number. So, how do we take this mass encrypted message Y and raise it to the power D? Here is where we really need to use our fast modular exponentiation algorithm. This was the algorithm based on repeated squaring. And then using this, we can compute Y to the D efficiently, mod N. But if we don't use this fast algorithm, we use a naive approach. Then this is going to be exponential time and there's no way we're going to be able compute it efficiently.

RA2 RSA - 130 - RSA Potential Pitfalls
let's look at some of the issues that can arise when we're implementing RSA first off suppose in our message little m is not relatively prime to capital n so the GCD of little m and capital n is greater than 1 now capital n is a product of two primes P and Q so it's only divisors are P and Q so what can be the common divisor of m and capital n it's got to be either P or Q so let's suppose that GCD of little m and capital n is P now what happens in the RSA protocol or we take this message m raise it to the power E and look at that mod capital N and then the receiver takes this encrypted message raises it to the power D and then takes it mod N and what do we get back well this equals the original message M now we didn't prove this case we proved the case when they're relatively prime to each other and then if followed by Euler's theorem and we claim that this case when they're not relatively prime followed by the Chinese remainder theorem this is in fact true but there's a potential problem in this case what's the problem well P divides m and N and if we look at the encrypted message Y which is m to the e mod n or of P divides M and it divides n then it's also going to divide Y so the GCD of Y and capital n is also going to be P what does this mean well anybody that's eavesdropping is gonna see this encrypted message and from this encrypted message and the public key capital n by simply running Euclid's algorithm they can take the GCD of these two numbers and they find that the GCD is little P prime P and once they know prime P then they can factorize n and therefore they can break the RSA cryptosystem they can find the decryption key little T so before using this message m and sending the encrypted version of it we have the first chat that m and n are relatively prime to each other if they share a common factor then anybody will be able to use this encrypted message to break this crypto system what are some other issues that can arise we need that little m is not too large in particular we need that little m is strictly less than capital n now typically our message is text so we first have to convert it into a number how might we do that well we can take the binary version of the text now the binary version of the text is gonna be a huge number so what we do is we break this huge number into n bit segments these are segments of length little N and therefore little m will be at most strictly less than 2 to the little n so if we break the message into little n bit strings then we get this property and if we ensure that P and Q are sufficiently large so we ensure that they're leading bit is 1 then if we look at capital n we know that capital n will be at least 2 to the N and therefore little m will be strictly smaller than capital n so this property that little m is not too large as easy to insure but we also need that m is not too small why is that the case well suppose that little e equals 3 which is a common practice and suppose that M is very small number so m cubed is strictly smaller than n or when we look at M cubed mod n what do we get well the mod n isn't doing anything because M cubed is smaller than n so M cubed or m to the e is the same as m to the e without the mod n so this mod n is not doing anything when this number m is too small and that means that our encrypted message the message we're sending in clear text is simply M cubed the Madonna isn't doing anything now if we see this message m cubed how do we decrypt it we just take the cube root so anybody seeing this encrypted message can simply take to the to brood and we get the original message back so it's easy to decrypt it's easy to break this crypto system in this case cube roots are difficult to do when we're doing it with respect to modular arithmetic but in real arithmetic cube roots are easy to do so how do we avoid this issue when we have a small message well we can choose a random number R and we can look at M plus R or M exclusive or with R and we can send this new message this padded message and we can also send a second message which is just R itself so we send two messages the padded message are itself and as long as our is not too small then this will be okay and if our is too small just choose a new random string until we get an R which is sufficiently large now there's one last issue I want to point out if we use the same message multiple times then we have a potential problem suppose we have the same message that we want to send to three different people each of these three people have a different public key but they're all using a equals two three suppose the first recipient has e equals to 3 and n one second recipient has n 2 and e equals to three third recipient has n 3 and e equal to three and suppose we use the same message m to send to these three people now the encrypted messages are going to be different the first encrypted message is going to be M cubed mod and 1 the second encrypted message is going to be M cubed mod and 2 the third one is going to be M cubed mod and 3 so we got three different encrypted messages y1 y2 and y3 but it turns out that if somebody sees these three encrypted messages which all come from the same message same number M then they can decrypt they can figure out M from y1 y2 and y3 how do they do that they use the Chinese remainder theorem this is a homework problem in the textbook in the desc coupe 2 textbook in Chapter 1 is problem 44 now all that remains for specifying the RSA protocol is to describe how we do primarily testing so let's dive into that

RA2 RSA - 131 - Recap of RSA
Let's take a moment now to recap the RSA algorithm and also the mathematics behind the algorithm. We start with Fermat's little theorem, that was the basis of the whole algorithm. Let's recap that. So the setting is, we have a prime number p and we have another number z, where z and p are relatively prime to each other, which means that the GCD of z and p is one. This means that they're relatively prime if their GCD is one. Now, the theorem says, if we take z and raise it to the power p_minus_one and we look at it mod_p, then what are get? We get one. And that's true for any z, so take any z which is not a multiple of p and we raise it to power p_minus_one we get one_mod_p. Actually, we didn't use Fermat's little theorem, we used the generalization known as Euler's theorem. Now Euler's theorem is a general theorem that holds for any capital N, but we used it for the particular case where capital N was the product of two primes, p and q. So let's recap it for this particular case that we're interested in. So, for primes p and q, look at their product, capital N, and take a z, which is relatively prime to capital N. Now in this case, if we raise z to the power p_minus_one_q_minus_one, then we get the analog of Fermat's little theorem. This is going to be one, when we look at it, mod_N, where N is p_times_q. Now, where did this exponent p_minus_one_times_q_minus_one come from? Well, that came from, we looked at how many numbers between one and capital N? This is the capital N here. How many numbers between one and capital N are relatively prime to capital N? For the case where capital N is p, then all numbers from one to p_minus_one are relatively prime to this N. So that's why the exponent is p_minus_one. For the case where N is p_times_q, then the number of numbers between one and p_times_q, which are relatively prime to it, are p_minus_one_times_q_minus_one. That's what we should solve before

RA2 RSA - 132 - Recap of RSA #2
Now, Euler's theorem was the basis for RSA algorithm. Now, let's go ahead in detail again the RSA algorithm. The first step is to choose a pair of primes p and q. These are the ones that we haven't seen actually how to do. We're going to explain how to choose prime numbers, after we review the RSA algorithm. Now, after we choose the pair of primes p and q, we look at their product. Hence let N be the product of p and q. The next step is to find an e which is relatively prime to (p-1)(q-1). By relatively prime, again we mean that the gcd of e and (p-1) and (q-1) is one. So they have no common factors. Now, why did this (p-1)(q-1) come up? Because recall Euler's theorem, that's the exponent here. So, what is the key implication of the fact that e is relatively prime to (p-1)(q-1)? That means that e has an inverse. So, the third step is to find the inverse of e relative to (p-1)(q-1). So, let d be the inverse of e mod (p-1)(q-1). We know it exists, because e is relatively prime to (p-1)(q-1). How do we find this inverse? We use the extended Euclid algorithm. Now, we can publish our public key N and e. We tell the whole world this public key N and e and anybody that wants to send us a message will encrypt that message using this public key, but nobody is going to know our private key little d. We're going to keep this private key d secret, because anybody that finds this private key d can decrypt messages. Now, anybody that wants to send us a message, let's say, m, they're going to encrypt the message using our public key. They take that message m, they raise it to power of e and look at a mod N. And then they send that Y, which is congruent to m to the e mod N. They send that message Y and the whole world can see that message Y, but only we can decrypt it, because only we know little d. Finally, we receive this message Y, this encrypted message. How do we decrypt it? We use little d in the following way. We take this encrypted message Y, we raise it to the power of little d and we look at that mod N. And it turns out that this equals m. What are the algorithms that we need to use? Well, first off, to find this e, which is relatively prime to (p-1)(q-1), what do we do? We try e equals three, five, seven, 11, 13, at some point we give up. For each of those e's, though, how do we check whether it's relatively prime to (p-1)(q-1)? We check its gcd which we do using Euclid's algorithm. Then once we find an e which is relatively prime, we compute its inverse. How do we do that? We used the extended Euclid algorithm, and we publish our key, usually e is small, so that taking m to the e mod N is relatively easy. If it's not, then we can use repeated squaring, our fast modular exponentiation algorithm, and definitely here, when we're raising this encrypted message Y to the power d, that's probably going to be to a huge power. So, how do we do Y to the d mod N? Here we need to use our fast modular exponentiation algorithm. The algorithm based on repeated squaring, and that's going to take time which is polynomial in little N, the number of bits in these numbers Y and d and N. Finally, the key thing about why this works is look at what's happening to the message. We're raising the message m to the power e and then to the power d. And recall that e times d is congruent to one mod (p-1)(q-1). So, when we apply Euler's theorem what we're going to get out is, we're going to get the message m back out. So, m raised to the power e times d modulo N is congruent to little m, because of Euler's theorem. What remains? We need to look at how we choose these prime numbers p and q. The other thing is let's just make an aside about why this algorithm is hard to break. Notice the whole world knows N, which is p times q, but only we know (p-1)(q-1), and therefore only we can compute the inverse of e mod (p-1)(q-1). The point is, can you get (p-1)(q-1) from N without knowing p and q, individually? The assumption is that no, we can not do that, that the only way to get (p-1)(q-1) is to get factor N into p and q. If you don't know how to factor N into the pair of primes which compose it, then you cannot get (p-1)(q-1). That's our assumption. So, this algorithm is as hard as factoring N. We don't know any other way to get (p-1)(q-1). And our assumption is that factoring is difficult, computationally difficult to solve. Now, to finish off the RSA algorithm, let's look at how we find prime numbers p and q.

RA2 RSA - 135 - Random Primes
Now, we want to choose a pair of primes P and Q. One way to do that, is to have a table of prime numbers, and then just go through that table of prime numbers. What's the problem with that? Well, if somebody has access to our table, then it'll be easy to crack our cryptographic scheme. So, we want something more secure. So what's the better approach? A better approach is to choose random primes P and Q, and we want these primes P and Q to be chosen, so that every time we run the algorithm they are being chosen independently from previous runs. So, how do we choose these primes at random? Well, first off how do we choose random numbers? That's, what we're going to do first. Let R be a random N-bit number. How do we choose R? Let's say, little N is six, actually in practice though, little N is going to be a huge number like a 1000 or 2000. How do we generate this random 6 bit number? We have a one dimensional array of size 6 and we generate each of the bits, for each bit we choose a random number 0 or 1. And, we make sure that every bit is generated independently of every other bit. And, then every time we run the algorithm, the bits are generated independent of previous runs of the algorithm. So, this is quite easy to generate random N-bit number, but we want a random N-bit prime number. So what do we do? We choose a random N-bit number regardless of whether it's prime or not. And then we check whether this random number is prime or not. How do we do that? We'll see how to do that in a moment. But, suppose we have a test for primality, so we given a number we can check whether it's prime or not. Then, if this random number happens to be prime then, what do we know? Then, we know it's a random prime number. So in that case, if R is prime we can output it, because it is a random prime number. What do we do if it's not a prime number? Then we repeat this procedure. We generate a new random number, check whether it's prime or not. How long is this algorithm going to take before it finds a prime number? Well the key thing is that primes are dense. What do we mean more precisely? The probability that this random number R, happens to be a prime number is roughly 1 over little N, which is the number of bits in it. So, for generating a 1000 bit number or a 2000 bit number the probability that it's going to be prime is about 1 over a 1000 or 1 over 2000, which means how many times are we going to have to repeat this procedure, before we find a prime number? In expectation, is going to be about little N, it's going to be about a 1000 or 2000 times, which is not a big deal, to repeat this a 1000 or 2000 trials before we find a prime number. But the question remains, how do we check whether a given number R is prime or not?

RA2 RSA - 136 - Primality Fermats Test
Now, we're going to derive a Primality Testing Algorithm using Fermat's Little Theorem. Let's first recall Fermat's Little Theorem. If r is a prime number, then for all z in this set, all z between one and r minus one. If we look at z raised to the power r minus 1 modulo r, then it's congruent to one. Now, we're going to use this as the basis for figuring out whether a given number r is prime or not. So, if it's prime it satisfies this. What if it's composite? We'll, what if we find a z between one and r minus one, where z raised to the power r minus one modulo r is not controlling to one. We'll, by Fermat's Little Theorem if this is the case, then what do we know about r? We'll, r must be composite if there's such a z. So, this z where z raised to r minus one is not congruent to one mod r is a witness. It proves that r is composite. And hence, we call this z a Fermat witness because it's a witness with respect to Fermat's Little Theorem. The first question we want to ask is whether every composite number has a Fermat witness. The answer to this first question is, yes it does. Every composite number has at least one Fermat witness and we'll demonstrate this in a moment. After we demonstrate this, then we have to look at how we find a Fermat witness. After we show that every composite number has at least one Fermat witness, then we'll look at how to find Fermat witnesses. What will show is that every composite number has many Fermat witness. We'll, there are some exceptions called Pseudo Primes but if we ignore Pseudo Primes, then every other composite number has many Fermat witness. So, in fact it will be easy to find Fermat witnesses for composite numbers. And that will give us our Primality Testing Algorithm. And then, we'll see how to deal with these Pseudo Primes. Let's first prove this fact that every composite number has at least one Fermat witness.

RA2 RSA - 137 - Trivial Witness
Once again, we have a number R and we're trying to determine if R is prime or composite. Now we say number Z is a Fermat witness for R. First off, Z lies between one and R minus. And crucially Z raised to the power R minus one is not congruent to one mod R. Then by Fermat's little theorem, we know that R is composite. Because if R is prime every such Z, Z raised to the power R minus one, is congruent to one mod R. So if we get a Z where is not true then this R must be composite. So Z is a witness to the fact via Fermat's little theorem that R is composite. We want to first prove that every composite number has at least one Fermat witness. So let's prove this fact. Now, R is composite so we know it has at least two divisors. So take a Z which is a divisor of R. So clearly this Z, which is a divisor of R, lies between one and R minus one. What else do we know about this Z? Well, look at its GCD. What do we know about the GCD of R and Z? Well, if we take Z to be a divisor of R then we know the greatest common divisor of these two numbers is Z itself. And since R is composite, we know this divisor is greater than one. Well, actually, this proof works for any Z where this statement is true. So any Z which is not relatively prime to R. And if R is composite, we always know there is at least two such Z's which are not relatively prime to R. Now, if the GCD of R and Z is greater than one, what do we know? Well, if you recall from our previous lecture about modular arithmetic, what about the inverse of Z mod R? We know it does not exist. There is no inverse of Z mod R. Why? Because the inverse of Z mod R exist, if and only if the GCD of R and Z is one. They're relatively prime to each other. Now, we want a proof for this Z that Z raised to the power R minus one is not congruent to one mod R. What are we going to do? Let's suppose that it is congruent to one mod R. So suppose that Z raised to the power R minus one is congruent to one mod R. That's the opposite of what we're trying to prove. So what will show is that, if this holds then we get a contradiction. How will we get a contradiction? Will show that Z has an inverse mod R. And we know that's not the case therefore we have a contradiction, therefore this assumption cannot hold, and therefore Z raised to the power R minus one must not be congruent to one mod R. Okay? Now, we have the fact that Z raised to the power R minus one is congruent one mod R. Now, Z raised to the power R minus one is the same as the following. It's the same as Z raised to the power R minus two times Z. This product is Z raised to the power R minus one. So if Z raised to the power R minus one is congruent to one mod R, then Z raised to the R minus two times Z is also congruent to one mod R. Now, look at this statement. Z times Z to the R minus two is congruent to one mod R. That means that Z has an inverse. What's its inverse? It's this number Z to the are minus two. Because when we look at the product of these two, it's one mod R. That's the definition of the inverse. So Z to the R minus two is the inverse of Z and Z is the inverse of Z to the R minus two. But we know that Z does not have an inverse mod R, therefore we have a contradiction. And thus, this assumption cannot hold and therefore we know that Z to the R minus one is not congruent to one mod R. And that proves that every composite R has at least one Fermat witness.

RA2 RSA - 138 - Non-Trivial Witness
Now we call this Fermat witness that we just derived a trivial Fermat witness. Why is it a trivial Fermat witness? This is a Fermat witness, z, where it also has the property that the greatest common divisor of z and r is greater than 1. So z and r are not relatively prime. Notice, such as z already proves that r is composite. If z and r have a non-trivial divisor, then we know that r has a non-trivial divisor, and therefore, it's not prime. So, any z where this is the case, proves that r is composite, there's no reason to run Fermat's test. So that's why we called such a z, a trivial Fermat witness. Now there always exists a trivial Fermat witness for composite numbers. Why? Because every composite number has at least two non-trivial divisors. The question is whether a composite number r, has a non-trivial Fermat witness. This is a number z which is relatively prime to r. Now it turns out that some composite numbers have no non-trivial Fermat witnesses, these are called pseudo primes, but those are relatively rare. For all the other composite numbers, they have at least one non-trivial Fermat witness, and if they have at least one, then in fact, they have many Fermat witnesses. And therefore it will be easy to find a Fermat witness and that's the key point. Trivial Fermat witnesses always exist. Every composite number has at least two trivial Fermat witnesses. But if a composite number has a non-trivial Fermat witness, then there are many Fermat witnesses, they're dense and therefore they're easy to find. And that's what we'll utilize for our primality testing algorithm.

RA2 RSA - 139 - No Non-Trivial Witnesses
Recall, for a number r, if we're checking whether r is prime or not, we say that z is a Fermat witness, if it proves that r is composite, according to Fermat's little theorem. What does that mean exactly? That means, that if z to the r minus one is not congruent to one mod r, then that z proves that r is composite. Now, we say it's non-trivial, if in addition GCD of z and r is one, so z and r are relatively prime. Because if GCD of z and r is greater than one, so they're not relatively prime to each other, then that z gives us a non-trivial divisor of r, and therefore we know already, trivially, that r is composite. Now, the question is, does every composite number have a non-trivial Fermat witness? We know it has a trivial Fermat witness. Namely, if it has a one of its divisors is a trivial Fermat witness, doesn't have a non-trivial Fermat witness. Well, in fact there are composite numbers which do not have non-trivial Fermat witnesses. These are called Carmichael Numbers. These are sort of pseudo primes. Okay. They behave like primes with respect to Fermat's little theorem. A Carmichael number is a composite number r, which has no non-trivial Fermat witnesses. Therefore, such a number is going to be inefficient to use Fermat's test, to prove that r is a composite number. We're going to have to find a different way to deal with Carmichael numbers. But, the key thing is that Carmichael numbers are rare. The smallest one is 561 and 1105 and so on. But, since they're relatively rare, let's ignore them for now and when we ignore Carmichael numbers, we're going to have a simple algorithm to check whether number r is prime or not, using Fermat's test and trying to find a Fermat witness when it's composite.

RA2 RSA - 140 - Primality Many Witnesses
So let's ignore Carmichael numbers for now since they're relatively rare. Let's assume that every composite number r, has at least one non-trivial Fermat witness. If we assume that it has at least one non-trivial witness, how many witnesses does it have, actually? How prevalent are these non-trivial witnesses? The key fact is that, if r has at least one non-trivial Fermat witness, then there are many non-trivial Fermat witnesses. In fact, if we look at the set of possible witnesses, one through r minus one, then at least half the numbers in this set are Fermat witnesses. Now, this is a relatively simple fact to prove and it's a very nice proof. The proof is in the book. But let's get the proof for now and let's try to use this, Lemma, to have an algorithm for checking whether a number is prime or not, when we ignore Carmichael numbers. So we assume that a composite number has at least one non-trivial witness. Then this Lemma tells us that at least half the numbers in this set are Fermat witnesses, are witnesses to the fact that r is composite. Can we use this fact now to get a test for whether r is composite or not? The point is that when r is prime, all of these numbers, when we raise them to the power r minus one is congruent one mod r. And when r is composite, then at least half these numbers, when we raise them to the power r minus one is, are not congruent one mod r. So how are we gonna check whether a number is prime or not? We're going to take a z, from this set, and raise it to the power r minus one. Look at mod r and see whether it's one or not.

RA2 RSA - 141 - Simple Primality Alg.
We have an n-bit number r, and here's our simple algorithm for checking whether r is prime or not based on Fermat's Little Theorem. And this is ignoring Carmichael numbers, it will be an efficient algorithm for primality testing. Recall, that if r is composite then, at least half these numbers in this set are witnesses to that fact using Fermat's Little Theorem. Whereas, if r is prime, then none of these numbers in this set are witnesses to the fact because r is prime. So, what are we going to do? We're going to choose a Z from this set. How do we choose a Z from this set? Well, we choose a Z randomly, uniformly at random from this set. So, we choose a random number between one and r_minus_one. Now, we do Fermat's Test for this Z. So, we compute Z raised to the power r_minus_one_mod_r and we check whether that's congruent to one, or not. If Z raised to the power r_minus_one is congruent to one_mod_r then what do we know? Actually, we don't know for sure either way, but we think that r is prime. What happens if Z raised to r_minus_one is not congruent to one_mod_r? Then, in this case we're sure that r is composite because this Z is a witness to the fact that r is composite.

RA2 RSA - 142 - Primality Alg. Analysis
Let's take a look at how this simple Primality testing algorithm performs. If r happens to be prime, what does the algorithm do? It always outputs that r is prime, because for every z in this set, z raised to the power r_minus_one is congruent to one_mod_r, by Fermat's little theorem. So, the probability that the algorithm outputs that r is prime, is one, this is always going to do so. So, it's always correct when r is prime. Now, what happens when r is composite? And let's assume that r is not a Carmichael number. Now, sometimes the algorithm is going to be correct, it's going to output that r is composite. When is that the case? When it finds a z which is a Fermat witness. So z raised to the power r_minus_one is not congruent to one_mod_r. But sometimes it's going to get confused, it's going to make a mistake, and it's going to find a z, which z raised to the power r_minus_one is congruent to one_mod_r. So it's going to think that r is prime. What is the probability that the algorithm outputs that r is prime, so, it makes a false positive statement? Well, we know that at least half the zs in this set are Fermat witnesses. So what's the chance that it finds a non witness? Well, at most half of them are not witnesses, so therefore, the probability of finding a non-witnesses is, at most, a half. So, the probability of a false positive is, at most, a half. Okay, so, we have a reasonable algorithm with probability of most a half that we get a false positive, and when it is prime, it's always correct. But can we get this better? Can we improve this error probability of a false positive?

RA2 RSA - 143 - Boosting Success
Here again is our original primality testing algorithm. The problem was that it had a false positive rate of at most a half. We want to prove that false positive rate. We want to get it down smaller. So, what are we going to do? Recall the algorithm starts by choosing a random number between one and R minus one, and then we run for a max test for that Z that we chose at random. Now, what we're going to do is instead of choosing one rule number at random from this set, we're going to choose K numbers at random from this set, where K is a parameter that we're going to choose. Now, for all of these K numbers, we're going to run for a max test. So we're going to take that ZI and we're going to raise it to the power R minus one and we're going to check mod R, whether it's congruent to one or not. Now what we need is just that one of these ZI's is a Fermat witness. If any of these ZI's is a Fermat witness, so ZI raised to the power R minus one is not congruent to one mod R then we know for sure that R is composite. Whereas if all of these ZI's are not witnesses, then we have a very good chance that R is prime. So our final check is whether any of these ZI's is a witness or not. So if for all I's it passes the test, so ZI raised to the power R minus one is congruent to one mod R, then what do we know? We know there's a good chance that R is prime. And if any of these ZI's is a witness then what do we know? Then we know for sure that R is composite. more precisely let's look at our analysis from before. Suppose that R is a prime number, what does the algorithm do? It always outputs that R is prime because every ZI, when we raise it to the power R, is going to be congruent to one mod R by Fermat's little theorem. So the probability the algorithm outputs R is prime is one, when R is in fact prime. What happens when R is composite but not Carmichael? The previous algorithm had a false positive with probability at most a half, because at most half of the Z's are non-witnesses. Now, we're choosing KZ's. We just need that one of them is a witness. What's the probability that none of them are witnesses? So think of the following analogy: say it's a witness if I flip a coin and it's a heads, and if it's tails it's a non-witness. So the probability of a tails for each of these K flips is at most a half. So suppose it was a fair coin, what's the chance that I have K tails? That means that all K of these are non-witnesses. If I have just one heads, or at least one heads, then I have a witness. What's the chance that none of them are witnesses? So the chance that all K of them are tails? That's at most one half to the K. So the probability of a false positive in this scenario is at most one half to the K. So if I choose K to be, let's say, 100. So I choose 100 numbers at random from this set, this is a huge set, this is about the order two to the 1000, or two to the 2000. So choosing 100 numbers from there, running this procedure 100 times is not much of a cost. Then the probability of a false positive is at most one half to the 100, which is a tiny, tiny probability. So there is a very minuscule chance of that. So I'm willing to take that chance of a false positive, in which case my scheme, my cryptographic scheme might be easy to break, the chance of that is very minuscule. So that completes our primality testing algorithm in the case when we assume that the composite numbers are not Carmichael numbers. So we're ignoring these pseudo prime numbers. It turns out that, actually, to deal with these pseudo prime numbers, Carmichael numbers, it's not that much more complicated of an algorithm. That's detailed in the textbook and I'll leave that to there.

RA2 RSA - 144 - Addendum Pseudoprimes
Here is the general algorithm for primality testing which handles Carmichael numbers. The algorithm is essentially the same as before with one small observation. I'll explain the algorithm using an example. Let's consider the example of 1,729, this is a composite number, in fact, it's a Carmichael number. So our previous algorithm, is unlikely to detect that is compiler. Now, let's first recall our previous approach. We first choose a random number Z between one and 1,728. For concreteness and simplicity, let's suppose that Z is five, I chose a small number to make it simpler. Now, our previous approach takes these numbers Z, which is five, and we raise it to the power of 1,728, which is X minus one, and we take that mod 1,729, which is X. So, we look at Z raised to the power X minus one mod X. Now, if this is not one, then we have a proof that this number is composite. Well, since this is a Carmichael number, this is unlikely to work and in fact it doesn't work. Five raised to the power of 1,728 is congruent to one, mod 1,729. So, firmus test fails in this case. Well, let's go back and look at how we compute five raised to this power. Well of course, we do use repeated squaring. Now, in the spirit of repeated squaring, let's take this number 1,728 and let's take out all the factors of two that we can. Now, notice that this number is even Y, while this number X, we're checking whether it's prime or not. So, it's odd and therefore X minus one is even or 1,728 is equal to two times 864, we take out another factor of two and repeat. We can do it six times, so we get two to the six times 27. We stop when we reach an odd number. Let's start a new approach by computing five raised to the power 27 mod 1,729. Now of course, this exponent might be very large, so of course, we're going to use the fast modular exponentiation algorithm to compute it. Suppose we ran it, and we computed this exponent, it turns out it's congruent to 1,217. Now, let's apply repeated squaring six times to get to this result. So let's take this result and square it. So, we're computing five to the power 54, and we're doing this mod X. So we take the previous results squared, and that's congruent to 1,065 mod X, then we take this previous result and we square it, and it turns out that 1,065 squared is congruent to one mod X. Now, we continue, of course once we get one it's going to continue one, so the next result will be one squared which is one of course, and we square it again and we're going to get one again. We do it a few more times, and eventually we get to five raised to the power, two to the six times 27, and that will be one, which we know from before, mod 1,729. Now, let's look backwards. So, we end with one here, we get this string of ones. Let's look at the first number which is different from one, what do we know about it? In this case, it's 1,065 but 1,065 squared is one mod X. Since 1,065 squared is one mod X therefore, 1,065 is a square root of one mod X. In fact, it's what we call a non-trivial square root of one mod X. Why is it non-trivial? What are trivial squared roots of one mod X? Well, the trivial square roots of one mod X are one and minus one. Why? Well, we always know that one squared is one and negative one squared is one. That's true in real arithmetic and it's also true in modular arithmetic. So, every number X has these two trivial square roots of one mod X. It turns out that prime numbers X only have these two square roots of one mod X. So, one and minus one are the only two square roots of one mod X when X is prime. But if we can show a non-trivial square root of one mod X then therefore, that implies that X is composite because prime numbers only have the trivial ones. So, if we show a non-trivial one, that proves that X is composite. In this case, we've shown that this number X has a non-trivial square root of one, namely 1,065. It turns out that for a composite number X, even if it's Carmichael for at least three quarters of the choices of Z, this algorithm works. Namely, if we compute Z raised to the power X minus one mod X and if we get one and we go backwards in this approach, so we use this repeated squaring and then we work backwards from the one to the first non-one, this leads to a non-trivial square root of one mod X, and therefore, proves that X is composite and this works for at least three quarters of the choices of Z. Now, the mathematics for proving that at least three quarters of the choices of Z work is quite complicated but the algorithm itself that we're using here is basically the same as before with the repeated squaring added in. So, to deal with Carmichael numbers, we use basically the same algorithm as before, except when formats test fails, we go back and we check whether we get a non-trivial square root of one mod X.

RA3 Bloom Filters - 145 - Hashing Outline
In this lecture we're going to talk about hashing and we're going to describe a popular technique called bloom filters. Before we get into hashing, we're going to talk about a toy problem, balls into bins. We are going to throw balls randomly into a set of bins. We'll do some simple probabilistic analysis of this problem and this will give us some intuition about the design of hashing schemes. One of the neat ideas we're going to see with the balls and bin's problems, is the power of two choices. This is going to motivate some of our more sophisticated hashing schemes. After we look at the toy problem balls into bins, then we'll look at the traditional hashing scheme; chain hashing. And then we'll look at our more sophisticated scheme, bloom filters. So let's dive into the balls into bins.

RA3 Bloom Filters - 146 - Balls Into Bins
For this toy problem, we have n balls, which are identical to each other, and we have n bins, which we'll label B1, B2, up through Bn. Each ball is thrown into a random bin, and this is done independent of the other bins. Now, what we're going to do for this toy problem, is we're going to throw each ball into a random bin. Now, the process for each ball is independent of what happened for the other balls. We want to look at the number of balls that are assigned to each bin. Therefore, we look at the random variable load_of_i, which is the number of balls assigned to bin i. What we're interested in is the maximum load. This is the maximum number of balls in any particular bin. In other words, the max load is the max_over_i of the load of bin i. How large can the max load get? Well, in the worst case, all of the balls might get assigned to the same bin. But, what's the chance of that? It's quite small. I mean, what's the chance of all n balls being assigned to bin B1, let's say. The probability of one particular ball being assigned to bin B1 is one_over_n. What's the chance that all n balls get assigned to this particular bin? It's one_over_n_to_the_n. This is really tiny, so this is very unlikely. In the worst case, the max load could be n because of such a scenario. But what is the typical scenario? How large is the max load typically? That's what we want to analyze now. We want to make a statement such as, with high probability, the max load is, some quantity, such as square root n, log n, order one. So, let's dive in and see what the max load is in a typical scenario.

RA3 Bloom Filters - 147 - Probability Quiz Question
Let's take a short probability quiz to give a quick refresher on some basic probability. Let's look at what is the probability, that the first log and balls are assigned to bin bi for a particular i. We want to look at the probability that the first log and balls are assigned to this particular bi. Go ahead, and write the quantity here.

RA3 Bloom Filters - 148 - Probability Quiz Solution
Now, the solution is one_over_n_to_the_log_n. Why is that? Let's look at it more closely. Take a particular ball j. What is the probability that this ball is assigned to this particular bin Bi? Well, the ball is going to a randomly chosen bin, so the chance of going to any particular bin is one_over_n. Therefore, the first ball has probability one_over_n of being assigned to bin Bi. The second ball, same, has a probability one_over_n of being assigned to bin Bi, and so on for all these log_n balls. So the probability that all of them are assigned to bin Bi is the product of one_over_n, for each. So, the total probability is one_over_n raised to the power log.

RA3 Bloom Filters - 149 - Analysis Setup
Now let's dive into the analysis of the maximum load. What we've seen so far, is that for a particular set of log and balls, the probability that these log and balls are assigned to a particular Bin Bi is one over N raised to the power LogN. We're going to try to show that the max load is typically at most LogN. Now, what does typically mean? We're going to have to detail exactly what we mean by that. But in order to prove that the max load is a most LogN, we want to show that the probability that a particular Bin Bi gets load greater than LogN and we want to propound that probability and show that it's small. It's unlikely to get load at least LogN. In order for Bin Bi to get loaded least LogN, a particular set of log N balls have to get assigned to bin Bi. Now maybe more than log and balls that get assigned to Bi but we know that there's at least LogN balls that are assigned to Bi. So we're going to get an upper bound on this probability. First, we have to choose the particular set of LogN balls that are going to be assigned to Bin Bi. How many ways are there of choosing the LogN balls? There's N choose LogN. Now, for this particular set of LogN balls, what's the chance that they are all assigned to Bin Bi? Well, that's what we found before, that's one over N raised to the power LogN. Now what happens for the other N minus LogN balls? Well, some of them might get assigned to this Bin Bi as well, in which case we may be counting these events multiple times. So we're getting an upper bound on this probability. Notice, that if we had an extra term here which is one minus one over N raised to the power N minus LogN, this is saying that all of the other balls besides these LogN balls that we chose are assigned to other bins. So what is the probability that a particular ball is not assigned to Bin Bi? That's one minus one over N, N minus LogN balls that are not assigned to Bin Bi. Then what is this bound? This is actually equal to the probability that this Bin Bi gets load exactly LogN. But that's not what we want to bound. We want to bound the probability that the Bin gets at least LogN. So we want to get an upper bound. We ignore where the other balls, the other N minus is LogN balls are assigned. And then we get an upper bound on the probability because we allow these balls, these N minus Log N balls to be assigned to any Bin. Maybe Bi or maybe a different Bin. Now let's try to get a handle on this term, N choose LogN. Let's look at it more generally, N choose K. Recall what is N choose K. It's N factorial over and minus K factorial times K factorial. If we expand this out we got N factorial on the numerator, but all the terms from N minus K downwards cancel out with this N minus K factorial in the denominator. So we get N times N minus one, down to N minus K plus one. The remaining terms again cancel with this N minus K factorial on the denominator and then also in the denominator what are we left with? We're left with K factorial which is K times K minus one times K minus two, and so on down to one. Let's try to get a handle on this quantity. Notice the first term is N over K, the second term is similar, is N minus one over K minus one. If N is big, that's pretty similar to N over K, and so on. So we have N over K, N minus one over K minus one, and so on down to N minus K plus one over one. So there's K quantities, K ratios there. So here are the K ratios. Each one let's say is approximately N over K. So this is approximately N over K raised to the power K. Actually, this approximation is not too bad of a bound on this quantity. What one can show using Stirling's formula, is that N choose K is the most, N times E over K all raised to the power K. So if we put an extra factor of E in the numerator, then we get a rigorous upper bound on N choose K. And that's what we're aiming for. We're aiming for an upper bound on the Load size of Bin Bi. So we can upper bound N choose LogN by using this formula. So plugging in this bound for our case, we have K equals LogN in our scenario. So we get the upper bound N times E over LogN raised to the power of Log N, that's for the N choose LogN, and then we still have this term one over N to LogN, one over N to LogN. Now these are both raised to the power of LogN, so we can cancel out this N with this N. So what are we left with? We're left with E over LogN, E over LogN raised to the power of LogN. Now notice the denominator is growing with N, whereas the numerator is a fixed constant. So as N grows this becomes smaller and smaller. We're going to look at this asymptotically as a function of N so we can bound this inner term by any fixed cost and we want. So let's bound it by the constant one quarter. So, we're going to say E over LogN is in most one fourth, and so we get this whole quantity is bounded by one fourth to the LogN. Now what is the bound that we used here on N? We use the fact that LogN is bigger than four times E. When is that true? That's true when N is big enough. In particular, if N is bigger than two to the 11 then LogN is bigger than four times E, so we can replace E over LogN by one fourth. Now what is the nice thing about using one fourth here? Well, assuming that the log was base two, then this quantity one fourth raised to the LogN is equal to one over N square. So in summary, we've shown that the probability that Bin Bi gets load at least LogN is at most to one over N square which is tiny as N grows.

RA3 Bloom Filters - 150 - Max Load Quiz Question
Now what we saw in the last slide was that the probability that a particular bin Bi gets load at least log n is at most, one_over_n_squared. Now, can we use that to bound the max load? Can we upper bound the probability that the max load is at least log n? Why don't you go ahead and write this quantity here. If you have trouble doing it, don't worry, we'll go through it in a minute.

RA3 Bloom Filters - 151 - Max Load Quiz Solution
The solution is one_over_N, the probability that the max load is at least Log n, is at most one_over_N. Let's go through it in more details to see why this is the case.

RA3 Bloom Filters - 152 - Max Load Analysis
Now we want to bound the probability that the max load is at least log n, that's the quantity here. In order for the maximum load to be at least log n, at least one bin, maybe several, have to have a load at least log n. In order to upper bound this probability, we can use our earlier analysis. We know the probability that a particular bin gets loaded, at least log n, is at most one over N squared. So now, in order for at least one bin to get loaded at least log n, lets look at all the choices for the bins. So we can sum over each bin, and then we can look at the probability that the load in bin BI, is at least log n, which is what we bounded right here. That's at most 1 over N squared. There are N choices for the bin, and for each particular bin the probability the load is at least log n is at most 1 over N squared, and this is, 1 over N, which proves the result, that the max load is at least log n, with probability at most 1 over N. Now, we want to look at the complementary event, that the max load is strictly less than log n. What is the probability of this? Well, this event is unlikely to happen. This happens with a small probability, this is going to happen with a large probability. In particular, it happens with probability at least one minus one over N. And in fact, one can do a similar analysis, a little bit more carefully, and you can show that the max load is theta of log n over log log n. So we can get an upper bound, and a lower bound which are within constants of each other. So, instead of an upper bound of log n, on the max load, we can get a slightly better bound of log n over log log n. And this error probability can be boosted from one over N to 1 over and squared or 1 over N to the tenth, any polynomial, and then, we can get here by changing the constant up front. And when this error probability is 1 over a polynomial and N, we say that this event happens with high probability. In particular, if it happens with high probability, then that means it happens with probability at least one minus one over some polynomial and N, and we can make this polynomial small as we want, by increasing this constant up front.

RA3 Bloom Filters - 153 - Best of Two Scheme
Now, let's look at the following twist on the balls and bins problem. This is going to be a better approach, better in the sense that it's going to reduce the max load. Now, in the previous balls and bins problem, each ball was going to a random bin and it was independent of the assignment for the other balls. Therefore, we could have assigned all the balls simultaneously, in parallel. They could have all been assigned to bins at the same time, or we could assign them one by one, sort of sequentially. So, we could have taken ball one and assigned it to a random bin, take ball two, assign to a random bin, and so on, up to ball n. That's what we're going to do here. We're going to assign the balls sequentially, and we're going to look at a slight twist of the other scheme. So, let's go through the balls from one through n, index i will correspond to the current ball that we're considering. In the old scheme, we choose one random bin say j, and we assigned the i ball to bin bj. Now, in the new scheme what we're going to do is, we're going to choose two random bins, say j and k. Now, which bin are we going to assign the ith ball? Well we're going to assign it to the better of these two bins. What exactly do we mean? We mean the one which has smaller load. So, let load of j and load of k denote the current load in these particular bins bj and bk, and we're going to assign this ith ball to the least loaded of these two. So if the load of bj is structurally smaller than the load of bk, then we assign the ith ball to bin bj. And in the other case, we assign the ith ball to bin bk. So, the ith ball is going to the least loaded of these two bins.

RA3 Bloom Filters - 154 - Power of Two Choices
This new best of two approach is a simple twist on the original approach. What are we doing now? Well, instead of choosing a random bin, we choose two random bins, and we assign the ith ball to the least loaded of these two random bins. It turns out that with this scheme, the maximum load is order log log n, with high probability. Recall that the previous approach had max load on the order of roughly log n and we've reduced it from log n to log log n just by, instead of choosing one random bin, we choose two random bins, and we send to the best of the two. This is a substantial gain because log log n is quite small, even for very large n. So this is almost like order one, it's very close, it's a very small quantity. After seeing this result, you might say, "Well, why choose two random bins. " Let's choose three random bins and maybe we'll get log log log n." Well, it turns out that the big gain is from one to two, and after that there's not much gain. In particular, if you choose d, at least two bins, so instead of choosing two random bins you choose d random bins and you assign the ith ball to the least loaded of all of these d bins, then the max load is going to be log log n over log d. So the improvement with d is very small. Now, keep this idea in mind later, this idea of choosing the best of two choices. We're going to use this intuition later to get better hashing schemes and then to drive the intuition behind the Bloom filters. So finally, let's dive into hashing.

RA3 Bloom Filters - 155 - Hashing Setup
Now, let's turn our attention back to hashing, which is our main focus. It will be useful to keep a running example in mind to motivate our various hashing schemes. The example we'll use is unacceptable passwords. We want to maintain a database of unacceptable passwords. For example, these might be words that are in the dictionary. Now the setting is, that a user will enter a proposed password and our system should quickly respond if that proposed password is acceptable or not. So we need to quickly check whether the proposed password is in the database of unacceptable passwords or not. Now let's formalize our setting a little bit more precisely. We have a huge set U which is the universe of possible passwords. Now this is an enormous set. For example, if we simply look at passwords as strings or words of length A, then this set is of size 52 to the A, hence this set U is too large to maintain. Instead, we're going to maintain a subset of this universe, which will denote a subset S. S will contain the set of unacceptable passwords. The main operation our data structure needs to perform are queries. So for an element X in our universe. So X is a proposed password in this setting. Is X in this subset S? So is X an unacceptable password? Now we want to build a data structure or hashing scheme, which answers these queries quickly. Let's first look at how the traditional hashing scheme known as chain hashing, works in this setting. Now in order to maintain this set S, we're going to use a hash table H of size N, little N. In chain hashing, this table H is an array of linked lists. We're going to use a hash function little H which maps elements in U two elements and H. So each of the possible passwords is mapped to one of these N bins by little H. Now to insert an element into this subset S we simply find its hash value, then we go to that bin and then we add the element onto the linked list at that particular location. And then to do a query, we simply go to the hash value and we look at the linked list to check whether it's there or not. For each element of the universe, little H of X maps to one of these N bins. Now we're going to analyze random hash functions. So we're going to assume that H of X maps to a random bin. Moreover, we'll assume this choice, this random map, is independent of all other hashes. So where H of X maps to is independent of where any other element of the universe maps to. So this little H is a completely random hash function. Now if you think of this hash table as bins and you think of these elements in S as balls then what this hash function is doing is its assigning these balls into random bins. So it's reminiscent of our balls into bins problem that we analyzed before. Now it will be useful to have a little bit of notation before we move on. This set U is huge, and we'll denote its size by capital N. The hash table, we'll denote its size by little N. Now capital N, as in RSA, will be exponential size in little N, and we'll use little M to denote the size of this database, capital S, that we're maintaining. And once again, capital N is much bigger than little N, and typically our hash table size is at least the size of the database we're maintaining. So little N is at least size M, and our goal of course is to try to maintain this database as not much larger than little M.

RA3 Bloom Filters - 156 - Chain Hashing
Once again, in the traditional hashing scheme, chain hashing, H or hash table is an array of linked lists. H is an array of size N, and H of I, the Ith element of H, is a linked list of elements in our subset S which map to I. So, in other words, H of I is a linked list of those elements. So, those unacceptable passwords whose hash value is exactly I. Let's look at the query time. How long does it take us to answer a query of the form? Is X in a subset S, that we're maintaining. Now, in order to answer this query, what we have to do is look at the hash table at the index I, which is H of X, and then we have to go through that entire linked list and check whether X is in there in that linked list or not. So, the time it takes us, is proportional to this size of this linked list. What's the size of this linked list? It's the load at this bin. If we think of the elements of S as balls, these are getting assigned to bins, which are their hash values. The time it takes us to answer a query is proportional to the load size at the hash value. Let's introduce some notation. Let M be the size of our dictionary of unacceptable passwords, and let little n, be the size of our hash table. So, in our balls in bins analogy, little m is the number of balls that we're throwing in, and little n is the number of bins. Now, if m equals n, so the number of balls is the same as the number of bins. This is the toy problem that we analyzed before, and what we saw is that the max load is order log n, with high probability. Of course, in the worst case it might be, order n or n might be the max load, but that's an unlikely event. With high probability, the max load is going to be order log n, which means in the query time in the worst case, it's going to be order log n with high probability. Now, when n is huge, then order log n might be too slow for us. So how can we achieve faster query time? Well, one way is to try to increase the size of our hash table. In order to decrease this max load from order log n to order one, so that the query time will be order one constant time queries. We're going to have to increase the size of the hash table from order m to order m squared. Now, that's quite a large price to pay. So let's see if there are simpler ways to achieve reductions in the query time. Now, our intuition for the following scheme is comes from the balls and bins example from before. This is a simple scheme that we use right now. We're sending n balls into n bins. Each ball is going into a random bin. What do we use to improve that balls and bins scheme, to improve the max load? Well, we use the two choice scheme, and what we saw is that the max load goes down to order log log n, when we allow each ball to go to the least loaded of two random bins. So, let's try and use a similar scheme now for hashing.

RA3 Bloom Filters - 157 - Power of Two Hashing Question
what we're gonna do now is instead of using a single hash function we're going to choose a pair of hash functions H 1 and H 2 each of these hash tables Maps elements of U of our possible passwords into our hash table of size n now we're assume that these hash functions are random so each element acts in the universe of possible passwords maps to a random element of the hash table H 1 of X is random in each two of X are random and these are independent of each other and independent of the other hash values the first question is how do we insert an element a possible password into our dictionary of unacceptable passwords in the traditional scheme this is quite straightforward what we do is we look at our hash function and we look at H of X that tells us the hash value and now we looked at the linked list at H of X and we add element acts onto that linked list but now we have two hash functions H 1 and H 2 so how do we do this insertion into our dictionary in this scenario when we have two hash functions this is a bit of an open-ended question but why don't you think about how you would insert an element into our dictionary using two hash functions

RA3 Bloom Filters - 158 - Power of Two Hashing Solution
let's go ahead and look at how we do this insertion we want to insert this element X into our dictionary of unacceptable passwords first thing we do is compute these two hash values so we compute H 1 of X and H 2 of X think of our balls and bins analogy we have this ball ax and what we've done is we've chosen two random bins H 1 of X and H 2 of X which bin do we add the ball ax into we added into the least loaded at all of these two bins what is the load of the bin it's the size of the linked list we can maintain the size of each of these linked lists so that we can quickly determine which of these two is least loaded and then we can add in X into that appropriate linked list and then we can increment the size of that linked list so this can all be done in order one time for an insertion next question is how do we do a query how do we check whether an element Y up proposed password Y is in our dictionary of unacceptable passwords we start off the same as an assertion we compute the two hash values H one of Y and H 2 of Y these are the two possible locations for Y we have no way of determining which of these two locations it might be in if at all because we have no way of determining what the dictionary looked like at the time that we inserted Y if we did insert Y so what do we do we check both bins we check the linked list at h1 of Y and we check the linked list at h2 of Y and we look for Y in both of these linked lists so we check the linked list at H of H 1 of Y and we check the linked list at H of H 2 of Y and we look in both of these linked lists for the element Y if it's in either of these linked lists then we know that Y is in the dictionary if it's in either of these linked lists then we know that Y was never inserted into a dictionary of unacceptable passwords so how long does it take to do a query or the query time now depends on the load at this location and the load at this location so if we have an upper bound on the maximum load then the query time is twice the maximum load now if M equals n so the size of our date dictionary of unacceptable passwords and the size of our hash table are the same then what we know from our balls and pinion analogy is that the query time the max load is gonna be order log log and in this scenario so just changing from one hash function to a pair of hash functions and using this scheme then our query time goes down dramatically from order log n to order log log n and there's no extra cost in terms of the space though there is a question about how we maintain this hash function H especially if it's a truly random hash function in practice we can't store a truly random hash function instead we use pseudo random hash functions so we use a hash function which we obtain from a library such as ran or D ran 48 but for the purposes as an analysis it's convenient to consider a truly random hash function so that we can do this nice analysis such as how we obtain the order log and max load for the M equals n case for the simple case of one hash function we skipped the analysis for the case of the balls and bins example where we did the two choices where we had each ball going to the best of two random bins in that case we we claimed that the max load is order log log n that analysis is reasonable to do but it's much more complicated so we skipped it in this lecture

RA3 Bloom Filters - 159 - Lecture Outline
Now this completes our description of the traditional hashing approach, the chain hashing. Now we can move on to the bloom filters.

RA3 Bloom Filters - 160 - Bloom Filters Motivation
Now we can finally describe Bloom filters. Let's keep in mind this running example from before the case of unacceptable passwords. We're going to describe a new data structure that has faster queries. Recall in the traditional hashing scheme that we previously described, the query time was order log in for the simple scheme or order log log in for the more advanced scheme which used the power of two choices that are ideal. Here we're going to achieve query time order one. So constant query time, and this is guaranteed. Recall that the other query times were probabilistic statements. So with high probability the query time was order log in or order log log in. In the worst case it was order N. But here it's guaranteed to always be constant query time. This data structure will be very simple and it will use less space than before. There are no linked lists or anything like that. It will just be a simple binary array. Now there are a lot of benefits. It's simpler, less space, faster queries. Now there must be some cost for this simplicity and this faster time. So what is the cost, what is the tradeoff for this scheme? Well, this scheme is not always correct. Occasionally, there are false positives, and this happens with some probability that we'll analyze. We'll try to figure out what is this probability of false positives occurring. What exactly do we mean by false positive? We have an element X which is not in our dictionary of unacceptable passwords. So this is an acceptable password, but our algorithm occasionally says, yes this X is in the dictionary. In this setting false positives are acceptable. Why? Because we have an acceptable password but we say that the password is unacceptable. It's in our dictionaries. So we falsely say that the password is in our dictionary of unacceptable passwords. So somebody types in a password and we say, no that's not allowed. Ideally, it should have been allowed, but we said that, no is not allowed. So then the user has to enter a new password. But in exchange for these false positives we have guaranteed query time. So we answer the question of whether it was an acceptable password or not quickly. And in this setting false positives are reasonable. False negatives that would have been a big cost, that would have been unacceptable in this setting. When we have an unacceptable password we definitely want to say it's unacceptable. If we have an acceptable password, okay. If we occasionally say that it's an unacceptable password that's okay. So in this setting it's reasonable to have false positive with some small probability that we'll try to bound. In other settings it may be unacceptable to have false positives. In which case bloom filters might be a bad idea. So this is not a universal scheme. You have to look at your setting and determine whether the price of having a simpler and faster scheme is worth the cost of having false positives. Is it acceptable to have false positives with some small probability?

RA3 Bloom Filters - 161 - Operations
What are the basic operations that our data structure is going to support? First operation is insert x. So given a possible password X, we want to add this password into our dictionary of unacceptable passwords. The second operation is a query on X, is this proposed password in our dictionary of unacceptable passwords? If this proposed password is in our dictionary of unacceptable passwords, then we're always going to output YES, so we're always correct in this case. The problem is that, when this proposed password is not in our dictionary, so it is an acceptable password, we usually output NO and we have to bound what we mean by usually. But occasionally, we're going to output YES. So when in this proposed password is acceptable, occasionally we're going to have a false positive and say YES it is in the dictionary of unacceptable passwords, so this password is not allowed. So we have false positives with some small rate and we have to bound that rate and see what it looks like.

RA3 Bloom Filters - 162 - Bloom Filters
Finally we can describe our Bloom filter data structure. The basic data structure is simply a binary array a 0-1 array of size little n. So we have this binary array. We don't have any linked lists hanging off it at all. It's just a binary array of size n, that's the whole data structure. We're going to start off by setting h to all zeros. So all of the n bits are set to zero. As before, we're going to use a random hash function which maps elements of the universe of possible passwords into our hash table of size little n. How do we insert an element x of possible password into our dictionary x of unacceptable passwords? First off we compute is hash value, then we set the bit in this array to one at that hash value. So we compute H_of_x and we set H, capital H at H_of_x to be one. Now it might already be one, in which case we're not doing anything. So the bits only change from zeros to ones. We never change them back from ones to zeros. That's one of the limitations on this data structure. There is no easy way to implement deletions, because we never change bits from ones to zeros, we only change them from zero to ones. Now how do we do a query? How do we check whether an element x is in our dictionary s? Where we compute x hash value, and we check the array. The bit had that hash value and we see whether it's one or zero. If the bit at this hash value is one, then we output yes. We believe it is in the dictionary s. If it's zero, then we're guaranteed that it no it's not in the dictionary. Because if it's zero that means we definitely did not insert it. If it's one, then we think, we might have inserted it but we're not sure. Somebody else might have been inserted at that hash value, and we have no way of checking whether it's x was inserted at the hash values or somebody else was inserted at the hash value. Because we're not maintaining a linked list at this point. Let me repeat this point about how false positives can arise. We have some element x which we do a query on. It's not in our dictionary of unacceptable passwords, but there is some other element y which is in our dictionary of unacceptable passwords. And these two elements, x and y, have the same hash value. h_of_x equals h_of_y. So when we inserted y into our dictionary, then we set this bit at this point to one. So then when we do the query on x, this bit looks is 1. So we think or as far as we know, x might be in our dictionary. So we have to output yes because it might be there. But in fact it is no because it was not inserted but somebody else was inserted with the same hash value. That's how false positives arise. Now this scheme is not going to perform very well. How can we improve it? Well we can try to use our power of two choices idea that we used before in our traditional hashing scheme. So what are we going to do? Well instead of using one hash function, we're going to use two hash functions. Now in the traditional balls and bins example, there was a big gain from going from one hash function to two hash functions, but then going from two to three or three to four, was not much of a gain. But here, this is a slightly different setting and there'll be a big gain possibly going from one to two but even for two to three there might be a gain. And it's not clear how many hash functions to use and we're going to try to optimize that choice of number hash functions. So we're going to allow, instead of two hash functions, we're going to allow k hash functions. So we want to generalize this scheme to allow k hash functions and then we're going to go back and figure out what is the optimal choice of k, the number of hash functions. So let's look at the more robust setting where we allow k hash functions, and how do we modify this data structure to accommodate k hash functions.

RA3 Bloom Filters - 163 - Robust Scheme
So now we have k hash functions instead of just one, h1, h2, up to hk. We're going to initialize our hash table at H, capital H to all zeroes. So all of the bits, the n bits of H are set to zero. How do we do an insertion? How do we add an element X? A possible password into our dictionary S of unacceptable passwords. Previously we computed this hash value H of X and we set that bit to 1. What are we going to do now? Now we compute the K hash values and we set all of those K bits to 1. So we go through the hash functions 1 through K, and then we compute it's I'th hash value, and we set this bit to 1. It might already be 1 as before, but we always change bits from 0 to 1 just like before. How do we do a query? How do we check whether an element X was inserted into our dictionary S? Well, we compute it's K hash values and we check whether all of those K bits are set to 1 or not. If all of those K bits are set to 1, then our best guess is that X was inserted into the database S. If any of those are still 0, then we're guaranteed that X was not inserted into the database. So let's write that out more precisely. If for all of those K hash values the hash function at those K bits is set to 1, then we output yes. We believe that this element X is in the database S. If any of these K bits is still 0, then we're guaranteed that this element X is not in the database. So we output no.

RA3 Bloom Filters - 164 - Correctness
Let's take a look at the correctness of this algorithm for our queries. Suppose x was inserted into our database s, and we do a query on x. What do we output? Well, when we inserted x into the database, we set all of these k bits to one. So when we do a query, we're guaranteed that all of these bits are set to one, and so we're going to output Yes, because none of the bits ever change from ones to zeros. Bits only change from zeros to one. It's a one directional process.So if x was inserted into the database, when we do a query on x, we always output Yes. It is in the database. Now, suppose x was not inserted into the database and we do a query on x. Sometimes, we might say yes, we believe it's in the database. In which case, we get a false positive. We falsely say that, yes, it's in the database. How can this occur? This can occur if all of the k bits were set to one by other insertions. So for each of the k bits of x, so take the ith bit. So this is hi of x. There is some element, z, which was inserted into the database s and one of the k bits for z exactly matches the ith bit of x. Which of the k bits for z? Let's say the Jth bit for z. So the Jth bit for z matches the ith for x. In other words, h_i of x as the ith for x, matches the jth bit of z. So h_i of x equals h_j of z. This means that when z was inserted into the database we did the insert of z. Then we set this bit which matches the ith bit of x to one. And if this is true for every bit of x, so all the k bits of x are set to one by some other insertion then we're going to get a false positive on x. So this scheme has this extra robustness or redundancy. In order to get a false positive, we need all of these k bits to be set to one by some other insertions, whereas the previous scheme only had one bit which we're checking. Now we have k bits which need to get set to one in order to get a false positive. So it seems like things improve that the false positive rate goes down as k increases. But in fact there's an optimal choice of k. If k gets too large, the false positive rate starts to shoot up again. Why is that? Well if k is huge, then for every insertion you're setting k bits to one. So you're setting many bits to one if k is huge. So that means that for each of these and insertions, each of these elements in s, they have many bits, many choices of j which are set to one. So it's more likely if k is big, that one of these k bits is going to match up with one of the bits of x. So if k is too large, every insertion is setting too many bits to one. If k is small, then when we're checking it, when we're doing the query on x, we're checking too few bits. So there's some optimal choice of k, not too large and not too small. What we want to do now is more precisely analyze these false positives. What's the probability of a false positive? We want to look at it as a function of k and then we can figure out the optimal choice of k in order to minimise the false positive rate. And then we can compare and see what that false positive rate looks like to see whether this is a good data structure to use

RA3 Bloom Filters - 165 - Analysis Setup
Let's start analyzing the false positive rate. As before, let M, denote the size of our database or dictionary that we're maintaining. And let little N denote the size of our hash table. Now, presumably, N, the size of our hash table is going to be at least the size of the database that we're maintaining. So, the number of bins is at least the number of balls that we're inserting. So, the important parameter is going to be the ratio of these sizes. So, let C denote this ratio. The size of the hash table compared to the size of the database. So, C is going to be at least one. And our goal is to try to get the smallest C possible. So once again, the size of our database as a dictionary of unacceptable passwords is M. And the size of our hash table is C times M. There's a constant C which is at least one, and our hash table is this constant C bigger than the database that we're maintaining. Now, for an element X, which is not in our database. So, we didn't do an insertion on X. Let's look at the probability of a false positive for this X. So X was not inserted into the database. And what is the probability of a false positive? So, we incorrectly say that X was inserted into the database. So, in order for this to occur, we need that all the K bits for X. So H-1 of X H-2 of X up to H-K of X, were all set to one. If all of these bits are one but X was never inserted into the database, then we'll get a false positive. We'll incorrectly say yes, it is in the database because all of the K bits are one, but it was never in fact inserted into the database. So, let's try to analyze this probability that all this K bits are set to one. Let's first look at a simpler problem for a specific bit, B. What's the probability that specific that is set to one? So, for a specific bit. B, this is ranges between 0, 1, and N minus one. What is the probability that this specific bit, B is set to one? It would be slightly easier to look at the complimentary event that this specific bit is set to zero. So, the probability that this specific bit is one, is one minus the probability that this bit is still zero. Now, to analyze the probability that it's still set to zero, what we have to do is we have to check that all of the insertions miss this one bit. Now, let's go back and think about our balls and bins analogy in order to analyze this probability. Now, we have M insertions. In our simple hashing scheme, these insertions correspond to throwing a ball into a bin. So, this corresponds to throwing M balls into bins. But notice for each insertion, we have K hash values that we look at. And we set K of these values to one. So, each insertion corresponds to K balls. So, actually we're throwing M times K balls into bins. So, we're throwing these M times K balls and we're throwing them into N bins. Now, what is this specific bit being set to zero correspond to in this balls and bins example? In order for this bit to still be zero we need that all these M times K balls miss this specific bin, B. So this probability that this bit is zero is equivalent to the probability that all M times K balls miss this specific bin. For one ball, what's the probability that it misses a specific bin? The chance that it hits the specific bin is one over N, the chance it misses this bin is one minus one over N. And we're doing this for M times K balls. Now, this expression is not very complicated but will be much more convenient for us to have a slightly simpler expression.

RA3 Bloom Filters - 166 - False Positive Probability
So what have we done so far? We've shown that the probability that a specific bit is zero is equal to one minus one over N raised to the power M times K. Let's try to manipulate this to get a slightly more convenient expression. I want to replace this by an exponential. Supposed I look at E to the minus A for a number A. Let's take a look at the Taylor series for the exponential function. Let me remind you of that expression. So I have the exponential of minus A, where A is a number. That start off with one minus A, plus A squared over two factorial, minus A cubed over three factorial. Notice it's a alternating sign next term is A to the fourth over four factorial, and so on. You have this infinite series. Now for small A this series is decreasing, and as A goes to zero, then this series is approximated by one minus A. So this is a good approximation when A is sufficiently small. That's going to correspond in our case to N being sufficiently large and we're looking at A as N grows to infinity. So let's use this approximation to simplify our analysis of the false positive rate. So what can I do here? Here I have a equals one over N, as N grows one over N goes to zero. So there's a reasonable approximation, so I can replace one minus one over N by E to the minus one over N. So I have E to the minus MK over N. Recall that C is the ratio of the size of the hash table to the size of the database. Therefore, this expression can be simplified to E to the minus K over C. So now I have a very simple expression for the probability that a specific bit is zero. Recall our original problem. We have an element X which was not inserted into our database. We want to look at the probability of a false positive for this element. So what's the chance we output yes, even though X was not inserted into the database? So what's the probability that all of these K Bits corresponding to X were set to one by some other insertions? Well, the probability of a specific Bit being set to zero. We've just analyzed and shown that it's approximately E to the minus K over C. So what's the probability one of these specific Bits is set to one? It's one minus the probability that is set to zero. The probability set to zero is E minus K over C, the probability set to one is one minus E minus K over C. And we want K specific Bits all set to one. So the probability of that, is this raised to the power K. This expression is the false positive probability. It's not very nice right now because we have this K. Can we simplify this by eliminating K? Can we figure out what is the optimal K in order to minimize this false positive probability? Recall our intuition from before, we wanted to have K not too small, if K is small, then when we do a query, we're checking too few bits. But if K was big, if it's too large, then when we do an assertion we're setting too many bits to one, for each insertion. So there's some middle ground and we want to figure out the optimal choice of K in order to minimize this false positive probability. So what are we going to do? We're going to take this function. We're going to take its derivative. Set it at equal to zero and find the optimal choice of K in order to minimize this expression. So a bit of calculus, we're going to skip it. But I'll tell you the punchline.

RA3 Bloom Filters - 167 - Optimal k
Recall the expression that we just obtained for the false positive probability. The expression was one minus E to the minus K over C raised to the power K. Let's look at this as a function of K. So look, Let F of K denote this expression. This is F of K is a false positive probability for a specific choice of K, the number of hash functions. Our goal is to figure out what's the optimal choice for the number of hash functions, in order to minimize this false positive probability. So what do we do? We are going to minimize this function F of K. How do we find the optimal choice of K? Well, we take it's derivative, set it equal to zero. Check whether it's a global minimum. And then we find that choice of K, which sets the derivative equal to zero. Where does that optimal happen? It happens at K equals C times LN two. That's the natural log of two. The log base E of two. I'm going to skip this calculus, so that I don't embarrass myself. I've forgotten my calculus too, so don't worry. But let's look at this choice of K, which is the optimal choice in order to minimize the false positive probability. It's quite interesting. Actually, first off, let's plug this choice of K back into this expression. And then we can simplify it. Well, first off, when you plug in K equal C LN two over here, then the C is cancelled, and you're left with LN two. And then on the outside we have C LN two. What is E to the minus LN two? That's exactly one half. And what's one minus a half? It's a half. So the inside is one half raised to the power C LN two. Let's separate the C from LN two. So we have one half to the LN two, all raised to the power C. Now what is this inside? This is just a fixed constant. It's one half raised to the power LN two. You can plug it in on your calculator. Turns out that inner expression is .6185 approximately. So we have that raised to the power C. C is the ratio of the size of our hash table compared to our database. Now we have a simple expression for the false positive probability. It's .6185 raised to the power C. So if you tell me how large of a hash table you're willing to do, I can tell you what the false positive probability is. Before we look at that, let's just take a look at this expression right here. I want to point out something interesting about this choice, this optimal choice of K. What's a probability a specific bit is zero, or one? The chance is one is this inner expression. Chance is zero is this expression right here. Both of those are one half. So the chance we're setting a bit to zero is one half. The chance we're setting it to one is a half. So what does this binary string look like after we've done M insertions? So it's a binary string of length N, and we've done M insertions into it. What does it look like? Well, each bit afterwards is set to zero with probability half. So each bit is randomly set to zero or one. So this string H corresponds to a random string, where each bit is independently flipped to zero or one. So what's interesting, is that the optimal choice of K means, that if we just look at what this random string looks like, it's going to correspond to a random binary string, where each bit is independently set to zero or one. So the optimal choice of K corresponds to balancing out the zeros and ones in H, so that H looks like a random string.

RA3 Bloom Filters - 168 - Looking at False Positive Rate
Recall our setting. We have a database of size M and we have a hash table of size C times M for some C strictly greater than one. What we just showed is that the false positive probability is approximately .6185 raised to the power of C. This .6185 corresponded to one half raised to the power LN two. Let's now look at some specific examples to see how this performs. Let's suppose we did the naive scheme, where K equals one. So, we didn't do the optimal choice of K. We just set one hash function. And let's look at the case where we do 10 times larger or 100 times larger. Now, this expression for the false positive probability was assuming the optimal choice of K. In order to analyze this case where K equals one, we have to go back to our expression of F of K. If you look back at that expression and you plug in K equals one and C equal's 10, or C equal's a 100, you get the following. In the first case, the false positive probability is .095. And in the second case it's point.00995. Now, suppose we do the optimal choice of K. So, then our false positive probability is going to be this expression. Let's look at C equals 10. What do we get? We get.0082. A reasonable gain. But not that much better than C equal's a 100 with this simple K equals one case. Let's try to C equals a 100. Sorry. Hash table is a 100 times bigger than the database we're trying to store. But this is just a binary string, right? So, it's very reasonable to consider a hash table which is 100 times bigger. Now, the false positive probability is 1.3 times ten to the minus 21. The key thing is that this is exponential in C. So, taking C equals to a 100, it's tiny. This is really a minuscule probability. And if this is not small enough for you, you can go C equals to 200, or 300 and you're going to get a really, really tiny probability of a false positive. So, if you're willing to have a very small probability of a false positive, then you have this very simple data structure which just corresponds to having a binary string. It's very simple to maintain and is very fast query times and the false positive probability is very small. The downside of this data structure is that occasionally, you might have some false positives and also it doesn't easily allow for deletions from the database. Though, there are some heuristics for allowing deletions, these are modifications which are called Counting Bloom Filters. Well, that completes our description of Bloom Filters. I look forward to seeing your projects where you're going to implement Bloom Filters and you're going to explore whether these approximations that we did in our analysis were reasonable or not.

