Now, what we saw in the previous slide was we looked P raised to the power T or K for big T. We did T equals 20, but let's take T going to infinity and see what it looks like. So let's take the limit as T goes to infinity and look at P raised the power T. It turns out there's this row vector pi. Now these entries might look quite familiar. They look very similar to the row of P to the 20. Now what is P to the T going to look like as T goes to infinity? Well, each row is going to converge to pi. So every row is going to converge to this row vector pi. What does this mean? This means that no matter where you start, it doesn't matter where you start, because that's the row here, independent of where you start. If you look for big enough T, the probability that you are at state J at time T is going to be exactly defined by this row vector pi. So pi of J is going to be the probability that I'm in State J at time T, for Big T. So for our 6210 example, what does this mean? This means no matter where you start at time zero, if the class is long enough, the probability that you're sleeping at time T is exactly 0.104. And similarly the probably you playing Starcraft at time T for big T is exactly point 0.406 for big T. Regardless of where you start at time zero. This pi is referred to as a stationary distribution. You can think of is like a fixed point of the process. For this particular example, regardless of where you start, you eventually reach this stationary distribution and once you're at the stationary distribution, you're going to stay at the stationary distribution. It's going to be invariant. Now what we want to understand is, does every Markov chain have a stationary distribution? And does every Markov chain have this property that regardless of where I start I eventually reach this stationary distribution? Moreover, is there a unique stationary distribution or is there multiple stationary distributions? If you think of the analogy with fixed points are the multiple fixed points? Well, there's only one fixed point and regardless of where I start, the basin of attraction is everywhere. So regardless of where I start, I always reach that one attractive fix point. So is there one stationary distribution which I reach regardless of where I start? Or can there be multiple stationary distributions? Certainly there can be multiple, but we want to look at conditions where there are a unique stationary distribution and regardless of where I start, I always reach that stationary distribution. Then we want to look at what is this pi? What is the stationary distribution? Now this is quite important. The stationary dispersion y. For page rank, what is going to correspond to where we're going to do a random walk. A Markov chain on the web pages and then the page rank is going to correspond to the stationary distribution of that Markov chain. So all this technology is going to be useful when we're trying to understand the page rank algorithm. Now before we move on and look at details about stationary distributions, I want to look at it from another perspective. I want to look at it from a linear algebra perspective. What does a stationary distribution pi mean from a linear algebra perspective?