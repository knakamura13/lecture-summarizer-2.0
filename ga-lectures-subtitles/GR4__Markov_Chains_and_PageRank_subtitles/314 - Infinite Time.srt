1
00:00:00,000 --> 00:00:03,350
 Now, what we saw in the previous slide was we looked P raised to

2
00:00:03,350 --> 00:00:08,270
 the power T or K for big T. We did T equals 20,

3
00:00:08,270 --> 00:00:12,210
 but let's take T going to infinity and see what it looks like.

4
00:00:12,210 --> 00:00:15,320
 So let's take the limit as T goes to infinity and look at P

5
00:00:15,320 --> 00:00:19,590
 raised the power T. It turns out there's this row vector pi.

6
00:00:19,590 --> 00:00:21,925
 Now these entries might look quite familiar.

7
00:00:21,925 --> 00:00:26,245
 They look very similar to the row of P to the 20.

8
00:00:26,245 --> 00:00:29,445
 Now what is P to the T going to look like as T goes to infinity?

9
00:00:29,445 --> 00:00:32,730
 Well, each row is going to converge to pi.

10
00:00:32,730 --> 00:00:36,030
 So every row is going to converge to this row vector pi.

11
00:00:36,030 --> 00:00:37,220
 What does this mean?

12
00:00:37,220 --> 00:00:39,430
 This means that no matter where you start,

13
00:00:39,430 --> 00:00:40,590
 it doesn't matter where you start,

14
00:00:40,590 --> 00:00:42,330
 because that's the row here,

15
00:00:42,330 --> 00:00:44,165
 independent of where you start.

16
00:00:44,165 --> 00:00:45,975
 If you look for big enough T,

17
00:00:45,975 --> 00:00:48,675
 the probability that you are at state J at time

18
00:00:48,675 --> 00:00:53,070
 T is going to be exactly defined by this row vector pi.

19
00:00:53,070 --> 00:00:57,518
 So pi of J is going to be the probability that I'm in State J at time T,

20
00:00:57,518 --> 00:01:01,105
 for Big T. So for our 6210 example, what does this mean?

21
00:01:01,105 --> 00:01:03,645
 This means no matter where you start at time zero,

22
00:01:03,645 --> 00:01:05,325
 if the class is long enough,

23
00:01:05,325 --> 00:01:11,480
 the probability that you're sleeping at time T is exactly 0.104.

24
00:01:11,480 --> 00:01:15,810
 And similarly the probably you playing Starcraft at time T for big T is

25
00:01:15,810 --> 00:01:21,015
 exactly point 0.406 for big T. Regardless of where you start at time zero.

26
00:01:21,015 --> 00:01:24,420
 This pi is referred to as a stationary distribution.

27
00:01:24,420 --> 00:01:26,850
 You can think of is like a fixed point of the process.

28
00:01:26,850 --> 00:01:28,165
 For this particular example,

29
00:01:28,165 --> 00:01:29,395
 regardless of where you start,

30
00:01:29,395 --> 00:01:32,235
 you eventually reach this stationary distribution

31
00:01:32,235 --> 00:01:34,290
 and once you're at the stationary distribution,

32
00:01:34,290 --> 00:01:36,480
 you're going to stay at the stationary distribution.

33
00:01:36,480 --> 00:01:39,615
 It's going to be invariant. Now what we want to understand is,

34
00:01:39,615 --> 00:01:43,040
 does every Markov chain have a stationary distribution?

35
00:01:43,040 --> 00:01:46,350
 And does every Markov chain have this property that

36
00:01:46,350 --> 00:01:50,425
 regardless of where I start I eventually reach this stationary distribution?

37
00:01:50,425 --> 00:01:52,770
 Moreover, is there a unique stationary distribution

38
00:01:52,770 --> 00:01:54,928
 or is there multiple stationary distributions?

39
00:01:54,928 --> 00:01:58,179
 If you think of the analogy with fixed points are the multiple fixed points?

40
00:01:58,179 --> 00:02:01,450
 Well, there's only one fixed point and regardless of where I start,

41
00:02:01,450 --> 00:02:03,600
 the basin of attraction is everywhere.

42
00:02:03,600 --> 00:02:04,875
 So regardless of where I start,

43
00:02:04,875 --> 00:02:08,210
 I always reach that one attractive fix point.

44
00:02:08,210 --> 00:02:12,565
 So is there one stationary distribution which I reach regardless of where I start?

45
00:02:12,565 --> 00:02:15,595
 Or can there be multiple stationary distributions?

46
00:02:15,595 --> 00:02:16,900
 Certainly there can be multiple,

47
00:02:16,900 --> 00:02:18,790
 but we want to look at conditions where there are

48
00:02:18,790 --> 00:02:22,650
 a unique stationary distribution and regardless of where I start,

49
00:02:22,650 --> 00:02:24,625
 I always reach that stationary distribution.

50
00:02:24,625 --> 00:02:26,655
 Then we want to look at what is this pi?

51
00:02:26,655 --> 00:02:28,645
 What is the stationary distribution?

52
00:02:28,645 --> 00:02:29,730
 Now this is quite important.

53
00:02:29,730 --> 00:02:31,245
 The stationary dispersion y.

54
00:02:31,245 --> 00:02:35,910
 For page rank, what is going to correspond to where we're going to do a random walk.

55
00:02:35,910 --> 00:02:38,880
 A Markov chain on the web pages and then

56
00:02:38,880 --> 00:02:44,095
 the page rank is going to correspond to the stationary distribution of that Markov chain.

57
00:02:44,095 --> 00:02:45,840
 So all this technology is going to be useful

58
00:02:45,840 --> 00:02:48,345
 when we're trying to understand the page rank algorithm.

59
00:02:48,345 --> 00:02:52,005
 Now before we move on and look at details about stationary distributions,

60
00:02:52,005 --> 00:02:54,375
 I want to look at it from another perspective.

61
00:02:54,375 --> 00:02:56,985
 I want to look at it from a linear algebra perspective.

62
00:02:56,985 --> 00:02:56,985
 What does a stationary distribution pi mean from a linear algebra perspective?

