Now here's a running example once again. Now let's suppose that at time zero I'm in state two and I want to know the state at time t equals one. What's the distribution for the state at time t equals one? Well, how do I get it? Why just look at this row. The second row of this transition matrix tells me the distribution for the state at time t equals 1. It's the one step transition matrix. Now what's another way to get row two. Well, I can take this vector which has a one in entry two and zeros everywhere else and I can multiply this row vector by this matrix, and then what do I get? I get row two of this matrix. So this my distribution at times zero and I multiply that by the transition matrix and I get the distribution at time t equals one. And in general at time zero I don't have to be in a fixed state. I can be in a distribution over the states. So let M be an arbitrary distribution over the end states. So what exactly does that mean. That means M is this vector and this row vector of size N and it's a probability distribution, so the sum of these entries is exactly one and all these entries are between zero and one. Now we're placing this factor by distribution, M. Then here we have P and then we get a distribution at time t equals one. So let's call this M zero to denote the distribution at times zero. And over here, we get a distribution for the time t equals one, so let's call this M one. In general, if you take M zero so the distribution at time zero and multiply by this matrix P, the transition matrix, then we get the distribution for the state at time t equals one. So we take this row vector for the distribution of time zero, multiply by one step. So we do one step of our random walk and then we get the distribution, the row vector for the state at time t equals one. Now the key property is that for a stationary distribution pi for any stationary distribution pi. So if I am in the stationary distribution at time zero or at any time t and I look at the state at time t plus one, then what is the distribution going to be? Well once I reach this distribution, I stay in it. It's the limiting distribution. It's like a fixed point of the process. So once you reach a fixed point you stay in a fixed point and that's the same for a stationary distribution. So if I'm in the stationary distribution at time t, and I do one step then I'm still in the stationary distribution pi. So pi times P equals pi. What does that mean in terms of linear algebra? Well this pi is an eigenvector with eigenvalue one. So pi is an eigenvector for this matrix P and it's an eigenvector with eigenvalue one. One turns out to be the largest eigenvalue for this matrix. So this is the principle eigenvector for this matrix. Now there can be multiple eigenvectors with eigenvalue one. We're going to look at situations where we know that there is at most one eigenvector with eigenvalue one. So there is at most one stationary distribution.