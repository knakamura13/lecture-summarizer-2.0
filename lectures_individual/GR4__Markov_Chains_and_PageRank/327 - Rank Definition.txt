So, let's go ahead and formalize this idea. So, a citation from web page y, it's value is going to be proportional to the importance the rank of web page y. So, we're going to scale this quantity by pi of y. Formally, the rank of the web page x. We're going to get it by looking at this sum over all web pages y, which have a link to x. The total value of the citations from y is pi of y. And y has this many outgoing links. This is the number of out neighbors. So, this link from y to x has value pi of y divided by the number of out neighbors of y. And this is going to be the definition of the page rank of web page x. Well, now to be precise, this is not exactly the definition of the page rank of a web page x. There's a technical glitch that we'll notice by looking at this from the perspective of Markov chains. Before we dive back into Markov chains, let's look closely at this proposed definition of the rank. It's a recursive definition. So, first off, is it well defined? Is there a pi satisfying it for every vertex x? This question of whether there exists a pi satisfying it, corresponds to whether there exists a stationary distribution for the corresponding Markov chain. Now, if there does exist such a pi, is there any unique such pi? Or are there multiple pis? This corresponds to the question of whether there is a unique stationary distribution or multiple stationary distributions. We'll address both of these questions using our intuition from Markov chains. First, we'll derive this definition using Markov chains and then we'll see how to ensure that there is a unique stationary distribution. So, let's dive back into Markov chains now.