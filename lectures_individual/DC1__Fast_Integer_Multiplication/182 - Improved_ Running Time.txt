Now if we look at the running time of our new algorithm, we have three sub-problems that were recursively computing. Each is a product of pair of n/2 or two bit numbers. And then to combine these solutions from these three sub-problems it takes us order and time to get the product of X*Y. What does this solve to? Well, let's go ahead and dive into it to give you a bit of a refresher on solving recurrences. The first step is upper bounding this O(n), by Cn for sum constant C. Now we can substitute in this expression back and forth, T(n/2). So we get Cn + 3T. Now we substitute n for T(n/2), which is Cn/2 + 3 (T(n/2)². Collecting terms, we have, Cn, plusanother Cn*3/2. Then we have a 3² x T(n/2)². Plugging that back in, we get Cn/2² from that term, + 3*T(n/2)³. Collecting terms we have Cn,*1, +3/2, +3/2². The next term is going to be 3/2³, and so on. We're going to get this geometric series. How many terms in this geometric series, what's the last exponent? We're going to keep going until this term is a constant. There are going to be log2n terms. Now we have this geometric series. We got to look at the series see whether the terms are equal, they're not. Is it decreasing geometric series, in which case the first term dominates? It's not. It's an increasing geometric series, because three houses bigger than one so the last term dominates. This whole thing is on the order of the last term. We get a O(n) for this term,*3/2 to log2n for this last term. Now this 2^logn is the same as n, so those cancel. We're left with 3^log2n. Let's convert that into a polynomial. You should remind yourself how to convert this into a polynomial. Let me give you a quick reminder. 3 is the same as 2^log(3). That's the definition of log. So I have this expression, 3^log2n. And I can replace 3 by this expression. And then I raise that whole quantity ^log2n. Now these two exponents multiply together, so I can swap them. This quantity is the same as, 2^log2^log2^3. Now these two things are the same. Now, this is much simpler. Because what is 2^log2n? This is simply n. Now, I have n raised to a power, which is a constant, log2^3. this recurring solves to, O(n)^ log2^3. What does this number log2^3? Well, if you plug it into a calculator, you see that log2^3 is roughly 1.59. So we went from an O(n)² algorithm, to an O(n)^1.5 9 algorithm. And in fact, we can improve this exponent. We can get arbitrarily close to 1, but there's an expense for that. This constant hidden in the Big O notation is going to grow as this exponent decreases. And instead of breaking the input up into two halves, we're going to break it up into more parts, and then we're going to have to work harder in order to combine the solutions together.