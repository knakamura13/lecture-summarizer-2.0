Directed graph example used to represent a Markov Chain for activities during CS 6210 class. Time discretized into integer steps t=0,1,2,... with four states: listening to Kishore, sleeping, checking email, playing StarCraft. Each state is a vertex in the graph; transitions between states are edges with weights indicating probabilities. Transition probabilities from one state at time 't' to another at 't+1' are quantified (e.g., email to StarCraft with probability 0.5). Probabilities must sum to 1 across all out-edges from any given state, ensuring they form a valid probability distribution for subsequent states. Probability values range from 0 to 1. Totality of the directed graph with weighted edges between 0 and 1 characterizes the Markov Chain, elucidating state transitions over time.