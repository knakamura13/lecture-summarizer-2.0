Let's look again at why the random surfer model is ergodic. We have our original web graph, capital G. Now, what happens in the random surfer model? Well, with probably alpha, we follow a random outgoing link in G. And with probably one minus alpha, we go to a random web page in the entire graph. This corresponds to adding in the complete graph, where capital N is the number of vertices in this original graph. So, this defines our new graph, G-prime. Now, suppose that alpha is strictly less than one. That means, with some positive probability, we use these edges from the complete graph. So, if we consider any pair of states, i and j. Let's look at the probability of going from state i to state j in one step. Well, if alpha is strictly less than one, then there's some chance, some probability, of going from state i to state j, using this last type of transition. That means, in the transition matrix, the entry i j in the matrix P is positive and all the entries in this matrix are positive. There is no zero entries in this matrix. It's a fully connected transition matrix. Therefore, if alpha is strictly less than one, then this random surfer model is ergodic. Now, what happens if alpha equals one, then we're not using this random button here? So, we're just using the original graph and there's no reason why the original graph is going to be ergodic. The original graph that we're interested in is this graph, G. Instead, we're looking at this graph, G-prime. For the case alpha less than one, we need this condition that alpha is less than one in order for it to be ergodic. But how does this new graph, G-prime, compare to this original graph, G? In particular, how does the principle eigenvector for this graph G-prime, this PageRank vector for G-prime, compare to the properties of the original graph G? While this is a somewhat vague, very triggering, but a very vague question. i don't know how to address it. But what we can look at is, what is the effect of varying alpha? How does the PageRank vector change as we vary alpha? Well, if alpha is large, if it's close to one, then this graph G-prime is close to the original graph, G. So we hope that the properties of G-prime are close to the properties of G. As alpha gets smaller, then this complete graph is becoming bigger and we're becoming further away from the original graph, G. But there's a trade-off. As alpha decreases, our convergence rate to the PageRank vector to the principle eigenvector is going to go faster. We're going to converge faster to this principle eigenvector, because of this complete graph, as this becomes bigger, yet the mix faster. Now, according to Wikipedia, Google uses alpha as 0.85. This presents a reasonable trade-off between these two scenarios. But an interesting question is, how does the PageRank vector change as we vary alpha? But if we look at alpha big like 0.99 or 0.95, compared to alpha is 0.85 or 0.75. How does a PageRank vector change? For example, if you look at the top sites, those sites with the largest PageRank vectors, how does a set of top sites change with alpha? And does their ordering change with alpha? So, if you implement the PageRank algorithm and you take a large dataset, then you can look at what is the effect of varying alpha on the ordering of the sites, according to PageRank.